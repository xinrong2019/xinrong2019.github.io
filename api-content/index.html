{"posts":[{"title":"“WHY-HOW-WHAT”黄金圈思维模式","content":" 这是一个教你如何做好事情的思维模式。 举个例子：你想要赚钱谋生 目的：赚钱 具体的方法和措施：通过学习编程，掌握技能，满足企业招聘要求，满足工作岗位的技能要求 现象和成果：掌握了或者没掌握，没有找到工作或者找到一份工作，或者找到的工作不满意 上面的方法（HOW）可以再进行分解： 目的：赚钱 具体的方法和措施：学习Java、中间件、SQL、调优，做笔记进行知识积累，做企业级分布式项目巩固所学，为我所用。 成果：获得经验，升职加薪 这其中，目的，也就是&quot;WHY&quot;尤为重要，必须要有一个让自己信服的理由去做一件事，这个理由必须要深刻，达到一定的影响力，比如影响你的作息、习惯。为了赚钱养家糊口，你必须放弃一些个人娱乐时间，投入到给自己提升技能的工作中去。 再说方法和措施，这是一个需要不断细化，不断迭代的过程，是行动的主体，占用你大部分的时间。可以拆分成很多个&quot;WHY-HOW-WHAT&quot;。执行的时候，经常会被各种事情打断，不要完美主义，要有容错的空间，允许计划没有100%完成。关键是得坚持，把事情做完。 比如，你想要刷MySQL知识点，吃饭的时候玩手机，刷到一个不错的Flink教程，这个时候别去管Flink，坚持把MySQL刷完。 最后说说成果。俗话说做事情要有始有终，不能做一半，半途而废。成果一般是提高了对某一个方面的认知。认知差异是这个社会不平等的原因之一，认知差异也是影响贫富差距的一个重要原因。 成果需要被展示，你对某一领域的某一方面的认知，需要被记录下来，比如通过博客或者自媒体都行。 文章参考： Why-How-What黄金圈法则 的理解和运用 ","link":"https://xinrong2019.github.io/post/why-how-whathuang-jin-quan-si-wei-mo-shi/"},{"title":"分布式基础理论认知","content":"分布式 TOC [TOC] 分布式系统定义及面临的问题 分布式系统定义为： 分布式系统是一个硬件或软件组件分布式在不同的网络计算机上，彼此之间仅仅通过消息传递进行通信和协调的系统。 分布式环境的各种问题 通信异常 网络分区 三态 分布式系统每一个请求与响应存在特有的“三态”概念，即成功、失败和超时。 节点故障 分布式理论：一致性概念 不同场景对分布式一致性的需求是不同的。 火车站售票系统，要求数据是实时一致； 转账系统要求最终一致，但是要正确； 网购系统要求最终一致，中间会存在不一致的状态，但是最终也会是一致的。 分布式一致性的提出 数据库之间复制的延时。 为什么要数据复制： 增加系统可用性，防止单点故障导致系统不可用 可以通过负载均衡，提高系统整体性能 数据一致性，是指对一个副本数据进行更新的时候，必须确保也能更新其他的副本，否则不同副本之间的数据将不一致。 一致性级别： 强一致性 弱一致性（尽可能保证一定时间内达到数据一致） 最终一致性（一定保证一定时间内达到数据一致） 分布式事务 是指事务的参与者、支持事务的服务器、资源服务器以及事务管理器分别位于分布式系统的不同节点上，通常一个分布式事务会涉及到多个数据源或业务系统的操作。 分布式理论-CAP定理 什么是CAP定理 CAP理论告诉我们，一个分布式系统，不可能同时满足一致性（C:Consistency），可用性（A:Availability）和分区容错性（P:Partition tolerance）这三个基本需求，最多只能同时满足其中两个。 对于分布式系统而言，分区容错性可以说是一个基本的要求，因此架构师往往需要把精力花在如何根据业务特点在C（一致性）和A（可用性）之间寻求平衡。 能不能解决3选2的问题 需要思考分区是不是百分之百出现呢？ 如果不出现，那么就能够同时满足CAP。 如果出现了分区，可以根据策略进行调整。比如C不必使用那么强的一致性，可以先将数据存起来，稍后更新，实现所谓的“最终一致性”。 基于这个思路，也引出了第二个理论Base理论。 分布式理论-BASE理论 什么是BASE理论 全称：Basically Available(基本可用)，Soft state(软状态)，和Eventually consistent(最终一致)三个短语的缩写，来自ebay的架构师提出。 Base理论和CAP理论的关系 Base理论是对CAP中一致性和可用性权衡的结果，其来源于大型互联网分布式实践的总结，是基于CAP定理逐步演化而来的。 Basically Available(基本可用) 分布式系统在出现不可预知的故障时，允许损失部分可用性。而不是完全不可用。具体举两个例子： 响应时间上的损失：正常情况下，一个在线搜索引擎要在0.5秒内返回用户相应结果，但由于出现故障，查询结果的响应时间增加到了1-2秒 功能上的损失：对于电商网站，在大促时，由于消费者的购物行为激增，为了保护系统的稳定性（或者保证一致性），部分消费者可能会被引导到一个降级页面。比如如下页面 Soft state(软状态) 什么是软状态？相对于一致性，要求多个节点的数据副本都是一致的，这是一种“硬状态”。 软状态是指：允许系统中的数据存在中间状态，并认为该状态不影响系统整体可用性，即允许系统在多个不同节点的数据副本之间进行数据同步的过程中存在延迟。 Eventually consistent(最终一致) 强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。因此最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性。 在实际工程实践中，最终一致性存在以下五类主要变种： 因果一致性（Causal consistency） 读己之所写（Read your writes） 会话一致性（Session consistency） 单调读一致性（Monotonic read consistency） 单调写一致性（Monotonic write consistency） 实际系统实践中，可以将其中若干个变种互相结合起来，以构建一个具有最终一致性的分布式系统。 总结：BASE理论面向的是大型高可用可扩展的分布式系统，通过牺牲强一致性来获得可用性，并允许数据在一段时间是不一致的，但最终要保证数据一致。 分布式理论-一致性协议2PC 背景：为了使系统尽量能够达到CAP，于是有了BASE协议，而BASE协议是在可用性和一致性之间做的取舍和妥协。 我们在对分布式系统进行架构设计的时候，对可用性和一致性反复权衡的过程中，涌现了一些经典的算法和协议，最著名的几种就是二阶段提交协议，三阶段提交协议，Paxos算法等。 什么是2PC 协调者：统一调度所有分布式节点的执行逻辑。负责调度参与者的行为，并最终决定这些参与者是否要把事务真正进行提交。 参与者：被调度的节点 二阶段提交就是把事务的提交过程分成了两个阶段来进行处理。流程如下： 阶段一：提交事务请求 事务询问 协调者向所有参与者发送事务内容，询问是否可以执行事务提交操作，并开始等待各参与者的响应。 执行事务 各参与者节点执行事务操作，并将Undo和Redo信息记入事务日志中 （Redo用来保证事务的原子性和持久性，Undo能保证事务的一致性，两者也是系统恢复的基础前提） 各参与者向协调者反馈事务询问的响应 如果参与者成功执行了事务操作，那么久反馈给协调者Yes响应，表示事务可以执行；如果参与者没有成功执行事务操作，就反悔No给协调者，表示事务不可以执行。 又称为投票阶段，即各参与者投票表明是否要继续执行接下来的事务提交操作。 阶段二：执行事务提交 根据阶段一的结果决定是否可以进行事务提交操作，正常情况下，包含两种操作可能：提交事务，中断事务。 提交事务过程如下： 假如阶段一所有参与者反馈都是Yes，那么就会执行事务的提交 发送提交请求 协调者向所有参与者发送commit请求 事务提交 参与者收到commit请求后，会正式执行事务提交操作，并在完成提价之后释放整个事务执行期间占用的事务资源。 反馈事务提交结果 参与者在完成事务提交之后，向协调者发送Ack信息 完成事务 协调者接收到所有参与者反馈的Ack信息后，完成事务。 中断事务步骤如下： 假如任何一个参与者向协调者反馈了No响应，或者在等待超时后，协调者尚未接收到所有参与者的反馈响应，那么就会中断事务。 发送回滚请求 协调者向所有参与者发送Rollback请求 事务回滚 参与者接收到Rollback请求后，会利用其在阶段一记录的Undo信息来执行事务回滚操作，并在完成回滚之后释放在整个事务执行期间占用的资源 反馈事务回滚的结果 参与者在完成事务回滚后，向协调者发送Ack信息 中断事务 协调者接收到所有的参与者反馈的Ack信息后，完成事务中断。 2PC主要做了两个事情：投票，执行。 将事务的处理过程分为了投票和执行两个阶段，核心是对每个事务都采用先尝试后提交的处理方式，从而保证其原子性和一致性，因此可以将二阶段提交看成一个强一致性的算法。 2PC优缺点 优点： 原理简单，实现方便 缺点： 同步阻塞，单点问题，数据不一致，过于保守 同步阻塞 各个参与者在等待其他参与者响应的过程中，无法进行其他操作。限制了分布式系统的性能。然而分布式系统就是为了提高系统整体的性能。 单点问题 协调者单点问题 数据不一致 协调者向所有参与者发送commit请求后，发生了局部网络异常或者协调者在尚未发送完所有commit请求之前自身发生了崩溃，最终导致只有部分参与者收到了commit请求。将导致严重的数据不一致问题。 过于保守 协调者通过超时机制判断是否需要中断事务，这种策略过于保守。 二阶段没有设计较为完善的容错机制，任意一个节点失败都会导致整个事务的失败。 分布式理论-一致性协议3PC 背景：为了弥补阶段二提交的缺点 什么是三阶段提交 将2PC的提交事务请求过程一分为二，共形成了由CanCommit、PreCommit和doCommit三个阶段组成的事务处理协议。 阶段一：CanCommit 事务询问 协调者向所有参与者发送一个包含事务内容的canCommit请求，询问是否可以执行事务提交操作，并开始等待各参与者的响应 各参与者向协调者反馈事务询问的响应 参与者在接收到来自协调者的包含了事务内容的canCommit请求后，正常情况下，如果自身认为可以顺利执行事务，则反馈Yes响应，并进入预备状态，否则反馈No响应 阶段二：PreCommit 协调者在得到所有参与者的响应之后，根据结果有两种执行操作的情况：执行事务预提交，或者中断事务 假如所有参与者反馈都是Yes，那么就会执行事务预提交 执行事务预提交分为三个步骤： 发送预提交请求 协调者向所有参与者节点发送preCommit请求，并进入prepared阶段。 事务预提交 参与者接收到preCommit请求后，会执行事务操作，并将Undo和Redo信息记录到事务日志中。 各参与者向协调者反馈事务执行的结果 若参与者成功执行了事务操作，那么反馈Ack，同时等待最终的指令：提交或终止 若任一参与者反馈了No响应，或者在等待超时后，协调者尚未接收到所有参与者反馈，则中断事务 中断事务也分为两个阶段： 发送中断请求 中断事务 阶段三：doCommit 这个阶段，做真正的事务提交完成回滚 执行事务提交： 发送提交请求 事务提交 反馈提交结果 完成事务 中断事务： 发送中断请求：协调者向所有参与者节点发送abort请求。 事务回滚 反馈事务回滚结果 中断事务 一旦进入阶段三，可能会出现两种故障： 协调者出现问题 协调者和参与者之间的网络故障 如果出现任意一种情况，最终都会导致参与者无法收到doCommit请求或者abort请求，针对这种情况，参与者都会在等待超时之后，继续进行事务提交。 3PC优缺点 优点 最大的优点是降低了参与者的阻塞范围（第一阶段不阻塞），其次能够在单点故障后继续达成一致（2PC在提交阶段会出现此问题，3PC会根据协调者的状态进行回滚或者提交）。 缺点 如果参与者收到了preCommit消息后，出现了网络分区，此时协调者所在节点和参与者所在节点无法进行网络通信，那么参与者等待超时后，会进行事务提交，这必然会出现分布式数据不一致的问题。 2PC和对比3PC 对于协调者和参与者都设置了超时机制（而2PC只有协调者有超时机制，即如果在一定时间内，没有收到参与者的消息则默认失败）。 在2PC准备阶段和提交阶段之间，插入了预提交阶段，是一个缓冲，保证了最后提交阶段之前各个参与节点的状态是一致的。 分布式理论：一致性算法Paxos 什么是Paxos算法 一种基于消息传递且具有高度容错特性的一致性算法。主要用来解决分布式系统中，如何就某个值达成一致的算法。 Google Chubby OceanBase Paxos解决了什么问题 解决了一致性问题 在分布式系统中，发生诸如机器宕机或网络异常（包括消息的延迟、丢失、重复、乱序、网络分区）等情况。可以快速且准确的在集群内对某个数据的值达成一致，并且保证不论发生以上任何异常，都不会破坏整个系统的一致性。 假如，一个集群环境中，要求所有机器上的状态是一致的，其中有两台机器想修改某一个状态，机器A想把状态修改为A，机器B想把状态修改为B，那么到底听谁的？ 进一步思考，可以引入协调者，谁先到，听谁的。 但是协调者宕机了呢？ 所以需要对协调者也做备份也要做集群，这时候，问题来了，这么多协调者，听谁的呢？ Paxos算法就是为了解决这个问题而生的 Paxos相关概念 提案（Proposal）：最终要达成一致的value就在提案里。包括提案编号（Proposal ID）和提议的值（Value） 三种角色： Proposer:提案发起者 Acceptor:决策者，可以批准提案，接受提案 Leaners:最终决策的学习者 如果某个提案被选定，那么该提案的value就被选定了。 具体的实现中，一个进程可能同时充当多种角色。可能即是Proposer又是Acceptor又是Leaner。 怎么理解“对某个数据的值达成一致”？ 指的是Proposer、Acceptor、Leaner都认为同一个value被选定。 那么Proposer、Acceptor、Leaner分别在什么情况下才能认为某个value被选定呢？ 问题描述 假设有一组可以提出提案的进程集合，那么对于一个一致性算法需要保证以下几点： 在这些被提出的提案中，只有一个提案会被选定 如果没有提案被提出，就不应该有被选定的提案 当一个提案被选定后，那么所有进程都应该能学习（learn）到这个被选定的value 推导过程 最简单的方案，只有一个Acceptor。 多个Acceptor 提出假设，从假设得到的约束提交 上面是因为“一个提案只要被一个Acceptor接受，则该提案的value就被选定”才导致出现不一致的问题。因此，我们需要加一个规定： 规定：一个提案被选定需要过半数以上的Acceptor接受 上面的规定又暗示：一个Acceptor必须能够接受不止一个提案！ 不然可能导致最终没有value被选定。 所以在这种情况下，我们使用一个全局的编号来标识每一个Acceptor批准的提案，当一个具有某value值的提案被半数以上Acceptor批准后，就认为该value被选定了，此时也认为该提案被选定了。 但是强调下，提案和value不是同一个概念，提案=提案编号+value。 根据上面的内容，我们现在虽然允许多个提案被选定，但必须保证所有被选定的提案都具有相同的value值，否则又会出现不一致。 于是有了下面的约束： P2：如果某个value为v的提案被选定了，那么每个编号更高的被选定提案的value必须也是v。 一个提案只有被Acceptor接受才可能被选定，因此我们可以把P2约束改写成对Acceptor接受的提案的约束P2a。 P2a：如果某个value为v的提案被选定了，那么每个编号更高的被Acceptor接受的提案的value必须也是v。 只要满足了P2a，就能满足P2。 上图会制造一个矛盾。虽然过半数Acceptor认为V1被选定，但是宕机恢复的Acceptor1接受了Proposer1提出的编号更新的提案的V2。 需要对P2a约束进行强化！ P2a是对Acceptor接受的提案约束，但其实提案是Proposer提出来的，所以我们可以对Proposer提出的提案进行约束。得到P2b： P2b：如果某个value为v的提案被选定，那么之后任何Proposer提出的编号更高的提案的value必须也是v。 由P2b可以推出P2a进而推出P2。 那么如何达到P2b的约束呢？ 主要满足P2C即可： Proposer生产提案 Acceptor接受提案 P1a：一个Acceptor只要尚未响应过任何编号大于N的Prepare请求，那么他就可以接受这个编号为N的提案。 算法优化 如果Acceptor收到一个编号为N的Prepare请求，在此之前他已经响应过编号大于N的Prepare请求。根据P1a，该Acceptor不可能接受编号为N的提案。因此，该Acceptor可以忽略编号为N的Prepare请求。 Paxos算法描述 Leaner学习被选定的value 上面介绍了如何来选定一个提案，下面看看如何让Leaner获取提案，大体有三种方案 如何保证Paxos算法的活性 活性：最终一定会发生的事情：最终一定要选定value 总结： 分布式理论：一致性算法Raft 什么是Raft算法 Raft是一种为了管理复制日志的一致性算法。 Raft将一致性算法分解成几个关键模块，领导人选举、日志复制和安全性 通过实施一个更强的一致性来减少需要考虑的状态的数量。 Raft算法分为两个阶段，首先是选举过程，然后在选举出来的领导人带领下进行正常操作，比如日志复制。 领导人选举 Raft通过选举一个领导人，然后给予他全部的管理复制日志的责任来实现一致性。 在Raft中，任何时候一个服务器都可以扮演下面的角色之一： 领导者：处理客户端交互，日志复制等操作，一般一次只有一个领导者 候选者：候选者就是选举过程中提名自己的实体，一旦选举成功，则成为领导者 跟随者：类似选民，完全被动的角色，这样的服务器等待被通知投票 而影响他们身份变化的则是选举。 Raft使用心跳机制来触发选举。 当server启动时，初始状态都是follower。每一个server都有一个定时器，超时时间为election timeout(一般为150-300ms)，如果某server没有超时的情况下收到来自领导者或者候选者的任何消息，定时器重启；如果超时，它就开始一次选举。 下面用图示展示这个过程： 任何一个服务器都可以成为候选者，它向其他服务器（选民）发出选举自己的请求，如图 其他服务器同意了，回复OK指令，如图所示。 此时如果有一个Follower服务器宕机，没有收到请求选举的要求，则只要达到半数以上的票数，候选人还是可以成为领导者。 这样，这个候选者就成为领导者，它可以向选民发出要执行具体操作的指令，比如进行日志复制。 而如果领导者宕机，会引发新的选举，所以，整个集群在选举和正常运行两个状态之间切换，具体如下图： 从上图可以看出，选举和正常运行之间切换，但请注意，上图中的term3有一个地方，后面没有跟着正常阶段，为什么呢？ 答：当一次选举失败（比如正巧每个人都透了自己），就执行一次加时赛，每个server会在一个随机的时间重新投票，这样就能保证不冲突了。所以，当term3选举失败，等了几十毫秒，执行term4选举，并成功选举出领导人。 接着，领导者周期性的向所有跟随者发送心跳包来维持自己的权威。 如果一个跟随者在一段时间内没有收到任何信息，也就是超时，那么他就会认为系统中没有可用的领导者，并且发起选举，以选出新的领导者。 要开始一次选举过程，跟随者要增加自己的当期任期号并转换到候选人状态。然后请求其他服务器为自己投票。那么会产生3种结果： 自己成功当选 其他服务器成为领导者 僵住，没有任何一个人成为领导者 注意： 每一个server最多在一个任期内投出一张选票（有任期号约束），先到先得。 要求最多只能有一个人赢的选票。 一旦成功，立即成为领导人，然后广播所有服务器停止投票阻止新的领导者产生。 僵住怎么办？raft通过使用随机选举超时时间方法将服务器打散投票。每个候选人在僵住的时候会随机从一个时间开始重新选举。 以上，就是Raft所有关于领导选举的策略。 日志复制（保证数据一致性） Leader选出后，就开始接收客户端请求。Leader把请求作为日志条目加入到它的日志中，然后并行的向其他服务器发起AppendEntries RPC复制日志条目。当这条日志被复制到大多数服务器上，Leader将这条日志应用到它的状态机并向客户端返回执行结果。 下图表示了当一个客户端发送一个请求给领导者，随后领导者复制给跟随者的整个过程。 4个步骤： 客户端的每一个请求都包含被复制状态机执行的指令 leader把这个指令作为一条新的日志添加到日志中，然后并行发起RPC给其他服务器，让他们复制这条信息 跟随者响应ACK，如果follower宕机或者运行缓慢或者丢包，leader会不断重试，直到所有的follower最终都复制了所有的日志条目。 通知所有Follower提交日志，同时领导人提交这条日志到自己的状态机中，并返回给客户端。 可以看到，直到第四步骤，整个事务才会达成。中间任何一个步骤发生故障，都不会影响日志的一致性。 分布式系统设计策略 分布式系统本质是通过将低廉的硬件攒在一起以获得更好的吞吐量、性能以及可用性等。 在分布式环境下，有几个问题是普遍关心的，我们称之为设计策略： 如何检测当前节点还活着？ 如何保障高可用 容错处理 负载均衡 心跳检测 心跳，就是以固定的频率向其他节点汇报当前节点状态的方式。收到心跳，一般可以认为一个节点和现在的网络拓扑是良好的。当然，心跳汇报时，一般也会携带一些附加的状态、元数据信息，以便管理。 心跳不是万能的，收到心跳可以确认节点正常，但是收不到心跳也不能认为该节点就已经宣告&quot;死亡&quot;。此时，可以通过一些方法帮助Server做决定：周期检测心跳机制、累计失效检测机制。 周期检测心跳机制 Server端每间隔t秒向Node集群发起监测请求，设定超时时间，如果超过超过时间，则判断“死亡”。 累计失效检测机制 在周期监测心跳机制基础上，统计一定周期内节点的返回情况（包括超时及正确返回），以计算节点的死亡概率。另外，对于宣告“濒临死亡”的节点可以发起有限次数的重试，以作进一步判断。 高可用设计 经过设计来减少系统不能提供服务的时间。 系统高可用性常用设计模式包括三种：主备（Master-Slave）、互备（Active-Active）和集群（Cluster）模式。 容错性 容错的处理是保障分布式环境下相应系统的高可用或者健壮性，一个典型的案例就是对于缓存穿透问题的解决方案。 具体看个例子，如图所示： 如果我们查询的某一数据在缓存中一直不存在，就会造成每一次请求都查询DB，这样缓存就失去了意义，在流量大时，或者有人恶意攻击，如频繁发起id为-1的条件进行查询，可能DB就挂了。 那这种问题有什么好的解决办法吗？ 一种方法可以缓存不存在的值，比如，key=&quot;null&quot;。 负载均衡 关键在于使用多台集群服务器共同分担计算任务，把网络请求及计算分配到集群可用的不同服务器节点上，从而达到高可用性及较好的用户操作体验。 分布式架构网络通信 Java领域通信的技术，有RMI、ESB、Hession、SOAP和JMS等，它们背后到底是基于什么原理实现的呢？ 基本原理 网络通信就是将流从一台计算机传输到另一台计算机，基于传输协议和网络IO来实现。 传输协议：TCP、UDP 网络IO：bio、nio、aio 什么是RPC RPC全称为remote procedure call，即远程过程调用。 借助RPC可以做到像本地调用一样调用远程服务，是一种进程间的通信方式。 RPC本身不是具体的技术，是整个网络远程调用过程。 RPC架构 核心组件 客户端（Client），服务的调用方 客户端存根（Client Stub），存放服务端端地址消息，再将客户端的请求参数打包成网络消息，然后通过网络远程发送给服务方。 服务端（Server），真正的服务提供者。 服务端存根（Server Stub），接收客户端发送过来的消息，将消息解包，并调用本地的方法。 对于RPC框架而言，核心模块就是通讯和序列化。 RMI Remote Method Invocation，是Java原生支持的远程调用，才用JRMP作为通信协议。主要用于不同虚拟机间的通信。可以理解为一个虚拟机上的对象，调用另一个虚拟机上的对象。 核心概念 以一个案例来讲解RMI的使用 案例步骤 代码实现 其中有一个引用对象作为参数 服务端 客户端 实现原理 BIO、NIO、AIO 以内存为目标，数据进内存叫IN，出内存叫OUT 同步和异步 不能光从字母意思了解，要从分布式的角度思考。 同步异步关注的是消息通信机制。 同步： 异步： 阻塞和非阻塞 BIO NIO AIO Netty ","link":"https://xinrong2019.github.io/post/fen-bu-shi-ji-chu-li-lun-ren-zhi/"},{"title":"Zookeeper深度实践","content":"Zookeeper TOC [TOC] 分布式系统之间如何协作，信息同步和共享。 通过网络进行信息共享 通过共享存储 Zookeeper通过对节点的更新订阅，通知，达到信息共享。 Zookeeper的基本概念 开源的分布式协调服务。可以基于它实现数据订阅发布、负载均衡、命名服务、集群管理、分布式锁和分布式队列等功能。 基本概念 集群角色 Leader：选举产生，Leader为客户端提供读写服务 Follower：提供读服务 Observer：提供读服务，不参与Leader选举，不参与写操作过半写成功策略，可以在不影响写性能等情况下提升集群的性能 会话（session） 客户端会话，一个客户端连接是指客户端和服务端之间的一个TCP长连接 Zookeeper对外的服务端口默认为2181 客户端启动的时候，首先会与服务器建立一个TCP长连接，从第一次连接建立开始，客户 端的生命周期也开始了，通过这个连接，客户端能够心跳检测与服务端保持有效的会话， 也能够向Zookeeper服务器发送请求并接受响应， 同时还能通过该连接接受来自服务器的Watch事件通知。 数据节点（Znode） 节点的两种含义：机器节点，数据单元。 Zookeeper将所有数据存储在内存中，数据模型是一棵树，由斜杠（/）进行分割的路径，就是一个Znode，例如/app/path1。每个ZNode上都会保存自己的数据内容，同时还会保存一系列属性信息。 版本 对于每个ZNode，Zookeeper都会为期维护一个叫作Stat的数据结构，Stat记录了这个ZNode的三个版本，分别是 version(当前ZNode版本) cversion(当前ZNode子节点的版本) aversion(当前ZNode的ACL版本) Watcher（事件监听器） Zookeeper允许用户在指定节点上注册一些Watcher，并且在一些特定事件触发的时候，Zookeeper服务端会将事件通知到感兴趣的客户端，该机制是Zookeeper实现分布式协调服务的重要特性。 ACL Access Control Lists，权限控制，其定义了五种权限： CREATE，创建自节点的权限 READ，获取节点数据和子节点列表的权限 WRITE，更新节点数据的权限 DELETE，删除子节点的权限 ADMIN，设置节点ACL的权限 其中需要注意的是，CREATE和DELETE这两种权限都是针对子节点的权限控制 Zookeeper环境等搭建 搭建方式 单机模式 下载 解压 tar -xzvf zookeeper-3.6.0.tar.gz 进入目录，创建data文件夹 cd zookeeper-3.6.0 mkdir data 修改配置文件 dataDir='你的zookeeper存放目录'/data 启动Zookeeper服务 进入bin目录，启动服务输入命令 ./zkServer.sh start 关闭服务命令 ./zkServer.sh stop 查看状态 ./zkServer.sh status 伪集群模式 注意事项： clientPort不同， dataDir不同， dataLogDir不同， 还要在dataDir所对应的目录中创建myid文件来指定对应Zookeeper服务器的实例 server.X这个数字就是对应，data/myid中的数字。在3个server的myid文件中分别写入了1,2,3那么每个server中的zoo.cfg都配了server.1 server.2 server.3就行了。因为在同一台机器上，后面连着的2个端口，3个server都不要一样，否则会端口冲突。 下载 解压，创建zkcluster目录 mkdir zkcluster 改变名称 mv zookeeper-3.6.0 zookeeper01 复制并改名 cp -r zookeeper01/ zookeeper02 cp -r zookeeper01/ zookeeper03 分别在三个zookeeper根目录下创建data和logs目录 mkdir data cd data mkdir logs 修改配置文件名称 cd conf mv zoo.sample.cfg zoo.cfg 配置每一个ZK的dataDir（zoo.cfg）clientPort分别为2181,2182,2183 clientPort=2181 dataDir=/zkcluster/zookeeper01/data dataLogDir=/zkcluster/zookeeper01/data/logs clientPort=2182 dataDir=/zkcluster/zookeeper02/data dataLogDir=/zkcluster/zookeeper02/data/logs clientPort=2183 dataDir=/zkcluster/zookeeper03/data dataLogDir=/zkcluster/zookeeper03/data/logs 配置集群 在每个zookeeper的data目录下创建一个myid文件，内容分别是1,2,3。这个文件就是记录每个服务器的ID。 touch myid 在每个zookeeper的zoo.cfg文件中配置客户端访问端口和集群服务器IP列表 server.1=192.168.101.25:2181:3881 server.2=192.168.101.25:2182:3882 server.3=192.168.101.25:2183:3882 #server.服务器ID=服务器IP地址:服务器之间通信端口:服务器之间投票选举端口 启动集群 Zookeeper的基本使用 Zookeeper系统模型 Zookeeper数据模型ZNode ZNode的类型 持久性节点（Persistent） 临时性节点（Ephemeral） 顺序性节点（Sequential） 在开发中，创建节点的时候通过组合可以生成以下四种节点类型：持久节点、持久顺序节点、临时节点、临时顺序节点。 持久节点：节点被创建后，会一直存在服务器，直到服务器操作主动删除 持久顺序节点：持久性和上面一样，顺序特性，就是节点在创建的时候，在节点名后面添加一个数字后缀，来表示其顺序。 临时节点：会被自动清理的节点，客户端会话结束，节点就会被删除。临时节点不能创建子节点。 临时顺序节点：有顺序的临时节点 事务ID 狭义上的事务是指数据库事务，一般包含了一系列对数据库有序的读写，这些数据库事务具有ACID特性，即原子性、一致性、隔离性、持久性。 在Zookeeper中，事务是指能够改变Zookeeper服务器状态的操作，也称为事务操作或更新操作，一般包括数据节点创建与删除、数据节点内容更新等操作。对于每一个事务请求，Zookeeper都会为其分配一个全局唯一的事务ID，用ZXID来表示，通常是一个64位的数字。每一个ZXID对应一次更新操作，从这些ZXID中可以间接地识别出Zookeeper处理这些更新操作请求的全局顺心。 ZNode的状态信息 整个ZNode节点内容包括两部分：节点数据内容和节点状态信息。图中quota是数据内容，其他的属于状态信息。这些信息的含义是： cZxid就是create zxid，表示节点被创建时的事务id。 crime就是create time，表示节点创建时间。 mzxid就是modified zxid，表示节点最后一次被修改时的事务id。 mtime就是modified time，表示节点最后一次被修改的事件。 pzxid表示该节点的子节点列表最后一次被修改时的事务ID。只有子节点列表变更才会更新pZxid，子节点内容变更不会更新。 cversion，表示子节点的版本号。 dataVersion表示内容版本号 aclVersion标识acl版本 ephemeralOwner表示创建该临时节点时的会话sessionID，如果持久性节点那么值为0. dataLength表示数据长度 numChildren表示直系子节点数。 Watcher--数据变更通知 ACL--保障数据安全 Zookeeper命令行操作 创建节点 读取节点 更新节点 删除节点 Zookeeper的api使用 建立会话 创建节点 获取节点数据 修改节点数据 删除节点 Zookeeper开源客户端 ZKClient Curator 作业题： Zookeeper应用场景 数据发布/订阅 可以实现配置信息的集中式管理和数据的动态更新。 发布订阅系统一般有两种设计模式，分别是推模式和拉模式。 Zookeeper采用推拉结合的方式： 客户端向服务端注册自己需要关注的节点，一旦该节点的数据发生变更，那么服务端就会向相应的客户端发送Watcher事件通知，客户端接收到这个消息通知后，需要主动到服务端获取最新的数据。 使用Zookeeper来进行配置集中管理，一般流程： 应用在启动的时候主动到Zookeeper服务端上进行一次配置信息的获取，同时，在指定节点上注册一个Watcher监听，这样一来，一旦配置信息变更，服务端会实时通知所有订阅的客户端，从而达到实时获取最新配置信息的目的。 机器列表信息、运行时的开关配置、数据库配置信息等可以在这个场景实现。 命名服务 什么是命名服务，客户端根据指定名字来获取资源的实体、服务地址和提供者的信息。 命名服务一要名字有意义，二要全局唯一。 为什么不用uuid 长度过长 含义不明 如何使用Zookeeper实现一套分布式全局唯一ID的分配机制。 使用到的Zookeeper特性是：顺序节点，每一个数据节点都能够维护一份子节点的顺序序列，当客户端对其创建一个顺序子节点的时候，Zookeeper会自动以后缀的形式在其子节点上添加一个序号。 全局唯一ID生成的Zookeeper节点示意图。 对于一个任务列表的主键，使用Zookeeper生成唯一ID的基本步骤： 所有客户端都会根据自己的任务类型，在指定类型的任务下面通过调用create接口创建一个顺序节点，例如创建&quot;job-&quot;节点 节点创建完毕后，create接口会返回一个完整的节点名，例如&quot;job-00000000003&quot; 客户端拿到这个返回值后，拼接上type类型，例如&quot;type2-job-00000000003&quot;，这个就可以作为一个全局唯一的ID了。 集群管理 包括集群监控和集群控制。 集群监控：侧重对集群运行时状态的收集 集群管理：对集群进行操作与控制 Agent集群管理 大规模升级困难 统一的Agent无法满足多样的需求 对机器的物理状态监控可以满足，但无法满足业务状态的监控。 分布式消息中间件中，监控到每个消费者对消息的消费状态；分布式任务调度系统中，需要对每个机器上任务的执行情况进行监控 编程语言的多样性 Zookeeper的两大特性 客户端如果对Zookeeper的数据节点注册Watcher监听，那么当该数据节点的内容或其子节点列表发生变更时，Zookeeper服务器就会向客户端发送变更通知。 对在Zookeeper上创建的临时节点，一旦客户端与服务器之间的会话失效，那么临时节点也会被自动删除。 利用其两大特性，可以实现集群机器的存活监控，若监控系统在/clusterServers节点上注册一个Watcher监听，一旦进行动态添加机器的操作，就会在/clusterServers节点下创建一个临时节点：/clusterServers/[HostName]，这样，监控系统就能够实时监测机器的变动情况。 分布式日志收集系统 做什么的：收集分布在不同机器上的系统日志。 日志源机器（需要收集日志的机器）分为多个组别，每个组别对应一个收集器。 问题： 变化的日志源机器 变化的收集器机器 如何快速、合理、动态地为每个收集器分配对应的日志源机器？ 使用Zookeeper： 注册收集器机器 在Zookeeper上创建一个节点作为收集器的根节点，例如/logs/collector，每个收集器机器在启动的时候，都会在收集器节点下创建自己的节点，例如/logs/collector/[HostName] 任务分发 所有收集器机器都创建好对应都节点后，系统根据收集器节点下子节点的个数，将所有日志源机器分成对应的若干组，然后将分组后的（日志源）机器列表分别写到这些收集器机器创建的子节点（/logs/collector/host1）上去。这样一来，每个收集器机器都能够从自己对应的收集器节点上获取日志源机器列表，进而开始进行日志收集工作。 图中有3台收集器机器，假如日志源机器有9台，分组后，每个收集器机器需要写入三台日志源机器。 状态汇报 目的：考虑机器挂掉的可能 收集器的状态汇报机制：每个收集器机器在创建完自己的专属节点后，还需要在对应的子节点上创建一个状态子节点，收集器机器定期写入状态信息，日志系统查询状态子节点的最后更新时间来判断对应的收集器机器是否存活。 动态分配 日志系统关注/logs/collector节点下的变更。一旦有变更，机器假如或者停止，就会重新分配。 全局动态分配 出现收集器机器挂掉或者新机器加入的时候，日志系统需要根据新的收集器机器列表，立即对所有的日志源机器重新进行一次分组，然后将其分配给剩下的收集器机器。 局部动态分配 why：全局动态分配影响面比较大，风险比较大 what：小范围内进行任务的动态分配 how：每个收集器机器在汇报自己日志收集状态的同时，也会把自己的负载汇报上去。这里的负载不仅仅是CPU Load，也是对当前收集器任务执行的综合评估。 如果一个收集器机器挂了，那么日志系统就会把之前分配给这个机器的任务重新分配到那些负载较低的机器上去。同样，如果有新的收集器机器加入，会从那些负载高的机器上转移部分任务给这个新加入的机器。 两点注意事项： 节点类型的选择 由于收集器节点记录了日志源机器列表，所以不能直接使用临时节点表示每个收集器节点。需要用持久节点。在收集器节点下创建状态节点，用来记录收集器的状态 日志系统节点监听 若采用Watcher机制，那么通知的消息量的网络开销非常大，需要采用日志系统主动轮询收集器节点的策略，这样可以节省网络流量，但是存在一定的延时。 Master选举 利用Zookeeper的强一致性，能够很好保证在分布式高并发情况下，节点的创建一定能够保证全局唯一性，即Zookeeper将会保证客户端无法重复创建一个已经存在的节点。 客户端集群每天定时往Zookeeper上创建一个临时节点，例如/master_election/2020-11-11/binding。在这个过程中，只有一个客户端能够成功创建这个节点，那么这个客户端所在机器就成了Master。 其他没有创建成功的客户端，会在节点/master_election/2020-11-11上注册一个子节点变更的Watcher，用于监控当前Master机器是否存活，一旦发现Master挂了，那么其余客户端将会重新进行Master选举。 保证数据唯一性 保证Master故障后能够通知其他节点可以重新选举 分布式锁 排他锁 又称写锁或独占锁。如果当前事务获取了排他锁，只有当前事务可以对共享资源读取和更新，其他事务只能等待当前事务释放锁才能操作。 定义锁 在/exclusive-lock节点下创建临时子节点/exclusive-lock/lock。 获取锁 创建临时子节点/exclusive-lock/lock的过程就是获取锁的过程，Zookeeper可以保证多个客户端只有一个可以创建同一个节点成功。其他没有获取到锁的客户端需要到/exclusive-lock节点上注册一个子节点变更的Watcher监听，以便实时监听lock节点的变更情况 释放锁 /exclusive-lock/lock是一个临时节点，两种情况会释放锁 获取锁的客户端宕机，临时节点会自动移除 获取锁的客户端正常执行完业务，客户端主动删除临时节点。 释放锁后，其他没有获取锁的客户端会收到通知，再次发起分布式锁的获取。 共享锁 如果事务T1对数据对象O1加上了共享锁，那么当前事务只能对O1进行读取操作，其他事务也只能对这个数据对象加共享锁——直到该数据对象上的所有共享锁都被释放。 共享锁和排他锁最根本的区别在于，加上排他锁后，数据对象只对一个事务可见，而加上共享锁后，数据对所有事务都可见。 下面看看如何借助Zookeeper实现共享锁。 定义锁 通过Zookeeper上的数据节点表示锁，通过/shared_lock/[Hostname]-请求类型-序号的临时顺序节点，例如/shared_lock/host1-R-0000001，这个节点就代表一个共享锁。 获取锁 获取锁的时候，所有客户端都会到shared_lock节点下创建临时顺序节点，如果当前是读请求，就创建如/shared_lock/host1-R-0000001节点；如果是写请求，就创建例如/shared_lock/host1-W-0000002的节点。 判断读写顺序 通过Zookeeper来确定分布式读写顺序，大致分为四步 1. 创建完节点后，获取/shared_lock节点下所有子节点，并对该节点变更注册监听 2. 确定自己的节点序号在所有子节点中的顺序 3. 对于读请求：若没有比自己序号小的子节点或所有比自己序号小的子节点都是读请求，那么表明自己已经成功获取到共享锁，同时开始执行读取逻辑，若有写请求，则需要等待。对于写请求：若自己不是序号最小的子节点，那么需要等待。 4. 接收到Watcher通知后，重复步骤1. 释放锁，与与独占锁一致 羊群效应 当锁下面的竞争机器数超过10，很大时，由于是在/shared_lock上注册的监听，如果同一时间有多个节点对应的客户端完成事务或者事务中断引起节点消失，Zookeeper服务器就会在短时间内向其余客户端发送大量的事件通知。这就是羊群效应。 没有找准客户端真正的关注点。判断自己是否是所有子节点中序号最小的。每个节点对应的客户端只需要关注比自己序号小的那个相关节点的变更情况就可以了，而不是关注全局的子列表变更情况。 客户端调用create接口创建类似于/shared_lock/[Hostname]-请求类型-序号的临时顺序节点 客户端调用getChildren接口获取所有已经创建的子节点列表（不注册任何Watcher） 如果无法获取共享锁，就调用exsit接口来对比自己小的节点注册Watcher。对于读请求：向比自己序号小的最后一个写请求节点注册Watcher监听。对于写请求：向比自己序号小的最后一个节点注册Watcher监听。 等待Watcher通知，继续进入步骤2 如何选择：根据项目的实际情况选择两种方式的一种。 分布式队列 FIFO先进先出队列模型 等待队列元素聚集后统一安排处理执行的Barrier模型 FIFO队列类似于一个全写的共享锁模型，思路：所有客户端都会到/queue_fifo这个节点下创建一个临时顺序节点，例如/queue_fifo/host1-0000001。 创建完节点后，根据如下4个步骤来确定执行顺序 通过调用getChildren接口来获取/queue_fifo节点的所有子节点，即获取队列中所有的元素 确定自己的节点序号在所有子节点中的顺序 如果自己的序号不是最小，那么需要等待，同时向比自己序号小的最后一个节点注册Watcher监听 接收到Watcher通知后，重复步骤1. Barrier：分布式屏障 场景：大规模并行计算的应用，最终的合并计算需要基于很多并行计算的子结果来进行。 思路：开始时，/queue_fifo节点是一个已经存在的默认节点，并且将其节点的数据内容赋值一个数字n来代表Barrier值，例如n=10表示只有当/queue_fifo节点下的子节点个数达到10后，才会打开Barrier。所有的客户端都会到/queue_fifo节点下创建一个临时节点，例如/queue_fifo/host1，如图所示 创建完节点后，按照如下步骤执行 通过调用getData接口获取/queue_barrier节点的数据内容：10 通过调用getChildren接口获取/queue_barrier节点下的所有子节点，同时注册对子节点变更的Watcher监听 统计子节点的个数 如果子节点个数还不足10个，那么需要等待 接收到Watcher通知后，重复步骤2 Zookeeper深入进阶 ZAB协议 Zookeeper原子广播协议 一种支持崩溃恢复到原子广播协议 主备模式的系统架构，保证集群中各副本之间的数据一致性。使用一个单一的主进程来接收并处理客户端的所有事务请求，并采用ZAB原子广播协议，将服务器数据的状态变更以事务Proposal的形式广播到所有的副本进程中。 基于ZAB协议如何处理请求 请求由Leader处理，Leader服务器负责将一个客户端事务转化成一个事务Proposal，并将Proposal分发给集群中所有的Follower服务器，之后需要等待所有的Follower服务器反馈，只要收到超过半数的正确反馈后，Leader就会再次向所有的Follower分发commit消息，要求其将前一个Proposal提交。 ZAB协议介绍 两个基本的模式：崩溃恢复和消息广播 进入崩溃恢复模式 什么时候进入？ 启动过程，网络中断、崩溃推出或重启 进入崩溃恢复模式会进行Leader选举 什么时候退出崩溃恢复模式？ 集群中有半数以上机器与Leader同步完状态后，就退出崩溃恢复模式 状态同步：就是数据同步 进入消息广播模式 当集群中已经有过半数Follower服务器完成了与Leader服务器的状态同步，就进入消息广播模式。 当新加入一台同样遵守ZAB协议的服务器到集群中，且集群中已经有一个Leader在负责消息广播，那么加入到服务器就自觉进入数据恢复模式：找到Leader所在的服务器，并于其进行数据同步，然后一起参与到消息广播流程中去。 只有Leader服务器可以进行事务请求的处理，如果其他机器收到客户端请求后，非Leader服务器会首先将这个事务请求转发到Leader服务器。 消息广播过程和崩溃恢复过程 消息广播 Leader服务器会为每一个Follower服务器都各自分配一个单独的队列，然后将需要广播的事务Proposal依次放入这些队列中去，并且根据FIFO策略进行消息发送。 每一个Follower服务器在接收到这个事务Proposal之后，都会首先将其以事务日志的形式写入到本地磁盘中，并且在写入成功后反馈给Leader服务器一个Ack响应。 当Leader服务器接收到过半数Follower的Ack响应后，就会广播一个Commit消息给所有Follower服务器以通知其进行事务提交，同时Leader自身也会完成对事务的提交。 而每一个Follower服务器在接收到Commit消息后，也会完成事务的提交。 崩溃恢复 崩溃恢复需要考虑什么？ 恢复过程会选出一个新的Leader，需要一个高效可靠的选举算法，不仅仅Leader自身知道已经被选举为Leader，还需要集群中其他机器也能够快速的感知到选举产生出来的新Leader机器。 需要确保那些已经在Leader服务器上提交的事务最终被所有服务器都提交 需要确保丢弃那些只在Leader服务器上被提出的事务 小结：Leader选举算法需要确保提交已经被Leader提交的事务，同时丢弃已经被跳过的事务。 让具有最高事务编号的Proposal的机器成为Leader（行文到这里，依然不是很清楚怎么做到的崩溃恢复，只知道一个结论） 数据同步过程 Leader确认事务日志中的所有Proposal是否都已经被集群中过半数的机器提交了，即是否完成数据同步。 具体的过程：Leader服务器为每一个Follower服务器准备一个队列，并将那些没有被各Follower服务器同步的事务以Propoal的形式逐个发送给Follower服务器，并在每一个Proposal消息后面，紧接着发送一个Commit消息，以表示该事务已经被提交。 等到Follower服务器将所有尚未同步的事务都从Leader服务器同步过来，并成功应用到本地数据库后，Leader服务器就会将该Follower服务器加入到真正可用的Follower列表中，并开始之后的其他流程。 运行状态分析 在ZAB协议的设计中，每个进程都有可能处于如下三种状态之一 LOOKING：进程初始状态是LOOKING，Leader选举阶段其余Follower进程也是LOOKING状态 FOLLOWING：Follower服务器和Leader服务器保持同步状态 LEADING：Leader服务器作为主进程领导状态 Leader能够在超时时间内正常收到过半心跳检测，或者TCP连接断开，那么Leader会放弃当前周期的领导，并转换为LOOKING状态，其他Follower会选择放弃这个Leader，同时转换到LOOING状态，之后会进行新一轮的Leader选举。 ZAB与Paxos的联系和区别 联系 都有Leader和Follower的角色 Leader进程都会等待过半数Follower作出正确的反馈后，才会将一个提议进行提交 都有一个表示当前Leader周期的值，ZAB叫epoch，Paxos叫Ballot 区别 Paxos中，新选举产生的Leader会进行两阶段的工作，读阶段，新的主进程和其他进程通信来收集主进程提出的提议，并将他们提交，第二阶段写，当前主进程开始提出自己的提议。 ZAB协议在Paxos基础上添加了同步阶段，此时，新的Leader会确保存在过半数的Follower已经提交了之前的Leader周期中的所有事务Proposal。 主要区别是因为他们的设计目标不同，ZAB主要用于构建一个高可用的分布式数据主备系统，Paxos用于构建一个分布式的一致性状态机系统。 服务器角色 Leader主要工作 事务请求的唯一调度者和处理者，保证集群事务处理的顺序性 集群内部各服务器的调度者 Leader请求处理链 Follower主要工作 处理客户端非事务请求（读取请求），转发事务请求给leader服务器 参与事务请求Proposal的投票 参与Leader选举的投票 Follower请求的处理链 Observer 观察Zookeeper集群的最新状态变化，并将这些状态变更同步过来。 对于非事务请求（读取），可以处理，对于事务请求，转发给Leader处理。 不参与任何形式的投票，包括事务请求的Proposal投票和Leader选举投票。 通常用于在不影响集群事务处理能力的前提下提升集群的非事务处理能力。 Observer处理请求链 服务器启动 服务器整体架构 Zookeeper服务器启动步骤 配置文件解析 初始化数据管理器 初始化网络IO管理器 数据恢复 对外服务 单机版服务器启动 集群服务器启动 Leader选举 当Zookeeper集群中的一台服务器出现以下两种情况之一时，需要进入Leader选举： 服务器初始化启动 服务器运行期间无法和Leader保持连接 启动时的选举 每个server发出一个投票，投票用(myid,ZXID)表示 接受来自各个服务器的投票 处理投票：先比较ZXID，大的作为Leader，否则再比较myid。 统计投票 改变服务器状态 运行时的选举 变更状态 每个server会发出一个投票 接收来自各个服务器的投票，与启动时过程相同 处理投票 统计投票 改变服务器状态 Zookeeper源码分析 源码环境搭建 将准备好的zookeeper-release-3.5.4导入idea中 启动服务器端 运行主类org.apache.zookeeper.server.ZookeeperServerMain，将zoo.cfg的完整路径配置在Program arguments。 在VM options配置，即指定到conf目录下的log4j.properties： -Dlog4j.configuration=file:/path-to-zk/conf/log4j.properties 运行输出日志如下 可以得知单机版启动成功，单机版服务端地址为127.0.0.1:2182 运行客户端 客户端启动类为org.apache.zookeeper.ZooKeeperMain，进行如下配置： 即客户端连接127.0.0.1:2182，获取节点/lg的信息。 单机模式服务端启动 Leader选举 Election接口 FastLeaderElection 默认选举策略 重要的内部类： Notification ToSend Messenger Messenger的内部类： WorkerReceiver：选票接收器，不断地从QuorumCnxManager获取其他服务器发来的选举消息，并将其转成一个选票，然后保存到recvqueue中，如果接收过程中，发现该外部选票轮次小于当前服务器的，忽略该外部投票，同时立即发送自己的内部投票。将QuorumCnxManager的Message转化为FastLeaderElection的Notification。 WorkerSender：选票发送器，不断的从sendQueue中获取待发送的选票，并将其传递到底层的QuorumCnxManager中，过程是将FastLeaderElection的ToSend转化为QuorumCnxManager的Message。 类的属性 类的构造函数 会启动WorkerSender和WorkerReceiver，并设置为守护线程。 集群模式服务端 ","link":"https://xinrong2019.github.io/post/zookeeper-shen-du-shi-jian/"},{"title":"Java基础知识","content":"Java基础知识 TOC [TOC] 目标 以面试为导向，知识点要全面，查漏补缺。突出重点。 学完后有一个基本的认知是什么，对于重点内容要知道为什么，了解实现原理。 基础 强引用、弱引用、虚引用、软引用 参见Java中的四种引用类型 背景 简单了解即可。和引用关联的知识点，不得不提对象的生命周期，再远点就是GC如何管理对象的生命周期的。这里假设读者已经知道这些内容了。 引用强度认知： 引用强度从强到弱分别为：强引用、软引用、弱引用、虚引用。 强引用 StrongReference 默认引用形式，使用时不需要显示定义。任何通过强引用所使用的对象不管系统资源有多紧张，Java GC都不会主动回收具有强引用的对象。 弱引用 WeakReference 如果一个对象只具有弱引用，无论内存充足与否，Java GC后对象如果只有弱引用将会被自动回收。 软引用 SoftReference 软引用和弱引用的特性基本一致， 主要的区别在于软引用在内存不足时才会被回收。如果一个对象只具有软引用，Java GC在内存充足的时候不会回收它，内存不足时才会被回收。 虚引用 PhantomReference 从PhantomReference类的源代码可以知道，它的get()方法无论何时返回的都只会是null。所以单独使用虚引用时，没有什么意义，需要和引用队列ReferenceQueue类联合使用。当执行Java GC时如果一个对象只有虚引用，就会把这个对象加入到与之关联的ReferenceQueue中。 文字干巴巴，去看原文代码 小结 强引用是 Java 的默认引用形式，使用时不需要显示定义，是我们平时最常使用到的引用方式。不管系统资源有多紧张，Java GC都不会主动回收具有强引用的对象。 弱引用和软引用一般在引用对象为非必需对象的时候使用。它们的区别是被弱引用关联的对象在垃圾回收时总是会被回收，被软引用关联的对象只有在内存不足时才会被回收。 虚引用的get()方法获取的永远是null，无法获取对象实例。Java GC会把虚引用的对象放到引用队列里面。可用来在对象被回收时做额外的一些资源清理或事物回滚等处理。 由于无法从虚引获取到引用对象的实例。它的使用情况比较特别，所以这里不把虚引用放入表格进行对比。这里对强引用、弱引用、软引用进行对比： final关键字的作用 (方法、变量、类) 参见final 关键字 应用在方法、变量、类上的作用不赘述，已经掌握，只查漏补缺 被final修饰的方法，不可以被重写。但是不影响本类的重载以及重载函数的重写。 final成员变量必须在声明的时候初始化或者在构造器中初始化，否则就会报编译错误。 不可变的类是天然无状态的，线程安全的。 如何写一个不可变类呢？ 将类声明为final，所以它不能被继承 将所有的成员声明为私有的，这样就不允许直接访问这些成员 对变量不要提供setter方法 将所有可变的成员声明为final，这样只能对它们赋值一次 通过构造器初始化所有成员，进行深拷贝(deep copy) 在getter方法中，不要直接返回对象本身，而是克隆对象，并返回对象的拷贝 具体可参考String和Integer等的写法 和static一起使用 对于静态final变量，我们可以直接初始化，或者使用静态代码块。而不可以使用构造函数或者构造代码块。 因为static要求在编译期间就确定值，然后放入静态区。而构造函数和构造代码块发生在运行期间。 final和private 类中所有的private方法都隐式的指定为final的，由于无法取用private方法，所以也就无法覆盖它，可以对private方法添加final修饰符，但并没有添加任何额外意义。（了解即可） 泛型、泛型继承、泛型擦除 泛型擦除分析 泛型擦除是什么，会带来什么问题？ 泛型擦除 使用泛型的话,运行期把对象都是当成object来处理的,所以可以运用的方法都是object的方法,且在赋值操作时,编译器会自动强转为指定泛型类型,另一个好处就是在编译期更早的发现向下转型可能出现的错误,因为向下转型是不安全的. 带来什么样的问题？ 在运行时反编译添加不同类型的数据，数据错误，代码不报错。 泛型继承，带上界的擦除 当使用上界时泛型擦除擦除为上界的类型,因此也就解释了为啥可以调用上界的方法.并且会和赋值操作的时候一样自动强转为对应的泛型,向上转型,为安全的操作。 带通配符的上界 带通配符的下界 总结 泛型的出现是为了减少向下转型出现的错误,泛型的目的是尽可能的在编译器发现转型时的错误,所以对于不安全的操作(编译器认为的)会绝对禁止,存储进去的都是绝对安全(编译器认为的)的数据. jdk ServiceLoader 参见Java SPI机制：ServiceLoader实现原理及应用剖析 SPI，全称Service Provider Interfaces，服务提供接口。可以用来解耦服务的实现和使用，增强应用的可扩展性。 JDK中，基于SPI的思想，提供了默认具体的实现，ServiceLoader。利用JDK自带的ServiceLoader，可以轻松实现面向服务的注册与发现，完成服务提供与使用的解耦。 使用 外部使用时，往往通过load(Class service, ClassLoader loader)或load(Class service)调用，最后都是在reload方法中创建了LazyIterator对象，LazyIterator是ServiceLoader的内部类，实现了Iterator接口，其作用是一个懒加载的迭代器，在hasNextService方法中，完成了对位于META-INF/services/目录下的配置文件的解析，并在nextService方法中，完成了对具体实现类的实例化。 META-INF/services/，是ServiceLoader中约定的接口与实现类的关系配置目录，文件名是接口全限定类名，内容是接口对应的具体实现类，如果有多个实现类，分别将不同的实现类都分别作为每一行去配置。解析过程中，通过LinkedHashMap&lt;String,S&gt;数据结构的providers，将已经发现了的接口实现类进行了缓存，并对外提供的iterator()方法，方便外部遍历。 总结 基于服务提供与发现的思想，系统自带的ServiceLoader以及基于此思想基础上的演化形式，被广泛的使用到实际的项目中。本质上，通过服务接口约定、服务注册与服务发现，完成将服务提供方与服务使用方的解耦，大大扩展了系统的可扩展性。服务注册的本质，是将服务接口与具体服务实现的映射关系注册到系统或特定实现中。服务发现的过程，本质上是向系统或特定实现去匹配对应的具体实现类，但在写法上是基于接口的编程方式，因为服务使用方和服务提供方彼此都是透明与未感知的。基于SPI思想的ServiceLoader实现及演化，在项目的组件化，或实现扩展性功能，甚至完成具有可插拔能力的插件化模块时，往往都被广泛使用到。 LinkedList、LinkedHashMap、LRU LinkedList 底层数据结构 设计模式 装饰者模式 代理模式 责任链模式 工厂模式 适配器模式 建造者模式 单例模式 模板模式 观察者模式 关于精度损失问题：int、long 超过最大值 关于注解：元注解的种类、继承java.lang.Annotation、注解的基础类型、注解的常用方法 关于ClassLoader，类加载器，双亲委派模型 Spring Boot 如何自定义starter 引入spring-boot-autoconfigure依赖 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-autoconfigure&lt;/artifactId&gt; &lt;version&gt;2.2.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; 编写JavaBean @EnableConfigurationProperties(SimpleBean.class) @ConfigurationProperties(prefix = &quot;simplebean&quot;) public class SimpleBean { private int id; private String name; public int getId() { return id; } public void setId(int id) { this.id = id; } public String getName() { return name; } public void setName(String name) { this.name = name; } @Override public String toString() { return &quot;SimpleBean{&quot; + &quot;id=&quot; + id + &quot;, name='&quot; + name + '\\'' + '}'; } } 编写配置类 @Configuration @ConditionalOnClass//当类路径下有指定当类自动配置 public class MyAutoConfiguration { static { System.out.println(&quot;MyAutoConfiguration init....&quot;); } @Bean public SimpleBean simpleBean() { return new SimpleBean(); } } 在resources下创建/META-INF/spring.fatories文件 在该文件中配置自己的自动配置类，多个配置用逗号隔开 org.springframework.boot.autoconfigure.EnableAutoConfiguration=\\ com.lagou.config.MyAutoConfiguration Spring Boot启动流程 @SpringBootApplication @SpringBootApplication注解里定义了3个事情： @SpringBootConfiguration声明使用该注解的类是配置类，由Spring IOC容器托管。 @EnableAutoConfiguration声明开启自动配置。 @ComponentScan声明包扫描的范围。 @Target(ElementType.TYPE) @Retention(RetentionPolicy.RUNTIME) @Documented @Inherited @SpringBootConfiguration @EnableAutoConfiguration @ComponentScan(excludeFilters = { @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class), @Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) }) public @interface SpringBootApplication { @SpringBootConfiguration @SpringBootConfiguration注解内部有一个核心注解@Configuration，表示当前类是一个配置类，并可以被组建扫描器扫描。 @EnableAutoConfiguration @EnableAutoConfiguration主要干了两件事： @Target(ElementType.TYPE) @Retention(RetentionPolicy.RUNTIME) @Documented @Inherited @AutoConfigurationPackage @Import(AutoConfigurationImportSelector.class) public @interface EnableAutoConfiguration { @AutoConfigurationPackage自动配置包 @Import(AutoConfigurationImportSelector.class)自动配置类扫描导入 源码剖析 自动配置入口AbstractApplicationContext.invokeBeanFactoryPostProcessors 自动配置关键类方法AutoConfigurationImportSelector.getAutoConfigurationEntry 具体细节： 在getCandidateConfigurations方法中调用SpringFactoriesLoader.loadFactoryNames， 从类路径下的META-INF/spring.factories文件中加载自动配置类 小结 @EnableAutoConfiguration就是从classpath中搜寻META-INF/spring.factories配置文件，并将其中的org.springframework.boot.autoconfigure.EnableAutoConfiguration对应的配置项通过反射实例化对应的标注了@Configuration的JavaConfig形式的配置类，并加载到IOC容器中。 @ComponentScan注解 扫描启动类所在包及其子包下的类，扫描过程中由@AutoConfigurationPackage注解进行解析，从而得到启动类所在包的具体位置。 总结： @SpringBootApplication注解主要是3个注解的组合注解。 执行原理 SpringApplication实例的初始化创建 public SpringApplication(ResourceLoader resourceLoader, Class&lt;?&gt;... primarySources) { this.resourceLoader = resourceLoader; Assert.notNull(primarySources, &quot;PrimarySources must not be null&quot;); this.primarySources = new LinkedHashSet&lt;&gt;(Arrays.asList(primarySources)); this.webApplicationType = WebApplicationType.deduceFromClasspath(); setInitializers((Collection) getSpringFactoriesInstances(ApplicationContextInitializer.class)); setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class)); this.mainApplicationClass = deduceMainApplicationClass(); } 项目的初始化启动 public ConfigurableApplicationContext run(String... args) { StopWatch stopWatch = new StopWatch(); stopWatch.start(); ConfigurableApplicationContext context = null; Collection&lt;SpringBootExceptionReporter&gt; exceptionReporters = new ArrayList&lt;&gt;(); configureHeadlessProperty(); //1 获取并启动监听器 SpringApplicationRunListeners listeners = getRunListeners(args); listeners.starting(); try { ApplicationArguments applicationArguments = new DefaultApplicationArguments(args); //2 准备环境 ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments); configureIgnoreBeanInfo(environment); Banner printedBanner = printBanner(environment); //3 创建Spring容器 context = createApplicationContext(); exceptionReporters = getSpringFactoriesInstances(SpringBootExceptionReporter.class, new Class[] { ConfigurableApplicationContext.class }, context); //4 Spring容器前置处理 prepareContext(context, environment, listeners, applicationArguments, printedBanner); // 5 刷新容器 refreshContext(context); //6 容器后置处理 afterRefresh(context, applicationArguments); stopWatch.stop(); if (this.logStartupInfo) { new StartupInfoLogger(this.mainApplicationClass).logStarted(getApplicationLog(), stopWatch); } //7 发出结束执行的事件 listeners.started(context); //返回容器 callRunners(context, applicationArguments); } catch (Throwable ex) { handleRunFailure(context, ex, exceptionReporters, listeners); throw new IllegalStateException(ex); } try { listeners.running(context); } catch (Throwable ex) { handleRunFailure(context, ex, exceptionReporters, null); throw new IllegalStateException(ex); } return context; } Spring IOC 什么是IOC 控制反转，管理对象的生命周期及对象之间的依赖关系 对象的创建，new的方式，改为从容器中拿。 构造器注入和set方法注入。 什么是对象的生命周期 实例化bean，设置属性值，调用BeanPostProcessor的初始化前方法，调用初始化方法，调用BeanPostProcessor的初始化后方法。 延迟加载 被修饰为lazy-init的bean ，Spring容器初始化阶段不会进行初始化，第一次进行getBean调用时，才初始化调用 如何处理循环依赖 用了三级缓存。 单例bean构造器参数循环依赖（无法解决） prototype原型bean循环依赖（无法解决） 单例bean通过set注入或@Autowired循环依赖（可以解决） 原理：基于Java引用传递，当获得对象的引用时，对象的属性是可以延迟后设置的，但是构造器必须在获取引用之前。 通过提前暴露一个ObjectFactory对象来完成，简单来说，ClassA在调用构造器完成对象初始化之后，在调用ClassA的serClassB方法之前，就把ClassA实例化的对象通过ObjectFactory提前暴露到Spring容器中。 AOP 面向切面编程 在不改变原有业务逻辑的基础上，增强横切逻辑，根本上解耦合，避免横切逻辑代码重复。 事务 本质，是对Connection的管理。将连接绑定到当前线程，从当前线程获取连接，运用ThreadLocal。 DataSourceTransactionManager @Override protected Object doGetTransaction() { DataSourceTransactionObject txObject = new DataSourceTransactionObject(); txObject.setSavepointAllowed(isNestedTransactionAllowed()); //从ThreadLoacal拿连接 ConnectionHolder conHolder = (ConnectionHolder) TransactionSynchronizationManager.getResource(obtainDataSource()); txObject.setConnectionHolder(conHolder, false); return txObject; } @Nullable private static Object doGetResource(Object actualKey) { Map&lt;Object, Object&gt; map = resources.get();//看resources这个变量 if (map == null) { return null; } Object value = map.get(actualKey); // Transparently remove ResourceHolder that was marked as void... if (value instanceof ResourceHolder &amp;&amp; ((ResourceHolder) value).isVoid()) { map.remove(actualKey); // Remove entire ThreadLocal if empty... if (map.isEmpty()) { resources.remove(); } value = null; } return value; } 看一下resources变量在TransactionSynchronizationManager中的定义 private static final ThreadLocal&lt;Map&lt;Object, Object&gt;&gt; resources = new NamedThreadLocal&lt;&gt;(&quot;Transactional resources&quot;); Spring事务管理基于AOP，如果需要增强Bean。使用AOP添加事务支持。 AOP是基于Spring扩展点BeanPostProcessor.postProcessAfterInitailization 同一个类中非事务方法调用@Transaction注解的事务方法事务失效问题 @Service class A{ @Transactinal method b(){...} method a(){ //标记1 b(); } } //Spring扫描注解后，创建了另外一个代理类，并为有注解的方法插入一个startTransaction()方法： class proxy$A{ A objectA = new A(); method b(){ //标记2 startTransaction(); objectA.b(); } method a(){ //标记3 objectA.a(); //由于a()没有注解，所以不会启动transaction，而是直接调用A的实例的a()方法 } } 当我们调用A的bean的a()方法的时候，也是被proxyA拦截，执行proxyA拦截，执行proxyA拦截，执行proxyA.a()（标记3），然而，由以上代码可知，这时候它调用的是objectA.a()，也就是由原来的bean来调用a()方法了，所以代码跑到了“标记1”。由此可见，“标记2”并没有被执行到，所以startTransaction()方法也没有运行。 https://zhuanlan.zhihu.com/p/101396825 https://mp.weixin.qq.com/s/1TEBnmWynN4nwc6Q-oZfvw https://juejin.im/post/5dc21bdff265da4d4e300413 https://blog.csdn.net/levae1024/article/details/82998386 https://blog.csdn.net/m0_38027656/article/details/84190949?depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2&amp;utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2 解决方法： springboot启动类加上注解:@EnableAspectJAutoProxy(exposeProxy = true)。 使用AopContext.currentProxy()获取代理对象 Redis 持久化方式 AOF，RDB 优缺点 健过期策略 集群方案 Codis 分布式事务 2PC 结合案例，应用存储数据，然后投递到MQ，如何保障事务。 开启事务，协调者向所有的事务参与者发送事务内容 1.数据存储失败，应用服务自己回滚。 2.数据存储成功，消息投递失败，消息没有发送成功，抛出了异常，定时重新发。 3.数据存储成功，消息投递失败，消息发送成功，消费端自己挂了，没有接收到。 这种情况，如果需要保证客户端收到，mq需要支持收到确认，只有消费者收到并发送确认到ack给mq,mq才知道消费者收到，否则，mq自己重发。 如果消息是可丢失的，不重要，那么就不需要客户端确认，不用管消费端挂了，在不在线。 ","link":"https://xinrong2019.github.io/post/java-ji-chu-zhi-shi/"},{"title":"Java基础知识清单","content":"1-17 福利：Java基础面试考点清单 带着问题与技术关键词，有目标的开启体系化学习之旅~ 基础： 强引用、弱引用、虚引用、软引用 final关键字的作用 (方法、变量、类) 泛型、泛型继承、泛型擦除 jdk ServiceLoader LinkedList、LinkedHashMap、LRU 装饰者模式、代理模式、责任链模式、工厂模式、适配器模式、建造者模式、单例模式、模板模式、观察者模式… 关于精度损失问题：int、long 超过最大值 关于注解：元注解的种类、继承java.lang.Annotation、注解的基础类型、注解的常用方法 关于ClassLoader，类加载器，双亲委派模型 J.U.C 线程池参数说明，线程池的线程回收、shutdown 线程池的生命周期？ 线程池的核心模型Worker对象的运作流程是怎样的？ 线程池的拒绝策略有哪4种？ 线程池的提交，execute与submit有什么区别？在实际开发中需要注意哪些问题？ threadlocal原理，数据结构 并发集合类了解哪些？ ConcurrentHashMap CopyOnWrite集合、原理、锁机制 ConcurrentLinkedQueue、LinkedTransferQueue、ArrayBlockingQueue、PriorityBlockingQueue、SynchronousQueue、DelayQueue AQS 原理： 独占 &amp; 共享 state &amp; CHL队列 锁： Synchronized、ReentrantLock、RWLock、Condition、LockSupport、StampedLock、 概念：CAS 自旋、重入、偏向 volatile： 多线程共享 &amp; 阻止指令重排序 jvm的逃逸分析 &amp; Tlab &amp; 消除伪共享 &amp; UNsafe &amp; atomic: CAS的缺点，自旋、ABA问题 atomic 原子性、Reference、referenceArray、longadder 并发控制： barrier、countdownlatch、exchanger、future、semaphore jvm虚拟机： 虚拟机内存模型 新生代（Eden S0 S1）、老年代 、MetaSpace （比例） 垃圾回收算法（引用计数、标记压缩、清除、复制算法、分区）、垃圾收集器 GC停顿、吞吐量，进入老年代阈值、大对象回收问题等 jvm性能调优、参数配置 常用命令：jstat、jmap、jstack等 内存溢出分析：堆内、堆外 （含义、如何设置） CPU飙升：死锁、线程阻塞 关于GC: minor major full stw，安全点等 数据结构&amp;算法 数组、链表、树、队列… 关于时间复杂度，时间换空间转换案例 关于排序、冒泡、快排、递归、二分搜索、位运算 Spring Spring生命周期，流程梳理 Spring扩展点作用 Spring IOC AOP 基本原理 动态代理 BeanPostProcessor 作用？ ApplicationContextAware 的作用和使用？ BeanNameAware与BeanFactoryAware的先后顺序？ InitializingBean 和 BeanPostProcessor 的after方法先后顺序？ ApplicationListener监控的Application事件有哪些？ Spring模块装配的概念，比如@EnableScheduling @EnableRetry @EnableAsync，@Import注解的作用？ ImportBeanDefinitionRegistrar 扩展点用于做什么事情？ ClassPathBeanDefinitionScanner 的作用？ NamespaceHandlerSupport 命名空间扩展点的作用？ 如何实现动态注入一个Bean？ 如何把自定义注解所在的Class 初始化注入到Spring容器？ BeanDefinition指的是什么，与BeanDefinitionHolder的区别，Spring如何存储BeanDefinition实例？ ASM 与 CGlib Spring的条件装配，自动装配 RPC通信框架 Dubbo Dubbo的Spi机制？ Dubbo的核心模型 invoker、invocation、filter Dubbo的隐式传递? Dubbo的泛化调用？ Dubbo的export与importer时机？ Dubbo的服务调用过程？ Dubbo的负载均衡策略？ Dubbo的集群容错？ 网络通信 IO / NIO IO NIO区别？ 多路复用的概念，Selector Channel的概念、Bytebuf的概念，flip、position… FileChannel 如何使用？ RAF使用，seek、skip方法 Netty 关于Netty的Reactor实现？ Netty的ByteBuf有哪些？ 内存与非内存Bytebuffer的区别与使用场景？ 池化与非池化buffer的区别与使用场景？ 关于Netty的请求Buffer和响应Buffer? Netty的ChannelPipeline设计模式？ Netty的核心option参数配置？ Netty的ChannelInboundHandlerAdapter和SimpleChannelInboundHandler关系？ Netty的EventLoop核心实现？ Netty的连接管理事件接口有哪些常用方法（ChannelDuplexHandler）？ Netty的编解码与序列化手段 Netty的FastThreadLocal实现？ Netty中应用的装饰者 和 观察者模式在哪里体现？ MQ API使用，常用生产消费模型，集群架构搭建 常见问题，消息可靠性投递、幂等性保障 概念、原理、存储、消息投递、通信机制、性能相关优化 MQ常见的作用于目的、服务解耦、削峰填谷等 RocketMQ Kafka RabbitMQ ActiveMQ 缓存 内存缓存 堆外内存缓存 回收释放 Redis 缓存穿透、雪崩、热点Key、大Key、无底洞问题，缓存更新与淘汰、缓存与数据库的一致性 Redis的幂等性 Redis的分布式锁实现 Redis的原子性，Redis的特点 Redis集群相关问题、一致性hash、slot概念等 流控组件 Hystrix Sentinel 高可用服务中间件 Zookeeper / Curator Nginx Haproxy LVS Haproxy 数据库存储&amp;调度 Sharding-JDBC ElasticJob 调度平台相关：DAG、airflow等 搜索相关度 ELK ，数据库加速、主搜（算法） Logback、Slf4j2 Solr &amp; Lucene ","link":"https://xinrong2019.github.io/post/java-ji-chu/"},{"title":"SpringCloud Alibaba学习笔记","content":"SpringCloud Alibaba学习笔记 目录 [TOC] 导学 为什么学 组件性能更强 良好的可视化界面 搭建简单，学习曲线低 文档丰富并且是中文 学习目标 Spring Cloud Alibaba核心组件的用法及实现原理 Spring Cloud Alibaba结合微信小程序从&quot;0&quot;学习真正开发中的使用 实际工作中如何避免踩坑，正确的思考问题方式 Spring Cloud Alibaba的进阶：代码的优化和改善，微服务监控 进阶目标 如何提升团队的代码质量 编码技巧 心得总结 如何改善代码结构设计 借助监控工具 定位问题 解决问题 思路 分析并拆解微服务-&gt;编写代码-&gt;分析现有架构问题-&gt;引入微服务组件-&gt;优化重构-&gt;总结完善 Spring Cloud Alibaba的重要组件 服务发现Nacos 服务发现原理剖析 Nacos Server/Client 高可用Nacos搭建 实现负载均衡Ribbon 负载均衡的常见模式 RestTemplate整合Ribbon Ribbon配置自定义 如何扩展Ribbon 声明式HTTP客户端-Feign 如何使用Feign Feign配置自定义 如何扩展Feign 服务容错Sentinel 服务容错原理 Sentinel Sentinel DashBoard Sentinel核心原理分析 消息驱动RocketMq Spring Cloud Stream 实现异步消息推送与消费 API网关Gateway 整合Gateway 三大核心 聚合微服务请求 用户认证与授权 认证授权的常见方案 改造Gateway 扩展Feign 配置管理Nacos 配置如何管理 配置动态刷新 配置管理的最佳实践 调用链监控Sleuth 调用链监控原理剖析 Sleuth使用 Zipkin使用 环境搭建 JDK8 MySQL Maven的安装与配置 IDEA Spring Boot必知必会 Spring Boot特性 无需部署WAR文件 提供stater简化配置 尽可能自动配置Spring以及第三方库 提供&quot;生产就绪&quot;功能，例如指标、健康检查、外部配置等 无代码生成&amp;无XML 编写第一个Spring Boot应用 Spring Boot应用组成分析 依赖：pom.xml 启动类：注解 配置：application.properties static目录：静态文件 templates目录：模板文件 Spring Boot开发三板斧 加依赖 写注解 写配置 Spring Boot Actuator 监控工具 /actuator 入口 /health 健康检查 显示详情配置 management.endpoint.health.show-details=always # 显示所有监控端点 management.endpoints.web.exposure.include=* # 描述信息（自定义键值对） info.app-name=spring-boot-demo info.author=kim info.email=xxx@163.com Spring Boot配置管理 支持的配置格式 management: endpoint: health: show-details: always endpoints: web: exposure: include: '*' # 描述信息 info: app-name: spring-boot-demo author: kim email: xxx@163.com 注意：值是*，yml写法需要加引号 yml是使用趋势 yml在有的配置中可以表达顺序，properties不行 17种配置方式 实际项目种经常用到的配置管理方式： 配置文件 环境变量 外部配置文件 命令行参数 环境变量方式配置管理 application.yml management: endpoint: health: show-details: ${SOME_ENV} endpoints: web: exposure: include: '*' # 描述信息 info: app-name: spring-boot-demo author: kim email: xxx@163.com 设置环境变量SOME_ENV 环境变量方式配置管理（java -jar方式） mvn clean install -DskipTests java -jar spring-boot-demo-0.0.1-SNAPSHOT.jar --SOME_ENV=always 外部配置文件方式配置管理 将打的jar包和配置文件放在同一目录，会优先读取该配置文件内配置 命令行参数方式配置管理 java -jar spring-boot-demo-0.0.1-SNAPSHOT.jar --server.port=8081 最佳实践 KISS，规避掉优先级，没人会记住17中配置姿势的优先级。 Profile # 所有环境下公用的配置属性 management: endpoint: health: show-details: ${SOME_ENV} endpoints: web: exposure: include: '*' # 描述信息 info: app-name: spring-boot-demo author: kim email: xxx@163.com # 连字符 --- # profile=x的专用属性，也就是说某个环境下的专用属性 # 开发环境 spring: profiles: dev --- # profile=y的专用属性，也就是说某个环境下的专用属性 # 生产环境 spring: profiles: prod server: tomcat: max-threads: 300 max-connections: 1000 IDEA启动配置 访问http://localhost:8080/actuator/configprops通过actuator端口查看 默认使用default，可以通过添加配置设置默认profile spring: profiles: active: dev 最佳实践 KISS，不要使用优先级，规划好公用和专用配置 微服务拆分与编写 单体架构vs微服务架构 单体架构是什么 微服务是什么 微服务特性 微服务全景架构图 微服务优缺点 微服务适用场景 业务分析与建模 项目功能演示与分析 微服务拆分 项目架构图 数据库设计 API文档 编写微服务 创建小程序 创建项目 编写用户微服务 编写内容微服务 单体架构 优点： 架构简单 开发、测试、部署方便 缺点： 复杂性高 部署慢，频率低 扩展能力受限（比如用户模块是CPU密集的，只能通过买更好的CPU的机器，比如内容模块是IO密集的，只能通过购买更多内存） 阻碍技术创新（SpringMVC-&gt;Spring Web Flux，改动大） 不适合庞大复杂的系统 微服务 拆分后的小型服务 微服务的特性 每个微服务可独立运行在自己的进程里；（每个服务一个Tomcat） 一系列独立运行的微服务共同构建起整个系统 每个服务为独立的业务开发，一个微服务只关注某个特定的功能，例如订单管理、用户管理 可以使用不同的语言与数据存储技术（契合项目情况和团队实力） 微服务之间通过轻量的通信机制进行通信，例如通过Rest API进行调用；（通信协议轻量、跨平台） 全自动的部署机制 微服务全景架构图 优点 单个服务更易于开发、维护 单个微服务启动较快 局部修改容易部署 技术栈不受限 缺点 运维要求高 分布式固有的复杂性 重复劳动（不同语言调用相同功能时） 适用场景 大型、复杂的项目 有快速迭代的需求 访问压力大（微服务去中心化，把业务和数据都拆分了，可以应对访问压力） 不适用微服务的场景 业务稳定 迭代周期长 项目演示 微服务拆分 业界流行的拆分方法论 个人心得 合理粒度 小程序的拆分 方法论 领域驱动设计（Domain Driven Design）(概念太多，学习曲线高) 面向对象（by name./by verb）（通过名词（状态），动词（行为）拆分） 个人心得 职责划分 规划好微服务的边界。比如订单微服务只负责订单功能。 通用性划分 把一些通用功能做成微服务。比如消息中心和用户中心。 合理的粒度 良好的满足业务（这是前提） 幸福感（你的团队没有人认为微服务太大，难以维护，同时部署也非常高效，不会每次发布都发布N多微服务） 增量迭代 持续进化 小程序的拆分 以面向对象方式拆分 用户中心按照通用性划分，内容中心按照职责划分。 项目初期不建议拆分太细，后期如果发现某个微服务过分庞大再细分。 项目架构图 数据库设计 数据建模 建表 user-center-create-table.sql USE `user_center`; -- ----------------------------------------------------- -- Table `user` -- ----------------------------------------------------- CREATE TABLE IF NOT EXISTS `user` ( `id` INT NOT NULL AUTO_INCREMENT COMMENT 'Id', `wx_id` VARCHAR(64) NOT NULL DEFAULT '' COMMENT '微信id', `wx_nickname` VARCHAR(64) NOT NULL DEFAULT '' COMMENT '微信昵称', `roles` VARCHAR(100) NOT NULL DEFAULT '' COMMENT '角色', `avatar_url` VARCHAR(255) NOT NULL DEFAULT '' COMMENT '头像地址', `create_time` DATETIME NOT NULL COMMENT '创建时间', `update_time` DATETIME NOT NULL COMMENT '修改时间', `bonus` INT NOT NULL DEFAULT 300 COMMENT '积分', PRIMARY KEY (`id`)) COMMENT = '分享'; -- ----------------------------------------------------- -- Table `bonus_event_log` -- ----------------------------------------------------- CREATE TABLE IF NOT EXISTS `bonus_event_log` ( `id` INT NOT NULL AUTO_INCREMENT COMMENT 'Id', `user_id` INT NULL COMMENT 'user.id', `value` INT NULL COMMENT '积分操作值', `event` VARCHAR(20) NULL COMMENT '发生的事件', `create_time` DATETIME NULL COMMENT '创建时间', `description` VARCHAR(100) NULL COMMENT '描述', PRIMARY KEY (`id`), INDEX `fk_bonus_event_log_user1_idx` (`user_id` ASC) ) ENGINE = InnoDB COMMENT = '积分变更记录表'; content-center-create-table.sql USE `content_center`; -- ----------------------------------------------------- -- Table `share` -- ----------------------------------------------------- CREATE TABLE IF NOT EXISTS `share` ( `id` INT NOT NULL AUTO_INCREMENT COMMENT 'id', `user_id` INT NOT NULL DEFAULT 0 COMMENT '发布人id', `title` VARCHAR(80) NOT NULL DEFAULT '' COMMENT '标题', `create_time` DATETIME NOT NULL COMMENT '创建时间', `update_time` DATETIME NOT NULL COMMENT '修改时间', `is_original` TINYINT(1) NOT NULL DEFAULT 0 COMMENT '是否原创 0:否 1:是', `author` VARCHAR(45) NOT NULL DEFAULT '' COMMENT '作者', `cover` VARCHAR(256) NOT NULL DEFAULT '' COMMENT '封面', `summary` VARCHAR(256) NOT NULL DEFAULT '' COMMENT '概要信息', `price` INT NOT NULL DEFAULT 0 COMMENT '价格（需要的积分）', `download_url` VARCHAR(256) NOT NULL DEFAULT '' COMMENT '下载地址', `buy_count` INT NOT NULL DEFAULT 0 COMMENT '下载数 ', `show_flag` TINYINT(1) NOT NULL DEFAULT 0 COMMENT '是否显示 0:否 1:是', `audit_status` VARCHAR(10) NOT NULL DEFAULT 0 COMMENT '审核状态 NOT_YET: 待审核 PASSED:审核通过 REJECTED:审核不通过', `reason` VARCHAR(200) NOT NULL DEFAULT '' COMMENT '审核不通过原因', PRIMARY KEY (`id`)) ENGINE = InnoDB COMMENT = '分享表'; -- ----------------------------------------------------- -- Table `mid_user_share` -- ----------------------------------------------------- CREATE TABLE IF NOT EXISTS `mid_user_share` ( `id` INT NOT NULL AUTO_INCREMENT, `share_id` INT NOT NULL COMMENT 'share.id', `user_id` INT NOT NULL COMMENT 'user.id', PRIMARY KEY (`id`), INDEX `fk_mid_user_share_share1_idx` (`share_id` ASC) , INDEX `fk_mid_user_share_user1_idx` (`user_id` ASC) ) ENGINE = InnoDB COMMENT = '用户-分享中间表【描述用户购买的分享】'; -- ----------------------------------------------------- -- Table `notice` -- ----------------------------------------------------- CREATE TABLE IF NOT EXISTS `notice` ( `id` INT NOT NULL AUTO_INCREMENT COMMENT 'id', `content` VARCHAR(255) NOT NULL DEFAULT '' COMMENT '内容', `show_flag` TINYINT(1) NOT NULL DEFAULT 0 COMMENT '是否显示 0:否 1:是', `create_time` DATETIME NOT NULL COMMENT '创建时间', PRIMARY KEY (`id`)); API 文档 课程文档主要分四类： API文档：https://t.itmuch.com/doc.html 课程配套代码：https://git.imooc.com/coding-358/ 课程相关资源（例如检表语句、数据模型、课上用到的软件等）：https://git.imooc.com/coding-358/resource 课上用到的一些课外读物（慕课网手记）：http://www.imooc.com/t/1863086 如何创建小程序 注册账号：https://mp.weixin.qq.com 按照提示填写信息 前端代码如何使用 创建项目 技术选型 Spring Boot Spring MVC Mybatis+通用Mapper Spring Cloud Alibaba（分布式） 工程结构规划 创建项目，整合框架 pom.xml &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.13.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;com.itmuch&lt;/groupId&gt; &lt;artifactId&gt;user-center&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;user-center&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 引入通用mapper--&gt; &lt;dependency&gt; &lt;groupId&gt;tk.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mapper-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.1.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.3.6&lt;/version&gt; &lt;configuration&gt; &lt;configurationFile&gt; ${basedir}/src/main/resources/generator/generatorConfig.xml &lt;/configurationFile&gt; &lt;overwrite&gt;true&lt;/overwrite&gt; &lt;verbose&gt;true&lt;/verbose&gt; &lt;/configuration&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;8.0.19&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;tk.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mapper&lt;/artifactId&gt; &lt;version&gt;4.1.5&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt; 通用Mapper包扫描配置 import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import tk.mybatis.spring.annotation.MapperScan;//注意是tk的MapperScan注解 @SpringBootApplication @MapperScan(&quot;com.itmuch&quot;) public class UserCenterApplication { public static void main(String[] args) { SpringApplication.run(UserCenterApplication.class, args); } } 在resources目录下新建generator目录，添加mybatis.generator配置 generator/generatorConfig.xml &lt;!DOCTYPE generatorConfiguration PUBLIC &quot;-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd&quot;&gt; &lt;generatorConfiguration&gt; &lt;properties resource=&quot;generator/config.properties&quot;/&gt; &lt;context id=&quot;Mysql&quot; targetRuntime=&quot;MyBatis3Simple&quot; defaultModelType=&quot;flat&quot;&gt; &lt;property name=&quot;beginningDelimiter&quot; value=&quot;`&quot;/&gt; &lt;property name=&quot;endingDelimiter&quot; value=&quot;`&quot;/&gt; &lt;plugin type=&quot;tk.mybatis.mapper.generator.MapperPlugin&quot;&gt; &lt;property name=&quot;mappers&quot; value=&quot;tk.mybatis.mapper.common.Mapper&quot;/&gt; &lt;property name=&quot;caseSensitive&quot; value=&quot;true&quot;/&gt; &lt;/plugin&gt; &lt;jdbcConnection driverClass=&quot;${jdbc.driverClass}&quot; connectionURL=&quot;${jdbc.url}&quot; userId=&quot;${jdbc.user}&quot; password=&quot;${jdbc.password}&quot;&gt; &lt;/jdbcConnection&gt; &lt;javaModelGenerator targetPackage=&quot;com.itmuch.usercenter.domain.entity.${moduleName}&quot; targetProject=&quot;src/main/java&quot;/&gt; &lt;sqlMapGenerator targetPackage=&quot;com.itmuch.usercenter.dao.${moduleName}&quot; targetProject=&quot;src/main/resources&quot;/&gt; &lt;javaClientGenerator targetPackage=&quot;com.itmuch.usercenter.dao.${moduleName}&quot; targetProject=&quot;src/main/java&quot; type=&quot;XMLMAPPER&quot;/&gt; &lt;table tableName=&quot;${tableName}&quot;&gt; &lt;generatedKey column=&quot;id&quot; sqlStatement=&quot;JDBC&quot;/&gt; &lt;/table&gt; &lt;/context&gt; &lt;/generatorConfiguration&gt; generator/config.properties jdbc.driverClass=com.mysql.cj.jdbc.Driver # nullCatalogMeansCurrent=true 如果不加这个配置，出现表名user在其他库，比如系统库的，会生产系统库的user jdbc.url=jdbc:mysql://localhost:3306/user_center?nullCatalogMeansCurrent=true jdbc.user=root jdbc.password=kim@2020 # 包名 moduleName=user # 表名 tableName=user application.yml spring: datasource: url: jdbc:mysql://localhost:3306/user_center hikari: username: root password: kim@2020 # &gt;=6.x com.mysql.cj.jdbc.Driver # &lt;=5.x com.mysql.jdbc.Driver driver-class-name: com.mysql.cj.jdbc.Driver 执行逆向生产代码 整合Lombok简化代码 &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.18.10&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; 常用注解 @Data @NoArgsConstructor//生成无参构造 @AllArgsConstructor//为所有参数生成构造 @RequiredArgsConstructor//为final属性生成构造方法 @Builder //建造者模式 @Slf4j 更多查询官网 在通用mapper wiki搜lombok，看有没有生成支持lombok的配置 mybatis.generator添加lombok支持 &lt;plugin type=&quot;tk.mybatis.mapper.generator.MapperPlugin&quot;&gt; &lt;property name=&quot;mappers&quot; value=&quot;tk.mybatis.mapper.common.Mapper&quot;/&gt; &lt;property name=&quot;caseSensitive&quot; value=&quot;true&quot;/&gt; &lt;property name=&quot;lombok&quot; value=&quot;Getter,Setter,ToString&quot;/&gt;&lt;!-- 添加的行 --&gt; &lt;/plugin&gt; 文档也说了，目前只支持@Getter@Setter@ToString@Accessors(chain = true)4种注解，一般我们自己的domain上还是习惯加如下注解： @Data @NoArgsConstructor//生成无参构造 @AllArgsConstructor//为所有参数生成构造 @Builder //建造者模式 可以手动加，更简单。 解决IDEA的红色警告 出现警告的原因： IDEA是非常智能的，它可以理解Spring的上下文。然而 UserMapper 这个接口是Mybatis的，IDEA理解不了。 而 @Autowired 注解，默认情况下要求依赖对象（也就是 userMapper ）必须存在。而IDEA认为这个对象的实例/代理是个null，所以就友好地给个提示。 解决方法：参见这篇手记 作业1: 课后研究一下@Resource和@Autowired注解 作业2: 研究@Repository、@Component、@Service、@Controller之间的区别和联系 编写用户微服务和内容微服务 注意：核心业务，一定要设计好业务流程，分析的过程中，使用业务流程图、活动图、用例图、序列图。重视业务和建模，没有建模的微服务是没有灵魂的。 实际开发流程 Schema First 1、分析业务（流程图、用例图...架构图等） 建模业务，确定架构 2、敲定业务流程（评审） 3、设计API/数据模型（表结构设计|类图|ER图） 4、编写API文档 5、编写代码 API First 1、分析业务（流程图、用例图...架构图等） 建模业务，确定架构 2、敲定业务流程（评审） 3、设计API/数据模型（表结构设计|类图|ER图） 4、编写代码 5、编写API文档 但是实际也不是完全按照这样等流程走。 编码。。。 RestTemplate的使用 现有架构存在的问题 硬编码IP，IP变化怎么办 如何实现负载均衡？ 用户中心挂了怎么办？ Spring Cloud介绍 什么是Spring Cloud Alibaba Spring Cloud的子项目 致力于提供微服务开发的一站式解决方案 包含微服务开发的必备组件 基于Spring Cloud，符合Spring Cloud标准 阿里的微服务解决方案 版本与兼容性 Spring Cloud 版本命名 Spring Cloud 生命周期 Spring Boot 、Spring Cloud、Spring Cloud Alibaba的兼容性关系 生产环境怎么选择版本？ Spring Cloud 版本命名 语义化 2.1.13.RELEASE 2：主版本，第几代 1：次版本，一些功能的增加，但是架构没有太大变化，是兼容的 13：增量版本，bug修复 RELEASE：里程碑。SNAPSHOT：开发版 ，M：里程碑 ，RELEASE：正式版 Greenwich SR1 ：Greenwich版本的第一个bug修复版 SR：Service Release bug修复 Release Train. 发布列车 伦敦地铁站站名。避免混淆，噱头。 Greenwich RELEASE： Greenwich版本的第一个正式版 Spring Cloud 生命周期 版本发布规划 https://github.com/spring-cloud/spring-cloud-release/milestones 版本发布记录 https://github.com/spring-cloud/spring-cloud-release/release 版本终止声明 https://spring.io/projects/spring-cloud#overview 版本兼容性 https://spring.io/projects/spring-cloud-alibaba#overview https://github.com/alibaba/spring-cloud-alibaba/blob/master/README-zh.md 生产环境怎么选择版本？ 坚决不用非稳定版本/end-of-life版本 尽量用最新一代 xxx.RELEASE版本缓一缓 SR2之后一般可大规模使用 整合Spring Cloud Alibaba 整合Spring Cloud 整合Spring Cloud Alibaba 整合好后，引入组件不需要指定版本 服务发现 服务提供者与服务消费者 名次 定义 服务提供者 服务的被调用方（即：为其他微服务提供接口的微服务） 服务消费者 服务的调用方（即：调用其他微服务接口的微服务） 如何让服务消费者感知到服务提供者 服务消费者内部使用定时任务去服务发现组件获取提供者信息，并缓存到本地，服务消费者每次调用服务提供者从本地缓存那提供者信息。 添加心跳机制，通过心跳机制改变服务状态 什么是Nacos 官网什么是Nacos 搭建Nacos Server 选择Nacos Server版本 查看引入到spring-cloud-alibaba-dependencie依赖 下载地址 https://github.com/alibaba/nacos/releases 搭建Nacos Server 参考文档：https://nacos.io/zh-cn/docs/quick-start.html 启动服务器 startup.sh -m standalone 访问控制台 http://localhost:8848/nacos 默认用户名密码都是nacos 将应用注册到Nacos 用户中心注册到Nacos 内容中心注册到Nacos 测试：内容中心总能找到用户中心 引入依赖 &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; 配置 spring: cloud: nacos: discovery: server-addr: localhost:8848 application: # 服务名称尽量用-，不要用_，不要用特殊字符 name: content-center 引入服务发现 @Slf4j @Service @RequiredArgsConstructor(onConstructor = @__(@Autowired)) public class ShareService { private final ShareMapper shareMapper; private final RestTemplate restTemplate; private final DiscoveryClient discoveryClient; public ShareDto findById(Integer id){ //获取分享详情 Share share = this.shareMapper.selectByPrimaryKey(id); //发布人id Integer userId = share.getUserId(); //用户中心所有实例的信息 List&lt;ServiceInstance&gt; instances = discoveryClient.getInstances(&quot;user-center&quot;); String targetURL = instances.stream() .map(instance -&gt; instance.getUri().toString() + &quot;/users/{id}&quot;) .findFirst() .orElseThrow(() -&gt; new IllegalArgumentException(&quot;当前没有实例！&quot;)); log.info(&quot;请求的目标地址：{}&quot;, targetURL); UserDto userDto = restTemplate.getForObject( targetURL, UserDto.class, userId); ShareDto shareDto = new ShareDto(); //消息的装配 BeanUtils.copyProperties(share, shareDto); shareDto.setWxNickName(userDto.getWxNickname()); return shareDto; } } Nacos服务发现的领域模型 Namespace：只要用来实现环境隔离，默认public Group：默认DEFAULT_GROUP，管理服务分组 Service：微服务 Cluster：微服务集群，对指定微服务的虚拟划分 Instance：微服务实例 如何使用 Namespace，在控制台页面创建。配置的时候使用生成的uuid。 spring: cloud: nacos: discovery: # 指定nacos server的地址 server-addr: localhost:8848 cluster-name: BJ namespace: 56116141-d837-4d15-8842-94e153bb6cfb Nacos元数据 官方描述：https://nacos.io/zh-ch/docs/concepts.html 级别：【服务级别、集群级别、实例级别】 元数据的作用： 提供描述信息 让微服务调用更灵活 例如：微服务版本控制 如何为微服务设置元数据 控制台界面 配置文件指定 spring: cloud: nacos: discovery: # 指定nacos server的地址 server-addr: localhost:8848 cluster-name: BJ namespace: 56116141-d837-4d15-8842-94e153bb6cfb metadata: instance: c haha: hehe version: 1 实现负载均衡-Ribbon 负载均衡的两种方式 服务端负载均衡 客户端负载均衡（客户端调用的时候使用选择负载均衡算法） 手写一个客户端负载均衡器 改写一下ShareService的findById方法。从Nacos获取到URL列表，然后随机从列表中取一个作为本次请求的服务提供者实例。 List&lt;String&gt; targetURLs = instances.stream() .map(instance -&gt; instance.getUri().toString() + &quot;/users/{id}&quot;).collect(Collectors.toList()); int i = ThreadLocalRandom.current().nextInt(targetURLs.size()); String targetURL= targetURLs.get(i); 随后启动content-center 启动多个user-center 配置允许并行运行 修改端口，运行启动类 server: port: 8082 使用Ribbon实现负载均衡 Ribbon是什么 引入Ribbon后到架构演进 整合Ribbon实现负载均衡 Ribbon是什么 负载均衡器 架构演进 整合Ribbon实现负载均衡 引入Nacos 我们引入spring-cloud-starter-alibaba-nacos-discovery时，已经引入了Ribbon。 直接使用就行了。 写注解 @Bean @LoadBalanced public RestTemplate restTemplate(){ return new RestTemplate(); } 配置RestTemplate的地方添加@LoadBalanced注解即可。 使用 UserDto userDto = restTemplate.getForObject( &quot;http://user-center/users/{userId}&quot;, UserDto.class, userId); Ribbon组成 先有个印象。二次开发再回头看 Ribbon内置的负载均衡规则 默认是ZoneAvoidanceRule。 每一个负载均衡算法源码都值得看一下。 细粒度配置自定义 Java代码配置 用配置属性配置 最佳实践总结 场景：当内容中心调用用户中心微服务的时候使用随机负载，当内容中心调用其他微服务的时候使用默认负载均衡策略。 Java代码配置 新建配置类，注册一个RandomRule。 package ribbonconfiguration; import com.netflix.loadbalancer.IRule; import com.netflix.loadbalancer.RandomRule; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; /** * 配置类所在的包必须是和启动类不一样的包 */ @Configuration public class RibbonConfiguration { @Bean public IRule ribbonRule(){ return new RandomRule(); } } 新建一个user-center的ribbon负载配置类，配置规则使用上面的随机规则。 package com.itmuch.contentcenter.configuration; import org.springframework.cloud.netflix.ribbon.RibbonClient; import org.springframework.context.annotation.Configuration; import ribbonconfiguration.RibbonConfiguration; @Configuration @RibbonClient(name = &quot;user-center&quot;,configuration = RibbonConfiguration.class) public class UserCenterRibbonConfiguration { } @RibbonClient注解配置Ribbon自定义配置 name=&quot;user-center&quot;表示为user-center配置的。 configuration = RibbonConfiguration.class用来指定负载均衡算法，或者负载均衡规则 父子上下文 这里的上下文是指Spring Context。 启动类拥有一个上下文，是父上下文，Ribbon会启动一个子上下文，父子上下文不能重叠。 启动类的上下文，会扫描启动类所在包及子包下的Bean。 Ribbon的配置类不能被启动类的上下文扫描到。因为Spring context是一个树状上下文。父子上下文扫描到包如果重叠会有各种问题。比如，导致事务不生效。 如果上面配置的RibbonConfiguration在启动类扫描范围内，会导致自定义配置失效，RibbonConfiguration配置的随机负载均衡全局生效。 配置属性方式 user-center: ribbon: NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule 这种方式没有上下文重叠的坑 两种配置方式的对比 细粒度配置最佳实践 尽量使用属性配置，属性方式实现不了的情况下再考虑用代码配置 在同一个微服务内尽量保持单一性，比如统一使用属性配置，不要两种方式混用，增加定位代码的复杂性 全局配置 方式一：让ComponentScan上下文重叠（强烈不建议使用） 方式二：唯一正确的途径：@RibbonClients(defaultConfiguration = xxx.class) package com.itmuch.contentcenter.configuration; import org.springframework.cloud.netflix.ribbon.RibbonClients; import org.springframework.context.annotation.Configuration; import ribbonconfiguration.RibbonConfiguration; @Configuration @RibbonClients(defaultConfiguration = RibbonConfiguration.class) public class UserCenterRibbonConfiguration { } 支持的配置项 Java Config方式：见Ribbon组成一节的接口 配置文件方式： 饥饿加载 默认是懒加载，在调用restTemplate时才会创建一个叫user-center的Ribbon Client user-center是要调用的客户端名字 懒加载的问题：在第一次调用user-center的接口时，访问会慢。 可以使用饥饿加载避免这个问题。 ribbon: eager-load: enabled: true clients: user-center 扩展Ribbon 支持Nacos权重 首先了解一下，Nacos的权重在0-1之间，1最大 Ribbon内置的负载均衡规则都不支持Nacos的权重，需要自己定义一个负载均衡规则。 @Slf4j public class NacosWeightedRule extends AbstractLoadBalancerRule { @Autowired private NacosDiscoveryProperties nacosDiscoveryProperties; @Override public void initWithNiwsConfig(IClientConfig iClientConfig) { //读取配置文件，并初始化当前配置NacosWeightedRule，一般不需要实现 } @Override public Server choose(Object key) { BaseLoadBalancer loadBalancer = (BaseLoadBalancer) this.getLoadBalancer(); log.info(&quot;loadBalancer = {}&quot;, loadBalancer); //想要请求的微服务的名称 String name = loadBalancer.getName(); //实现负载均衡算法 //这里不自己实现，直接使用nacos提供的 //拿到服务发现的相关API NamingService namingService = nacosDiscoveryProperties.namingServiceInstance(); try { Instance instance = namingService.selectOneHealthyInstance(name); log.info(&quot;选择的实例是：port = {}, instance = {}&quot;, instance.getPort(), instance); return new NacosServer(instance); } catch (NacosException e) { return null; } } } 配置为全局规则 /** * 配置类所在的包必须是和启动类不一样的包 */ @Configuration public class RibbonConfiguration { @Bean public IRule ribbonRule(){ return new NacosWeightedRule(); } } 更多扩展方式可以扩展Ribbon支持Nacos权重的三种方式 同一集群优先调用 为了实现容灾，把内容中心和用户中心部署在北京机房和南京机房里，希望调用的时候同机房优先。 使用Nacos服务发现领域模型里的Cluster 编写同集群优先调用规则 @Slf4j public class NacosSameClusterWeightedRule extends AbstractLoadBalancerRule { @Autowired private NacosDiscoveryProperties nacosDiscoveryProperties; @Override public void initWithNiwsConfig(IClientConfig iClientConfig) { } @Override public Server choose(Object key) { //拿到配置文件中的集群名称 String clusterName = nacosDiscoveryProperties.getClusterName(); BaseLoadBalancer loadBalancer = (BaseLoadBalancer) this.getLoadBalancer(); log.info(&quot;loadBalancer = {}&quot;, loadBalancer); //想要请求的微服务的名称 String name = loadBalancer.getName(); //拿到服务发现的相关API NamingService namingService = nacosDiscoveryProperties.namingServiceInstance(); try { //1 找到指定服务的所有实例 List&lt;Instance&gt; instances = namingService.selectInstances(name, true); //2 过滤出相同集群下的所有实例 Stream&lt;Instance&gt; instanceStream = instances.stream() .filter(instance -&gt; Objects.equals(instance.getClusterName(), clusterName)); List&lt;Instance&gt; sameClusterInstances = instanceStream.collect(Collectors.toList()); List&lt;Instance&gt; instancesToBeChosen; if(CollectionUtils.isEmpty(sameClusterInstances)){ instancesToBeChosen = instances; log.warn(&quot;发生跨集群调用，name = {}, clusterName = {}, instances = {}&quot;, name, clusterName, instances); }else { instancesToBeChosen = sameClusterInstances; } //3 基于权重的负载均衡算法，返回1个实例 Instance instance = ExtendBalancer.getHostByRandomWeight2(instancesToBeChosen); log.info(&quot;选择的实例是 port = {}, instances = {} &quot;,instance.getPort(), instance); return new NacosServer(instance); } catch (NacosException e) { log.error(&quot;发生异常&quot;,e); } return null; } } class ExtendBalancer extends Balancer{ //Nacos没有暴露从实例列表中选一个，只有selectOneHealthyInstance public static Instance getHostByRandomWeight2(List&lt;Instance&gt; hosts) { return getHostByRandomWeight(hosts); } } 配置全局NacosSameClusterWeightedRule @Configuration public class RibbonConfiguration { @Bean public IRule ribbonRule(){ return new NacosSameClusterWeightedRule(); } } 配置所在集群 spring: datasource: url: jdbc:mysql://localhost:3306/content_center hikari: username: root password: kim@2020 # &gt;=6.x com.mysql.cj.jdbc.Driver # &lt;=5.x com.mysql.jdbc.Driver driver-class-name: com.mysql.cj.jdbc.Driver cloud: nacos: discovery: server-addr: localhost:8848 cluster-name: BJ application: # 服务名称尽量用-，不要用_，不要用特殊字符 name: content-center logging: level: com.itmuch.usercenter.dao.content: debug server: servlet: context-path: port: 8010 #user-center: # ribbon: # NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule ribbon: eager-load: enabled: true clients: user-center 启动内容中心服务 接下来，配置两个用户中心服务，分别配置不同的集群和端口 spring: datasource: url: jdbc:mysql://localhost:3306/user_center hikari: username: root password: kim@2020 # &gt;=6.x com.mysql.cj.jdbc.Driver # &lt;=5.x com.mysql.jdbc.Driver driver-class-name: com.mysql.cj.jdbc.Driver cloud: nacos: discovery: server-addr: localhost:8848 # 多集群配置 cluster-name: BJ application: # 服务名称尽量用-，不要用_，不要用特殊字符 name: user-center logging: level: com.itmuch.usercenter.dao.user: debug server: # 本地启动多个实例，启动前记得改端口 port: 8081 查看Nacos控制台 观察到user-center的集群数目是2。点击详情 页面访问请求http://localhost:8010/shares/1 可以看到总是请求到相同机房的实例（8081也属于BJ集群）。 模拟BJ集群下线。选择Nacos控制台里BJ集群的8081实例，将其下线。 再次浏览器访问http://localhost:8010/shares/1 可以观察到已经请求到了异地机房的NJ机房的实例8082 番外：为开源项目贡献代码 目前同集群优先调用规则已经在新版本中被采纳了，可以直接配置。我用的是2.1.0.RELEASE版本 同集群优先调用规则的类是com.alibaba.cloud.nacos.ribbon.NacosRule,直接配置这个类使用，不需要再扩展了。 基于元数据的版本控制 配置元数据，只要在spring.cloud.nacos.discovery.metadata下配置key-value对就可以 spring: cloud: nacos: discovery: server-addr: localhost:8848 cluster-name: BJ metadata: version: v1.0 核心逻辑是，服务提供者和服务消费者配置相同的或不同的version元数据，在服务消费者请求服务提供者的时候，从待选实例中过滤一下，找到相同版本号的实例列表，再用一种负载算法从从版本号列表中选一个实例。 String version = nacosDiscoveryProperties.getMetadata().get(&quot;version&quot;); NamingService namingService = nacosDiscoveryProperties.namingServiceInstance(); try { //1 找到指定服务的所有实例 List&lt;Instance&gt; instances = namingService.selectInstances(name, true); //过滤出同集群的实例列表 //过滤出版本号相同的实例列表 List&lt;Instance&gt; sameVersionInstances = instancesToBeChosen.stream() .filter(instance -&gt; Objects.equals(instance.getMetadata().get(&quot;version&quot;), version)) .collect(Collectors.toList()); //从列表中选出一个实例 Instance instance = ExtendBalancer.getHostByRandomWeight2(instancesToBeChosen); 具体实现参见手记 深入理解Namespace 配置namespace spring: datasource: url: jdbc:mysql://localhost:3306/content_center hikari: username: root password: kim@2020 # &gt;=6.x com.mysql.cj.jdbc.Driver # &lt;=5.x com.mysql.jdbc.Driver driver-class-name: com.mysql.cj.jdbc.Driver cloud: nacos: discovery: server-addr: localhost:8848 cluster-name: BJ metadata: version: v1.0 # 指定namespace namespace: bc4f4e1a-bf4e-4bcc-86f1-7f6252f81e45 application: # 服务名称尽量用-，不要用_，不要用特殊字符 name: content-center 跨namespace不能调用 在用户中心和内容中心分别配上同样的命名空间ID。才可以正常访问。 现有架构存在的问题 代码不可读 复杂的url难以维护 难以响应需求变化，变化没有幸福感 编程体验不统一 声明式HTTP客户端Feign Feign是Netflix开源的声明式HTTP客户端 Github地址 https://github.com/openfeign/feign 使用Feign实现远程HTTP调用 引入依赖 &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; 写注解 启动类上加上@EnableFeignClients注解 写配置 暂时没有 实现一个Feign接口 @FeignClient(name = &quot;user-center&quot;) public interface UserCenterFeignClient { /** * http://user-center/users/{id} * @param id * @return */ @GetMapping(&quot;/users/{id}&quot;) UserDto findById(@PathVariable Integer id); } @Slf4j @Service @RequiredArgsConstructor(onConstructor = @__(@Autowired)) public class ShareService { private final ShareMapper shareMapper; private final UserCenterFeignClient userCenterFeignClient; public ShareDto findById(Integer id){ //获取分享详情 Share share = this.shareMapper.selectByPrimaryKey(id); //发布人id Integer userId = share.getUserId(); UserDto userDto = this.userCenterFeignClient.findById(userId); ShareDto shareDto = new ShareDto(); //消息的装配 BeanUtils.copyProperties(share, shareDto); shareDto.setWxNickName(userDto.getWxNickname()); return shareDto; } } 所谓的声明式HTTP客户端，就是只需要声明一个Feign Client接口，Feign就会根据声明的接口，自动帮我们构造请求的目标地址，并帮助你请求。 Feign的组成 细粒度配置自定义 默认Feign不打印任何日志，可以自定义Feign日志级别，让其打印日志 Feign日志级别 Java配置方式 UserCenterFeignConfiguration /** * feign的配置类，最佳实践不要加@Configuration注解，否则必须挪到@ComponentScan能扫描的包以外。 * 是因为重复扫描，父子上下文的问题 */ public class UserCenterFeignConfiguration { @Bean public Logger.Level level(){ //打印所有请求的细节 return Logger.Level.FULL; } } UserCenterFeignClient @FeignClient(name = &quot;user-center&quot;, configuration = UserCenterFeignConfiguration.class) public interface UserCenterFeignClient { /** * http://user-center/users/{id} * @param id * @return */ @GetMapping(&quot;/users/{id}&quot;) UserDto findById(@PathVariable Integer id); } logging: level: com.itmuch.usercenter.dao.content: debug com.itmuch.contentcenter.feignclient.UserCenterFeignClient: debug 属性方式配置 feign: client: config: # 想要调用的微服务的名称 user-center: loggerLevel: full 全局配置 代码方式 将细粒度的配置方式都注释掉 在启动类配置上全局配置 @EnableFeignClients(defaultConfiguration = UserCenterFeignConfiguration.class) 配置属性方式 feign: client: config: default: loggerLevel: full 支持的配置项 代码方式 属性配置方式 配置最佳实践 Ribbon配置 vs Feign配置 Ribbon是一个负载均衡器，帮我们选择一个实例 Feign是一个声明式HTTP客户端，帮助我们更优雅的请求 Feign代码方式vs属性方式 优先级：全局代码&lt;全局属性&lt;细粒度代码&lt;细粒度属性 最佳实践 尽量使用属性配置，属性方式实现不了的情况再考虑用代码配置 在同一个微服务内尽量保持单一性，比如统一使用属性配置，不要两种方式混用，增加定位代码的复杂性 Feign的继承 这个特性带来了紧耦合，因为在微服务间共享接口，官方不建议使用。 现状：很多公司用，代码复用。 新项目如何选择：权衡利弊，会得到什么好处，失去什么，是不是划算，划算就上。 多参数请求构造 如何使用Feign构造多参数的请求 Get请求参数使用@SpringQueryMap注解 @FeignClient(name = &quot;user-center&quot;) public interface TestUserCenterFeignClient { @GetMapping(&quot;/q&quot;) UserDto query(@SpringQueryMap UserDto userDto); } Post请求多参数，也可以使用@RequestBody。 Feign脱离Ribbon使用 @FeignClient(name = &quot;baidu&quot;, url=&quot;http://www.baidu.com&quot;) public interface TestBaiduFeignClient { @GetMapping(&quot;&quot;) String index(); } @GetMapping(&quot;baidu&quot;) public String baiduIndex(){ return this.testBaiduFeignClient.index(); } RestTemplate vs Feign 如何选择？ 原则：尽量用Feign，杜绝使用RestTemplate 尽量减少开发人员的选择，共存会带来风格的不统一，额外的学习成本和额外的代码理解成本 事无绝对，合理选择 Feign解决不了，才用RestTemplate Feign的性能优化 连接池【提升15%左右】，默认使用URLConnection，可以修改 可以选用httpclient或者okhttp 添加依赖 &lt;dependency&gt; &lt;groupId&gt;io.github.openfeign&lt;/groupId&gt; &lt;artifactId&gt;feign-httpclient&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.github.openfeign&lt;/groupId&gt; &lt;artifactId&gt;feign-okhttp&lt;/artifactId&gt; &lt;/dependency&gt; feign: client: config: default: loggerLevel: full httpclient: # 让feign使用apache httpclient做请求，而不是默认的urlclient enabled: true # feign的最大连接数 max-connections: 200 # feign单个路径的最大连接数 max-connections-per-route: 50 okhttp: enabled: true # feign的最大连接数 max-connections: 200 # feign单个路径的最大连接数 max-connections-per-route: 50 日志级别 生产环境建议设置为basic Feign常见问题总结 常见问题总结 现有架构总结 服务容错-Sentinel 雪崩效应：基础服务故障，导致导致上层服务故障，并且故障不断放大。又称为cascading failure，级联失效，级联故障。 雪崩效应是因为服务没有做好容错。 常见的容错方案（容错思想） 超时 限流 仓壁模式（线程池隔离） 断路器模式 5秒内错误率、错误次数达到就跳闸。 断路器三态： 使用Sentinel实现容错 是什么：轻量级的流量控制、熔断降级Java库。 整合Sentinel &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt; &lt;/dependency&gt; 可以使用/actuator/sentinel断点查看sentinel相关信息。 整合Actuator &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; 需要加入配置才能暴露sentinel端点。 management: endpoints: web: exposure: include: '*' Sentinel控制台 搭建Sentinel控制台 https://github.com/alibaba/Sentinel/releases 生产环境，控制台版本最好和整体版本一致。 启动sentinel控制台 java -jar /Users/kim/Downloads/sentinel-dashboard-1.7.2.jar 默认在localhost:8080端口，用户名密码都是sentinel。 为内容中心整合sentinel控制台 # 指定sentinel 控制台地址 spring.cloud.sentinel.transport.dashboard: localhost:8080 确保nacos、sentinel控制台、内容中心和用户中心都启动了。然后访问http://localhost:8010/shares/1多次，就可以在实时监控里看到效果。 流控规则 点击簇点链路，点击/shares/1的流控按钮，就可以为这个访问路径设置流控规则。 资源名 默认是请求路径。 针对来源 针对调用者限流。针对来源是调用者微服务名称。 阈值类型 QPS、线程数。比如选择QPS，表示：当调用当前资源的QPS达到阈值时，就去限流。 是否集群 流控模式 直接 关联 &lt;1&gt;当关联的资源达到阈值，就限流自己 比如我们设置关联资源为/actuator/sentinel，当关联资源的qps达到1时，就限流/shares/1 写一个测试类，调用/actuator/sentinel public class SentinelTest { public static void main(String[] args) throws InterruptedException { RestTemplate restTemplate = new RestTemplate(); for (int i = 0; i &lt; 10000; i++) { String forObject = restTemplate.getForObject(&quot;http://localhost:8010/actuator/sentinel&quot;, String.class); Thread.sleep(500); } } } 运行这个测试类，再去调用/shares/1,发信啊已经被限流了。 实际应用，如果希望修改优先，可以配置关联API为修改的API，资源名设置为查询的API。当修改的测试过多，就限流查询，保证性能。 链路 只记录指定链路上的流量 流控效果 ","link":"https://xinrong2019.github.io/post/springcloud-alibaba-xue-xi-bi-ji/"},{"title":"网课分享","content":"斯坦福网络安全课 https://web.stanford.edu/class/cs253/ 高级数据结构 https://courses.csail.mit.edu/6.851/fall17/lectures/ MIT计算机科学 https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/ ","link":"https://xinrong2019.github.io/post/wang-ke/"},{"title":"是不是很酷文章摘录","content":"关于提升瓶颈的问题 关于提升瓶颈的问题，可以参考这个问答：https://t.zsxq.com/uRJauBi 如果你做了四年安卓，感觉“技术就那样”，转去做前端，近乎一定也是“就那样”。当然，如果你接触前端，发现你更喜欢前端技术的话，慢慢转去做前端没问题。但具体在什么技术领域，应该不是你现阶段发展的瓶颈。 我的建议是，向上发展，而不是领域迁移。 什么叫向上发展？ 选定安卓或者前端某一个技术领域，去研究大厂的高级别的技术职位，需要达到什么标准？他们简历关看什么？期望你有什么经历？什么技术水平？笔试考什么？对应什么知识？面试又面什么？需要你达到什么水平？找到自己的差距，开始向这个标准努力。 或者，如果对管理岗感兴趣的话，研究一下，在自己所在的企业，从你现在的level，怎么往上升？怎么成为你所在组的 leader？甚至成为整个技术部门的 leader？自己还差什么？ 不是说要你争名夺利。而是说，眼睛应该往更高的地方去看，去思考，去想，去研究，那些你期望的岗位上的人，他们到底为什么能走到那里？他们和自己的差别在哪里？一旦找到这个差别，努力就好了。 我公众号上转载的一篇文章，给你提供一个可能的方向参考： https://mp.weixin.qq.com/s/gzZU-pk-aJNUk0vEixtHPA 关于语言选择的问题 关于语言选择的问题，可以参考这个问答：https://t.zsxq.com/ufAieAy 不要选择语言，而是选择领域。 不过你刚大二，说实话，不用想这么多。依托一两个语言，把基础知识学好，真的最重要。 什么是基础知识？算法，数据结构，操作系统，软件工程，网络，数据库，计算机底层原理（可以参考这里：https://mp.weixin.qq.com/s/h9mnGmIUoht7zRtDh6XD-g ），数学（离散数学为主），等等等等。 这些课程应该也是你们现在课程设计的中心。 这些学好了，应用层的开发真的很简单。你去大厂工作也好，将来考研究生也好，就会发现，主要考查的，也是这些基础内容。 更重要的是，等你真的开始吃技术这碗饭的时候，爬得越高，越会意识到，这些基础知识的掌握，决定着你的技术上限。 加油！：） 系统开发，推荐算法，图像，后端，这些都是方向。C++不是方向，Java同理。 任何语言本身不是一个学习的方向。 一个值钱的架构师，道路应该是陡峭的：但从另一个角度看，任何一个值钱的职业，都应该是陡峭的，不容易的。所以，我建议在选择职业道路的时候，不要想难度。第一看自己的兴趣；第二看市场的需求。 我认为优秀的架构师长期有巨大的市场需求。至于你的兴趣是否在这里，只有你自己知道。 如何应对大龄危机，是一个太过宽泛的问题。我不认为存在一个万能之法，使用它就解决大龄危机问题了。如果这个方法存在的话，大龄危机就不是一个问题了。 关于大龄问题，我也一直在思考，以后可能会形成一篇甚至几篇公众号文章。 不过现在，我对这个问题也没什么经验，毕竟我才 34 岁，还年轻的很：） 天生不聪明 https://mp.weixin.qq.com/s/QvXIDpyrpiOmvEhcOUUmxQ 对聪明的不同看法，会影响人的表现和行为发展。 聪明到底是天生的？还是后天学习来的？ 认为聪明是后天学习来的孩子，学习成绩明显的高于相信聪明是天生的孩子。 相信聪明是天生的学生，数学成绩持续下降；而那些相信聪明是后天的学习可以弥补的学生，数学成绩是不降反升的！ 认知神经科学基础课和补习班 “补习班”——讲解具体的数学知识点。数学考不好？来来来，课后我们多做点儿练习。 “认知神经科学”基础课。课程的内容，主要就是向大家传授当前认知神经科学的最新研究成果：人类的大脑是如何学习到知识的？答案是通过不断的思考。在不断地学习和思考的过程中，人的大脑内部产生着剧烈的神经活动，迫使脑神经之间建立了更多的连接。随着神经元之间连接越来越多，我们对问题的认识也就越来越深刻，遇到类似问题反应也会越来越快。不仅如此，甚至还能触类旁通，举一反三，乃至和其他的领域结合，产生创新性的想法。这表现出来，就是你更聪明了。 维生素B族都是水溶性维生素，它们有协同作用，调节新陈代谢，维持皮肤和肌肉的健康，增进免疫系统和神经系统的功能，促进细胞生长和分裂（包括促进红血球的产生，预防贫血发生）。其中维生素B1、B6和B12有助保护神经组织细胞，维生素B2则具有抗氧化作用，而植物能合成维生素B2，动物一般不能合成，必须由食物获得维生素B2，而维生素B2是维持动物正常生长所必需的元素之一，如果缺乏则有可能造成生长停顿，或局部损害。 补充维生素B不会让你更聪明，但是会在你需要的时候促进神经系统产生连接。 我们对聪明的看法，会影响，甚至是严重影响我们的表现！ 聪明不是固定的。只要你相信聪明是靠努力可以弥补的，并且努力下去，你就会变聪明。 我们现在可以回到文章开头的问题了：觉得算法好难，自己不够聪明，要花好长时间才能理解一个算法，刷题效率也很低，半天能过一道题就不错了，我该怎么办？ 对此，我的回答是：对不起，我没有更好的方法。并且，我坚信，不仅我没有，这个世界上根本不存在这样的一个方法。我经常使用反证法来阐述这个问题：假设这个世界存在一个简单、可行、快速、高效的学会算法的方法，那么，所有的人早就使用这个方法学习算法了，所有的人也早就成为算法大神了，算法也就不是什么让人头疼的事情了。可这是和现实不相符的。所以，这个方法不存在：） 以上证明不仅适用于算法学习，对各个领域的学习都适用。 但是，如果能给你一点安慰的话，我想实话告诉你：在我刚开始接触算法的时候，我也觉得算法好难，自己不够聪明，要花很长时间才能理解一个算法，刷题效率也特别低，别说半天一道题了，一个礼拜死磕一道题都是家常便饭。 或许，你我都是天生不聪明的人。 不过，好在，天生不聪明似乎并没有什么关系。因为，只要你相信聪明是靠努力可以弥补的，并且努力下去，你终将变得很“聪明”。甚至，你会超越这种“聪明”，理解一个很嘻哈又很深刻的道理：聪明不是什么大不了不起的事儿：） 选择和努力同样重要 我用了这么长的文章，回答了一个问题。其实最后答案是一句废话：要努力。换句文绉绉的表示法，就是：万事无他，唯手熟尔。 当然，我也承认，只是努力，可能并不够。或者说，至少，还有改进的余地。人生是一个维度极其丰富的过程，用任何一个单一维度去解释它，都是极其幼稚可笑的。比如，我就认为，另外一个非常重要的维度，叫做“选择”。我们经常听到互联网上的一种声音：选择大于努力。对于这个观点怎么看？大家可以期待一下我的一篇文章，我会聊聊我对于“选择”的看法。 但是，在这篇文章里，作为计算机专业的同学，如果想学好算法，将来成为一个计算机科学领域的大神，并且你已经深刻地明白了努力就能更聪明，却不知如何选择从哪里开始努力的话... 咳咳咳，我建议大家从选择我在慕课网上的算法课程开始：） 如果高效学习有什么秘诀的话，那就都在这里了：） 不要完美主义 **学习不是要么0分，要么100分的。**80分是收获；60分是收获；20分也是收获。有收获最重要。但是因为着眼于自己的不完美，最终放弃了，那就是彻底的0分了。 仔细想，这种“完美主义害死人”的例子特别多。我看到过很多同学，其实是在学习的路上，被自己的“完美主义”逼得“放弃了”——由于学习中有一点没有做好，遭受到了一点点挫折，最终就放弃了整个学习计划。每个人都一定要接受自己的不完美。想开一点：我们都不是小升初考了满分，才能上初中的；也不是中考考了满分，才能读高中的；更不是高考考了满分，才能念大学的；将来也不会是大学所有科目都是满分，才能出来工作。不完美其实是常态，根本不会影响我们学习更多更深入的内容。但是在自学过程中，很多同学却要求自己在自己制定的每一步计划中都达到“完美”，才进行下一步。最终结果，通常都是“放弃”。 可能有的同学会跳出来反驳我：学习当然要认真啊！在这里，我必须强调，我所说的“不要完美主义”，和“学习认真”是不冲突的。什么是“完美主义”，什么又是“囫囵吞枣”，这是一个“度”，每个人其实不一样。不要“完美主义”，不代表学习可以草率前行。每个人都必须要找到适合自己的学习节奏。我的经验是：在自己又因为自己的学习进度而沮丧的时候，问自己一句：是不是自己又犯“完美主义”的毛病了：） 不要过度依赖“学习路径”，学习要冲着自己的目标去。 比如，很多同学想学机器学习，大多数学习路径都会告诉你，机器学习需要数学基础。于是，很多同学就转而学习数学去了，非要先把数学学好再去学机器学习。可是发现数学怎么也学不好（在这里，可能完美主义的毛病又犯了），而机器学习却一点儿都没学。最终放弃了机器学习，非常可惜。其实，如果真正去接触机器学习，就会发现，至少在入门阶段，机器学习对数学的要求没有那么高。正因为如此，我一直建议：只要你在本科接触过高数，线数，概率这些科目的基础概念，想学机器学习，就去直接学习机器学习。学习过程中发现自己的数学不够用，再回头补数学。在这种情况下，数学学习得也更有目标性，其实效果更好。 类似这样的例子还有很多，很多同学想学习做ios app，就先去精通swift语言，或者想做android app，就先去精通java语言。在我看来大可不必。以我的经验，只要你有一门编译型语言基础，大概看一下这些语言的基础语法，就可以直接上手ios或者android app的开发了。先能做出一个最基本的app，在这个过程中，就会意识到语言特性的意义，再回头深入研究语言也不迟。此时还能结合真实的开发任务去理解语言特性，比没有上手app开发，抽象地理解语言特性，有意义的多。 再比如，我的《算法与数据结构》课程和《玩转算法面试》课程，在视频中都是使用C++进行编码的。虽然我一再强调对于算法的学习，语言不重要，但还是有很多同学表示，要先把C++学透，再回来把课程中的算法学好。这是完全没必要的。事实上，在我的这两门课程中，我看到的收获最大的同学，是那些能够把课程中的算法思想理解清楚，然后用自己熟悉的语言去实现的同学：） 依然是：不要“过度”学习路径依赖，什么叫“过度”，每个人的标准不一样。每个人都需要寻找自己的那个“度”。 不要迷信权威的“好”教材。 不是说权威教材不好，而是每一本教材都有其预设的读者群，如果你不在这个预设的读者群的范畴里，教材再好也没用。最简单的例子：再好的高数教材，对于小学生来说，都是一堆废纸。 诚然，算法不容易，但是，一上来就抱着《算法导论》啃，实在是选择了一条完全没必要的，更难的，甚至可能是根本走不通的路。对于一个领域的学习，了解市面上有什么好的教材是必要的，单也不能迷信权威教材。每个人必须要去探索学习如何寻找适合自己的学习材料。 不要看不起“薄薄”的“傻”教材，这些你看不起的学习材料，可能是你入门某个领域的关键。 在这里，关键字是够“薄”。因为“薄”的教材能让你以最快的速度看完，对整个学科有一个全盘的认识：这个领域是做什么的？解决什么问题了？整体解决问题的思路是怎样？解决问题的方法大致是怎样划分的？一些最基础的方法具体是怎样的。这些在初学阶段是至关重要！是让你全盘把握整个领域脉络的。虽然通过这么一本薄薄的教材，你的脉络把握肯定不够全面细致，但比没有强太多！ 我看过不少同学，一上来学习《算法导论》，关于复杂度分析的笔记做了好几页，然后就放弃了，可是连什么是动态规划都不知道。这样完全没有对“算法”这个领域有全面的认识，甚至可以说根本没有学过“算法”！先用薄教材入门，再找“厚”教材，细细体会其中的细节，是我百试不爽的学习方法。 另外，在这里，我还要强调“入门教材”，很多教材虽然够“薄”，但不是“入门教材”。大家要注意。 不要迷信单一教材。 在大多数情况下，学习不是一本固定教材可以搞定的。非要找到一本“最适合自己的”教材，然后就一头扎进去，其实是不科学的。 大多数同学喜欢仅仅扎进一本书里，一旦选定了自己的学习材料，就对其他材料充耳不闻，甚至是排斥的心理。这种做法，一方面又是“完美主义”的表现——非要把这本教材学透；另一方面，其实也是“犯懒”的表现，不愿意多翻翻，多看看，自己多比较比较，自己去寻找最适合自己的材料，一味地盲目相信所谓“大神”的推荐，殊不知，这些推荐，不一定是更适合自己的材料；更何况，还有很多大神，明明是靠不出名的“薄”教材入的门，但给别人做推荐的时候，就突然变成自己是算法奇才，自幼阅读《算法导论》而所成的神话了：） 实践！ 前面说了很多和教材选择相关的话题，但**对于计算机领域的学习来说，教材的意义其实远远小于实践的意义。**如果仅仅是看学习材料就是学习的话，那么教学网站的视频后期处理人员就是水平最高的工程师了。因为每段视频，他们都需要看一遍。但是，很显然，仅仅是看视频，是无法学到知识的。**对于计算机领域的学习来说，真正动手实践去编程是异常重要的。怎么夸大其中的作用都不过分。**这就好比学游泳，必须下水去游泳；或者学开车，必须亲自上路。否则你说的再头头是道，一个小学生文化水平的人，只要他开过车，游过泳，都能在这两个领域瞬间秒杀你。 很多同学都说我的算法讲得好，其实，我一直认为，这其中的一个最简单的秘诀就是：我带领大家把大多数算法都非常细致的实现了一遍；或者对其中的应用进行了非常具体的实践。反观大多数高校教育，对于算法或者机器学习这种一定程度偏理论的学习，通常非常不强调实践。最终的结果是学习者只是接受了很多抽象的概念，但对其中具体的实现细节，却是云里雾里。我见过太多同学，都明白什么是O(n2)复杂度，什么是O(nlogn)的复杂度，却问我对于100万的数据规模，为什么自己的选择排序运行起来就没反应了。答案很简单：O(n2)的复杂度太慢了，100万的数据规模太大了，一般家用计算机转选择排序一时半会儿是转不完的。这些同学一定理解O(n^2)的算法比O(nlogn)的算法慢，却没有真正实践过，不知道这个差距到底是多少。 在我的课程中，经常遇到有些同学提出这样的问题：这个算法的某句话（或者某段逻辑），为什么要写成A的样子，而不是B的样子？这种问题其实很好，但我觉得解决方法也很简单，实际的去把算法改写成B的样子，实际的运行试试看，看会发生什么。如果发生了错误，仔细分析一下，为什么会有错误？如果没有错误，具体比较一下：A和B两种不同的写法，为什么都正确？又有什么区别？**真正的学习上的提高，就发生在这个过程中。**我当然可以告诉给同学们一个结果，但是自己亲自实践一遍，相比阅读我给出的一个答案，自己对其中问题理解的深刻程度，是完全不可比拟的。 debug非常非常重要。 我看到的另一类“经典”问题就是：老师，这个代码为什么错了，然后贴一大段代码。这种问题背后，依然是，透露着学习方法的不对劲：提问的同学懒得debug。**在计算机领域，debug近乎和实践是一个意思。**如果只是把材料上的代码“抄”一遍，这不叫实践，这叫抄代码。小学生也能做。但是“抄”一遍，不小心没抄对，发生了错误，然后自己一点一点调试，找到错误的根源，这叫真的实践。小学生不能做。（当然，自己理解了算法的逻辑，按照自己的理解，把算法写出来，才是终极目的：） 不过很多同学不喜欢debug，我当然理解。其实谁都不喜欢debug，但是，debug才是最重要的能力。**通常在一个领域里，你最不喜欢做的事情，就是这个领域的核心竞争力！**我见过的所有计算机领域的“高手”，不管是在哪个细分领域，都无一例外，是个debug好手。我经常告诉大家，在实际工作中，其实debug的时间要占你真正编程时间的70%。如果你做一个项目，根本不需要debug，要么是你的项目对你来说太简单了，要么是你根本没有接触到这个项目的核心。 debug不仅仅是找到代码错误，解决错误的手段，其实更是一个重要的学习手段。通过debug，看看自己写的程序执行逻辑，哪里和自己设想的不一致？再回头看自己哪里想错了，或者想漏了，分析一下自己为什么想错了，或者想漏了，等等等等，依然是，进步就是发生在这个过程的。 在我的算法课程中，很多同学对递归想不明白，我的建议都是：用一个小数据量，一步步跟踪程序，看看程序到底是怎么运行的。通常这么做，1个小时的时间，就足以让你深刻理解递归程序的运转逻辑。可是，很多同学懒得花这1个小时的时间，最终的结果是，花了一个下午，对着代码生看，硬想，最终还是没有理解程序的运转逻辑。 量变到质变。 还有很多同学，对于算法的一些问题，会问：老师，你是怎么想到用这样的方法的？对于这类问题，我的回答一般都是：你见的还不够多。 不知道是不是受高中阶段学习的影响，有一些同学特别执着于就着一个单一的问题，寻找其中的“解题路径”。当然，我不是说这是完全错误的，但也有一个“度”。我的经验是：与其把时间花在这里，不如去见更多问题。比如动态规划，是算法学习的一个难点，很多同学在学会了背包问题的解法之后，总是执着于去追寻：是怎么想到这种状态定义的方法的。可能是我个人水平有限，我无法清楚地解释是如何想到这种状态定义的方法的。但是我的经验告诉我：再去看，去实践100个动态规划相关的问题，然后回头看背包问题，你会发现这种状态定义的方式非常自然。**仅仅对着一个问题思考，很多时候都是死胡同。你见识的还不够多，就不足以帮助你总结出更加“普遍”的问题解决的规律。**当你见得足够多的时候，一切就都变得很自然，所谓的“量变到质变”。 不过，大多数同学在这个环节都会“犯懒”，企图通过一个问题就理解问题的本质，这其实和企图通过一本教材就精通一个领域的想法是一样的，是不现实的，不可能的。同时，这里又包含着学习过程中的“完美主义”的思想，遇到一个问题一定要把它想的无比透彻。但是我的经验告诉我：**大多数问题，其实都是需要“回头看”的。随着你对一个领域理解的越深入，回头再去看那些曾经的问题，都会产生新的视角，对于很多曾经想不明白的问题也豁然开朗。这也是“进步”的根源。**如果卡在一个问题上不前进，不给自己“回头看”的机会，甚至最后是放弃了，就什么也没有学会了。 所以，很多时候，你发现对一些问题“百思不得其解”，或许不是因为自己“笨”，而是因为“还不够努力”：） 最后，一定要相信时间的力量。 有一天，在我的一个算法课程群里，有个滴滴的后端大神发招聘，结果大家七嘴八舌的就议论开了，大致主题思想就是：自己什么时候能够成为滴滴的后端大神。这位滴滴的后端大神今年32岁；大多数议论的同学，其实连22岁都不到。我告诉他们，其实10年后，你们就是大神。 这其实很好理解，回想十年前，也就是12岁的你，和现在的你比较，是不是天壤之别？如果把你扔到一堆12岁的小朋友中间，22岁的你是不是就是个大神？同理，32岁的人，已经在业界摸爬滚打了那么多年，扔回到22岁的大学生中间，当然是大神：） 很多时候，所谓的“大神”并不神秘，仔细观察他们的经历，会发现时间有着不可磨灭的作用。只要你没有虚度时间，每天都在进步，通常结果都不会太差的。如果再加上一点点机遇，就是大神。 想了解计算机的底层原理？这些资源通俗易懂又有趣 大家可以关注一下波波老师的公众号和知识星球：是不是很酷 总结 ","link":"https://xinrong2019.github.io/post/shi-bu-shi-hen-ku-wen-zhang-zhai-lu/"},{"title":"Mac工作环境搭建","content":"目录 [TOC] App软件 WPS 有道云笔记 CleanMyMac X Visual studio code uPic Typora Tencent Lemon Snagit2020 ShadowsocksX-NG-R8 QQ 微信 钉钉 Polarr Photo Editor Pro PDF Expert Parallels DeskTop Navicat Premium Motrix Mark Text Little Snitch Kap IntelliJIDEA IINA Google Chrome GoLand Firefox eZip CotEditor Clion Araxis Merge Android 文件传输 Kantu Jietu 百度网盘 软件环境 JDK HomeBrew Git Gradle Maven GoLang vim配置 cd vi .vimrc ##i进入编辑模式 # 显示行号 set number # 检测文件类型 filetype on # 开启语法高亮 syntax on # 支持使用鼠标 set mouse=a # 按下回车键后，下一行的缩进会自动跟上一行的缩进保持一致。 set autoindent # 按下 Tab 键时，Vim 显示的空格数 set tabstop=2 # 由于 Tab 键在不同的编辑器缩进不一致，该设置自动将 Tab 转为空格 set expandtab # 是否显示状态栏。0 表示不显示，1 表示只在多窗口时显示，2 表示显示 set laststatus=2 # 在状态栏显示光标的当前位置（位于哪一行哪一列） set ruler ##按esc键，退出编辑模式，输入:wq 安装HomeBrew 常用命令 brew list # 查看已经安装的包 brew update # 更新Homebrew自身 brew doctor # 诊断关于Homebrew的问题(Homebrew 有问题时请用它) brew cleanup # 清理老版本软件包或者无用的文件 brew show ${formula} # 查看包信息 brew search ${formula} # 按名称搜索 brew upgrade ${formula} # 升级软件包 brew install ${formula} # 按名称安装 brew uninstall ${formula} # 按名称卸载 brew pin/unpin ${formula} # 锁定或者解锁软件包版本，防止误升级 terminal配置(zsh配置) .bash_profile alias rm='rm -i' alias cp='cp -i' alias mv='mv -i' alias l='ls -alHh' alias ..='cd ../' alias ...='cd ../../' export HOMEBREW_BOTTLE_DOMAIN=https://mirrors.ustc.edu.cn/homebrew-bottles Mac默认安装了zsh，下载oh-my-zsh简化配置，如果没安装，使用brew安装 # 安装 zsh brew install zsh # 查看当前使用的 shell echo $SHELL # 切换 shell chsh -s /bin/zsh # 安装wget，安装oh-my-zsh用 brew install wget # 安装oh-my-zsh wget https://github.com/robbyrussell/oh-my-zsh/raw/master/tools/install.sh -O - | sh # 安装完后重启终端 zsh主题 ZSH_THEME=&quot;af-magic&quot; plugins=( git zsh-syntax-highlighting zsh-autosuggestions last-working-dir z ) export GRADLE_USER_HOME=/Users/akm/.gradle HIST_STAMPS=&quot;yyyy-mm-dd&quot; 在.zshrc文件中应用用户环境变量 # .zshrc文件最后添加下面一行 source ~/.bash_profile 更新zsh配置 # 更新配置 source ~/.zshrc uPic安装配置 Git安装和配置 Finder配置 拷贝路径 在终端打开 Mac其他 显示隐藏文件 Maven settings.xml &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;settings xmlns=&quot;http://maven.apache.org/SETTINGS/1.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd&quot;&gt; &lt;pluginGroups&gt; &lt;/pluginGroups&gt; &lt;proxies&gt; &lt;/proxies&gt; &lt;servers&gt; &lt;/servers&gt; &lt;mirrors&gt; &lt;mirror&gt; &lt;id&gt;aliyunmaven&lt;/id&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;name&gt;阿里云公共仓库&lt;/name&gt; &lt;url&gt;https://maven.aliyun.com/repository/public&lt;/url&gt; &lt;/mirror&gt; &lt;mirror&gt; &lt;id&gt;aliyunmaven&lt;/id&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;name&gt;阿里云谷歌仓库&lt;/name&gt; &lt;url&gt;https://maven.aliyun.com/repository/google&lt;/url&gt; &lt;/mirror&gt; &lt;mirror&gt; &lt;id&gt;aliyunmaven&lt;/id&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;name&gt;阿里云阿帕奇仓库&lt;/name&gt; &lt;url&gt;https://maven.aliyun.com/repository/apache-snapshots&lt;/url&gt; &lt;/mirror&gt; &lt;mirror&gt; &lt;id&gt;aliyunmaven&lt;/id&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;name&gt;阿里云spring仓库&lt;/name&gt; &lt;url&gt;https://maven.aliyun.com/repository/spring&lt;/url&gt; &lt;/mirror&gt; &lt;mirror&gt; &lt;id&gt;aliyunmaven&lt;/id&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;name&gt;阿里云spring插件仓库&lt;/name&gt; &lt;url&gt;https://maven.aliyun.com/repository/spring-plugin&lt;/url&gt; &lt;/mirror&gt; &lt;/mirrors&gt; &lt;profiles&gt; &lt;/profiles&gt; &lt;/settings&gt; ","link":"https://xinrong2019.github.io/post/mac-gong-zuo-huan-jing-da-jian/"},{"title":"Gradle高级应用","content":"构建脚本介绍 Gradle构建中的两个基本概念是项目（project）和任务（task），每个构建至少包含一个项目，项目中包含一个或多个任务。 在多项目构建中，一个项目可以依赖于其他项目；类似的，任务可以形成一个依赖关系图来确保他们的执行顺序。 项目-任务关系 上图是一个项目任务关系图。 Project1依赖Project2 Project1中，TaskA依赖TaskB和TaskC Project2中，TaskF依赖TaskE，TaskE依赖TaskD 项目 一个项目代表一个正在构建的组件（比如一个jar文件），当构建启动后，Gradle会基于build.gradle实例化一个org.gradle.api.Project类，并且能够通过project变量使其隐式可用。 group、name、version apply、dependencies、repositories、task 属性的其他配置方式：ext、gradle.properties 任务 任务对应org.gradle.api.Task。主要包括任务动作和任务依赖。任务动作定义了一个最小的工作单元。可以依赖于其他任务、动作序列和执行条件。 任务中的方法举例： dependsOn doFirst、doLast 自定义任务 自动创建test目录结构 1.在build.gradle文件中，添加任务 def createDir = { path -&gt; File dir = new File(path) if(!dir.exists()){ dir.mkdirs() } } task makeJavaDir(){ def paths = ['src/test/java','src/test/resources'] doFirst { paths.forEach(createDir) } } 2.重新导入依赖 不重新导入依赖，可能会看不到自定义任务 3.在Tasks-&gt;other下执行makeJavaDir 自定义创建web目录 1.在build.gradle文件中，添加任务 task makeWebDir(){ dependsOn 'makeJavaDir'//依赖任务makeJavaDir def paths = ['src/main/webapp','src/test/webapp'] doLast { paths.forEach(createDir) } } 这里第二行我们使用dependsOn方法，依赖我们上一个任务makeJavaDir。这样在创建web目录时，可以把test目录也创建好。 2.重新导入依赖 不重新导入依赖，可能会看不到自定义任务 3.在Tasks-&gt;other下执行makeWebDir 构建的生命周期 理解构建的生命周期，生命周期通常会暴露扩展点，以供开发者使用，影响构建的行为，创建灵活的功能。 初始化 初始化项目，决定有哪些项目参与到构建过程中 配置 生成Task的执行关系和执行图 执行 执行Task的动作 依赖管理 概述 几乎所有的基于JVM的软件项目都需要依赖外部类库来重用现有的功能。自动化的依赖管理可以明确依赖的版本，可以解决因传递性依赖带来的版本冲突。 工件坐标 group、name、version 常用仓库 mavenLocal/mavenCentral/jcenter 自定义maven仓库 文件仓库 依赖的传递性 B依赖A，如果C依赖B，那么C依赖A 自动化依赖管理 首次使用jar，会从远程仓库下载到本地仓库； 如果多次使用相同的jar，会缓存到本地缓存 依赖阶段配置 compile、runtime testCompile、testRuntime 依赖阶段关系 添加logback编译时依赖 compile 'ch.qos.logback:logback-classic:1.2.1' 解决版本冲突 版本冲突例子 解决冲突 查看依赖报告 排除传递性依赖 强制指定一个版本 注意：gradle会默认解决版本冲突，使用最高版本的冲突依赖。 修改默认解决策略 configuration.all{ resolutionStrategy{ failOnVersionConflict() } } 让版本冲突出现时报错，让我们知道。 排除传递性依赖 compile('org.hibernate:hibernate-core:3.6.3.final'){ exclude group:&quot;org.slf4j&quot;,module:&quot;slf4j-api&quot; //transitive = false } 其中module，就是name。 强制指定一个版本 configuration.all{ resolutionStrategy{ force 'org.slf4j:slf4j-api:1.7.24' } } 多项目构建介绍 项目模块化 在企业项目中，包层次和类关系比较复杂，把代码拆分成模块通常是最佳实践，这需要你清晰的划分功能的边界，比如把业务逻辑和数据持久化拆分开来。项目符合高内聚低耦合时，模块化就变得很容易，这是一条非常好的软件开发实践。 TODO模块依赖关系 配置要求 所有项目应用Java插件 web子项目打包成war 所有项目添加logback日志功能 统一配置公共属性 项目拆分，gradle多项目构建 1.新建两个模块，都是gradle项目 1.1 右键点击根目录todo，new-&gt;Module 1.2 新建gradle模块，点击next 1.3 填入模块名，然后next，再next 1.4 按照上面三步建立model、repository和web模块 1.5 根目录下的setting.gradle文件中会有gradle管理的项目描述 rootProject.name = 'todo' include 'model' include 'repository' include 'web' 1.6添加模块依赖 我们的项目repository模块依赖model模块，web模块依赖repository模块。 所以需要在repository模块中添加model模块的依赖，在web模块中添加repository模块依赖。 dependencies { compile project(&quot;:model&quot;) testCompile group: 'junit', name: 'junit', version: '4.12' } dependencies { compile project(&quot;:repository&quot;) testCompile group: 'junit', name: 'junit', version: '4.12' } 多项目构建实战 1.所有项目中应用Java插件 将子模块的java插件配置都删除，在根项目中使用allprojects方法应用 group 'com.kim.gradle' version '1.0-SNAPSHOT' allprojects { apply plugin:'java' sourceCompatibility = 1.8 } repositories { mavenCentral() } //省略其他配置 2.web子项目打包成war 个性化需求，给web子模块应用war插件 3.所有项目添加logback日志功能，包括Junit allprojects { apply plugin:'java' sourceCompatibility = 1.8 } subprojects { repositories { mavenCentral() } dependencies { compile 'ch.qos.logback:logback-classic:1.2.1' testCompile 'junit:junit:4.12' } } 这里用subprojects可以达到同样的效果 4.统一配置group和version 在根目录下新建gradle.properties文件，加入这两个属性。 group=com.kim.gradle version=1.0-SNAPSHOT 同时，子模块中删除这两个属性。 5.执行root项目的clean任务 执行root项目的clean任务，观察执行顺序。 &gt; Task :clean &gt; Task :model:clean UP-TO-DATE &gt; Task :repository:clean UP-TO-DATE &gt; Task :web:clean 自动化测试 1.测试配置 dependencies { testCompile 'junit:junit:4.12' } 2.测试发现 gradle是如何发现哪些类或方法是测试类的呢 任何继承自junit.framework.TestCase或groovy.util.GroovyTestCase的类 任何被@RunWith注解的类 任何至少包含一个被@Test注解的类 发布 配置发布插件 allprojects { apply plugin:'java' sourceCompatibility = 1.8 apply plugin: 'maven-publish' publishing { publications { myPublish(MavenPublication){ from components.java } } repositories { maven { name &quot;myRepo&quot; url &quot;&quot; } } } } 发布到本地仓库 发布到公司私服 在发布插件配置中配置公司私服的url，然后执行publish这个任务 项目源码 ","link":"https://xinrong2019.github.io/post/gao-ji-ying-yong/"},{"title":"第一个Gradle项目","content":"示例介绍 TODO应用程序，只实现添加待办事项 Java应用程序版 Web版 Java应用程序版 启动类 package com.kim.gradle.todo; import java.util.Scanner; public class App { public static void main(String[] args) { int i = 0; Scanner scanner = new Scanner(System.in); while (++i &gt; 0){ System.out.println(i + &quot;. please input todo item name&quot;); ToDoItem item = new ToDoItem(scanner.nextLine()); System.out.println(item); } } } ToDoItem package com.kim.gradle.todo; public class ToDoItem { private String name; private boolean hasDone; public String getName() { return name; } public void setName(String name) { this.name = name; } public boolean isHasDone() { return hasDone; } public void setHasDone(boolean hasDone) { this.hasDone = hasDone; } public ToDoItem(String name) { this.name = name; } @Override public String toString() { return &quot;ToDoItem{&quot; + &quot;name='&quot; + name + '\\'' + &quot;, hasDone=&quot; + hasDone + '}'; } } 打jar包 控制台中运行程序 java -classpath build/libs/todo-1.0-SNAPSHOT.jar com.kim.gradle.todo.App 1. please input todo item name kim ToDoItem{name='kim', hasDone=false} 2. please input todo item name Web版 添加war插件 在build.gradle文件中添加war插件 plugins { id 'java' id 'war'//添加的内容 } //apply plugin:'java' //apply plugin:'war' group 'com.kim.gradle' version '1.0-SNAPSHOT' sourceCompatibility = 1.8 repositories { mavenCentral() } dependencies { testCompile group: 'junit', name: 'junit', version: '4.12' } plugins方法也可以由apply方法替换 打war包 打包后，在项目根目录/build/libs下会生成war包，将war复制到一个servlet容器中，比如tomcat的webapp目录下，运行即可。 ","link":"https://xinrong2019.github.io/post/di-yi-ge-gradle-xiang-mu/"},{"title":"查询性能优化","content":"6.1 为什么查询速度会慢 6.2 慢查询基础：优化数据访问 6.2.1 是否向服务器请求了不需要的数据 6.2.2 MySQL是否在扫描额外的记录 6.3 重构查询的方式 ","link":"https://xinrong2019.github.io/post/cha-xun-xing-neng-you-hua/"},{"title":"创建高性能的索引","content":"5.1 索引的基础 5.1.1 索引的类型 5.2 索引的优点 5.3 高性能的索引策略 5.3.1 独立的列 5.3.2 前缀索引和索引选择性 5.3.3 多列索引 5.3.4 选择合适的索引列顺序 5.3.5 聚簇索引 5.3.6 覆盖索引 5.3.7 使用索引扫描来做排序 5.3.8 压缩（前缀压缩）索引 5.3.9 冗余和重复索引 5.3.10 未使用的索引 5.3.11 索引和锁 5.4 索引案例学习 5.4.1 支持多种过滤条件 5.4.2 避免多个范围条件 5.4.3 优化排序 5.5 维护索引和表 5.5.1 找到并修复锁坏的表 5.5.2 更新索引统计信息 5.5.3 减少索引和数据的碎片 5.6 总结 ","link":"https://xinrong2019.github.io/post/chuang-jian-gao-xing-neng-de-suo-yin/"},{"title":"Schema与数据类型优化","content":"良好的逻辑设计和物理设计是高性能的基石，应该根据系统将要执行的查询语句来设计schema，这往往需要权衡各种因素。 例如，反范式的设计可以加快某些类型的查询，但同时可能使另一些类型的查询变慢。比如添加计数表和汇总表是一种很好的优化查询的方式，但这些表的维护成本可能会很高。 本章主题是schema设计，主要是MySQL数据库的设计，是接下来两章的铺垫。阅读顺序建议先看本章，再顺序看后两章，再回头看看本章。 4.1 选择优化的数据类型 4.1.1 整数类型 4.1.2 实数类型 4.1.3 字符串类型 4.1.4 日期和时间类型 4.1.5 位数据类型 4.1.6 选择标识符（identifier） 4.1.7 特殊类型数据 4.2 MySQL schema设计中的陷阱 4.3 范式和反范式 4.3.1 范式的优点和缺点 4.3.2 反范式的优点和缺点 4.3.3 混用范式化和反范式化 4.4 缓存表和汇总表 4.4.1 物化视图 4.4.2 计数器表 4.5 加快alter table操作的速度 4.5.1 只修改.frm文件 4.5.2 快速创建MyISAM索引 4.6 总结 ","link":"https://xinrong2019.github.io/post/schema-yu-shu-ju-lei-xing-you-hua/"},{"title":"掌握Gradle构建工具","content":"学习动机： 目前开发的项目使用的构建工具是gradle，最初搭建项目骨架的时候是参照已有gradle项目配置搭建的，遇到问题基本上是靠搜索引擎搜索，对gradle的认知仅仅停留在会使用，想要进一步提高，或者有一个成体系的认知。 学习目的： 正文 目前主流构建工具 Gradle是什么 一个开源的项目自动化构建工具，建立在Apache Ant和Apache Maven概念的基础上，并引入了基于Groovy的特定领域语言（DSL），而不是使用XML形式管理构建脚本。 学习安排 快速尝鲜 准备使用Gradle 第一个Gradle项目 基本原理 构建脚本介绍 依赖管理 深入实战 多项目构建 测试 发布 准备使用Gradle 安装 安装和配置好JDK 从官网下载Gradle 配置环境变量，GRADLE_HOME 添加到path，%GRADLE_HOME%\\bin 验证是否安装成功，gradle -v Groovy基础知识 Groovy是什么 Groovy是用于Java虚拟机的一种敏捷的动态语言，它是一种成熟的面向对象编程语言，既可以用于面向对象编程，又可以用作纯粹的脚本语言。使用该种语言不必编写过多的代码，同时又具有闭包和动态语言中的其他特性。 与Java比较 完全兼容Java的语法 分号是可选的 类、方法默认是public的 编译器给属性自动添加getter/setter方法 属性可以直接用点号获取 最后一个表达式的值会被作为返回值 ==等同于equals()，不会有NullPointerExceptions 高效的Groovy特性 assert语句 可选类型定义 可选的括号 字符串 集合API 闭包 使用IDEA创建Gradle项目 1. New Project 2. 写上GroupId和ArtifactId 3. 填写Project Name，点击Finish完成 4. 打开Groovy Console 5. 验证Groovy语法 public class ProjectVersion{ private int major private int minor ProjectVersion(int major, int minor) { this.major = major this.minor = minor } } ProjectVersion v1 = new ProjectVersion(1,1) println v1.minor ProjectVersion v2 = null; v2 == v1 执行结果： 上面可以看到v2==v1的表达式返回false，其实调用的是Object类的equals方法。 Groovy高级特性实操 def version = 1 assert version == 1 println version //字符串 def s1 = 'Eucaly' def s2 = &quot;gradle version is ${version}&quot; def s3 = '''my name is Eucaly''' println(s1) println(s2) println(s3) //集合api def buildTools = ['ant','maven'] buildTools &lt;&lt; 'gradle' assert buildTools.getClass() == ArrayList assert buildTools.size() == 3 def buildYears = ['ant':2000,'maven':'2004'] buildYears.gradle = 2009 println(buildYears.ant) println(buildYears['gradle']) println(buildYears.getClass()) println(buildYears) //闭包,经常被当作方法参数使用 def c1 = { v -&gt; print v } def c2 = { print 'hello' } def method1(Closure closure){ closure('param') } def method2(Closure closure){ closure() } method1(c1) method2(c2) 读懂Groovy构建脚本 apply plugin:'java' version ='0.1' repositories { mavenCentral() } dependencies { compile 'common-codec:commons-condec:1.6' } 上面的脚本代码通常是项目中build.gradle文件中的构建代码模板，下面从groovy脚本的角度来一句句分析是什么意思。 构建脚本中默认都有一个Project实例，脚本中默认的作用域都是Project apply plugin:'java' plugin:'java'是命名参数，意思是plugin参数的值是java； apply是Project实例中的方法,这里调用apply方法，省略了括号。 version ='0.1' version是Project实例中的一个属性 repositories { mavenCentral() } repositories也是Project实例中的方法，入参是一个闭包； 整个花括号部分代码块{mavenCentral()}是一个闭包。 dependencies { compile 'common-codec:commons-condec:1.6' } dependencies也是Project实例中的方法，入参是一个闭包 ","link":"https://xinrong2019.github.io/post/zhang-wo-gradle-gou-jian-gong-ju/"},{"title":"好好说话：自己顺心，对方舒服","content":"一、怎样说话让人舒服？ 1、说出对方说过的话，也就是重复对方的语言 哎呀，最近长胖啦，你看，都没有腰啦！ 嗯，确实长胖了，我听说仰卧起坐可以瘦腰，你要不试试？ 哎呀，最近长胖啦，你看，都没有腰啦！ 你最近长胖了吗？我看看呢.... 2、说出对方想听的话，也就是说出对方的期待 既要情境式的推断，还要明确沟通的目的。 当沟通是为了解决问题时，适当的表达自己积极情绪，进而婉转提出你的建议或者给出判断，会让对方更加愉悦地接受你的观点。 3、说出对方想说的话，也就是顺情说话 说出对方不好意思或没来得及说的话。 需要换位思考，理解对方的难处，第一时间告诉他，从而触动他的内心，进而让他愿意配合你的需求。 有应聘者想电话问询公司HR，关于面试结果的问题，他们一般会这样问： 您好！我知道您很忙，我长话短说... 再如，有经验的销售员，会第一时间说出你的担忧和顾虑： 您最近买车可能被汽车漏油事件给吓到了，您别担心，这是极小概率事件。我们一定引以为戒，为您做好百分之百的全面检测，如有任何质量问题，以一赔三。 二、如何表达自己的真实想法？ 第一、表达事实，不做主观评价 比如，你的室友喜欢熬夜看小说、打游戏，影响了你的正常作息，你会怎样和室友沟通呢？ 你作息习惯很不规律，熬夜看小说、打游戏，影响了我休息。 我们俩作息习惯不一样，不知怎样调整配合一下呢？ 上面的说法，&quot;很不规律&quot;是一种主观评价，室友听了多半会有抵触情绪。 换个说法，只讨论作息习惯的调整问题，没有任何评价，室友听了会一起思考问题，参与解决问题。 那以后你休息，等你睡着了，我再看小说、打游戏试试？ 这至少从解决问题的角度向前迈进了一步。 第二、表达感受，解释感受来源 不仅表达了“辛苦了”、“真谢谢你！”，还解释了这些感受来源，像“打开水、取快递、寄包裹”，“节约了很多时间”等细节。 第三、表达需求，引导对方配合 你需要告诉对方“看哪里”，对方才知道“怎样做”。 比如，你写过一篇关于面试的公众号推送，想拿给身边的同学，帮你提一些建议，你会怎样表达？ 麻烦你帮我看看这篇推送，假设你正在求职，帮我提些修改建议号码？ 在向对方表达需求时，只有告诉对方“看哪里”，才能更好地引导对方配合自己，完成任务。 第四、表达正能量，让对方变得更好 忙就对了，不忙就失业啦！ 累，说明你正在走上坡路呢！ 你的工作就是来克服困难的！ 第五、表达幽默，赢得双方换心 幽默是一种生活态度，发现趣味，表达出来。 你喜欢什么样的男孩？ 我喜欢投缘的男孩。 一定要头圆吗？稍微有点方不行吗？ 这里采用谐音联想。 我们明天一起去钓鱼好吗？ 好啊，最好钓到一条美人鱼带回家。 让明天的约会带有童话色彩。 房东对租客说：对不起，我不租给带小孩的家庭。 小孩立刻站出来，说：“你租给我吧，我不带小孩，我带两个家长。” 说话幽默的方法多种多样，生活中善于观察、联想、积累，让幽默成为一种潜意识的思考过程，时间长了，你的表达就会变得风趣幽默。 问答摘录和总结 我的性格，偏内向， 优点：言简意骇、不失分寸、善于聆听。 坚持做好自己，不断完善自己。 提升语言表达能力，并非一朝一夕之功，需要长期积累，坚持训练： 博览群书是一个方面。首先你感兴趣的书，以持续扩展知识面，增加词汇量； 积极和不同的人打交道，是另一个方面。因为实践也是学习，而且是更重要的学习和提升； 以学促用，以用促学：多阅读，促思考，多使用，促表达。 “说了就后悔”，很常见。不过，后悔之后，是成长！ 想轻松，需要增强自信。自信的人，自然放松～ 想自信，需要你提升实力。主动学习，勇敢练习很必要～ 你已经开始了主动学习！接下来勇敢去练习，学了这一讲，就练习这一讲：可以训练自己表达事实、表达感受、表达需求、表达正能量、表达幽默。 背后说人好，积累人品，受人喜爱！ 追求完美，很难快乐。 视角不同，看到的风景也不同。与其看到的是记处分，不如看到的是：有缺点的人比完美的人更受欢迎！ 知足常乐！快乐源于你珍惜拥有：家庭幸福，空时有友，忙时充实！多好的状态，笑着保持下去... ","link":"https://xinrong2019.github.io/post/hao-hao-shuo-hua-zi-ji-shun-xin-dui-fang-shu-fu/"},{"title":"大厂Java面试必问点","content":"2020年大厂Java面试必问点全套学习视频97集 JVM相关 1. jdk体系和jvm架构 2. 帧栈核心组成部分解析 3. 局部变量表、操作数栈详解 4. 方法区、本地方法栈详解 5. 堆内存详解 6. 垃圾收集机制 7. 线上系统JVM调优实战案例 8. jvm性能调优与底层原理综合分析 数据库相关 9. 索引的本质 10. 红黑树和b+树图解 11. 如何基于b+树索引建立高性能索引 12. MyISAM存储引擎索引实现解析 13. InnoDB存储引擎索引实现解析 14. 为什么dba总推荐使用自增主键做索引 15. MySQL索引性能优化最佳实践 Redis相关 16. Redis核心数据结构介绍 17. String应用场景 18. Hash应用场景 19. Hash结构的优缺点 20. List应用场景 21. Set应用场景 22. 微博与微信关注模型解析 23. Redis开发最佳实践 24. 分布式锁场景解析 25. 模拟高并发场景 26. 基于Redission框架实现分布式锁 27. Redis主从架构锁失效问题 28. Redission分布式锁实现原理 29. 双十一大促如何将分布式锁的性能提升100倍 Java并发相关 30. CPU多核硬件架构剖析 31. JMM内存模型规范-JSR133 32. 内存模型工作原理 33. JMM的8大数据原子操作解析 34. Volatile可见性底层实现原理 35. CPU缓存一致性协议 36. CPU缓存当中数据的4种状态 37. 多线程设计与JMM 38. 并发存在的问题 39. AQS同步器源码解析 40. 同步器加锁过程 41. 同步器核心原理 42. 手写高并发秒杀场景同步器锁防超卖和压测 43. 同步器锁反推AQS框架核心原理 44. HashMap核心原理 45. 红黑树的左旋右旋规则 46. 为什么初始容量是2的指数幂 47. Java7的HashMap扩容死锁演示与环链形成分析 48. 链表转红黑树 49. HashMap数据结构其他内容 50. Java线程 51. 线程生命周期 52. 线程池运行原理 53. 线程池的5种状态 54. 线程的执行原理 55. 手写线程池 56. 红包系统业务流程分析 57. 微信红包场景分析 58. 红包业务流程分析 59. 红包系统设计 60. 如何设计一个弹性伸缩的红包系统后端 61. 超高并发拆红包场景下如何突破性能瓶颈 Spring IOC相关 62. SpringIOC生命周期 63. Spring底层多级缓存设计思想 64. Spring bean实例化底层原理 65. Spring Bean生命周期 66. BeanPostProcessor 67.SpringIOC其他 Spring事务相关 68. 数据库事务特性 69. 四种隔离级别上 70. 四种隔离级别下 71. 事务传播机制 72. Spring对事务的支持与使用 73. AOP事务底层原理 SpringBoot相关 74. Servlet3.x新规范解读 75. JavaSPI服务动态扩展机制 76. 启动原理 77. 源码环境搭建 78. SpringBoot零配置实现原理 79. SpringBoot启动流程 80. SpringBoot自动装配原理 81. Bean自定义对象生命周期 82. Bean定义解析 83. @Import注解原理 84. SpringBoot自动装配源码解读 85. 手写SpringBoot自定义启动器 分布式相关 86. 什么是分布式事务问题 87. Seata核心概念 88. @GlobalTransaction原理 89. SpringCloud集成Seata 90. Seata的设计思想 91. Seata核心源码解析 92. 微服务分布式事务 93. XA、JTA规范能解决分布式事务吗上 94. XA、JTA规范能解决分布式事务吗下 95. 分布式事务解决方案TCC实现原理 96. CAP和BASE原则 ","link":"https://xinrong2019.github.io/post/da-han-java-mian-shi-bi-wen-dian/"},{"title":"Go语言从入门到出门","content":"学习动机 掌握另一种编程语言，提高对编程语言的认知 坚持学习，培养坚持做完一件事的能力，提高自信 学习资源 李文周的博客 2020年寒假高薪特训: 20天入门到精通Go语言 官网 B站老男孩第5期 B站老男孩第4期 B站老男孩周末班5期 学习方法 目的导向，结果导向 通过教程掌握基础 通过阅读和分析源码进阶 通过开源项目、开源中间件进阶 在公司里运用、布道 Go语言学习路线 零基础 学习计算机知识 基础知识 计算机体系结构 计算机硬件基础 计算机软件知识 入门好书 计算机是怎样跑起来的 程序是怎样跑起来的 动手制作一台计算机 备选进阶书 深入理解计算机操作系统 学习操作系统知识 基础知识 操作系统管理 操作系统基本原理 命令行的使用 入门好书 30天自制操作系统 Linux就该这么学 Linux命令行与Shell脚本编程 Linux Shell脚本攻略 备选进阶书 Linux内核设计的艺术：图解Linux操作系统架构设计与实现原理 学习网络知识 基础知识 网络链接 网络协议 入门好书 网络是怎样连接的 图解HTTP HTTP/2基础教程 图解TCP/IP 备选进阶书 HTTP权威指南 TCP/IP详解 无编程经验的同学 学习编程基础知识 基础知识 程序设计基础 高等数学 算法基础 程序员英语 入门好书 我的第一本编程书 程序员的数学 算法图解 啊哈算法 程序员的英语 备选进阶书 计算机程序设计艺术 Linux/Unix系统编程手册 Unix环境高级编程 有其他语言编程经验的同学 学习Go语言基础知识 基础知识 Go语言规范 Go语言命令 Go语言基础编程 Go语言并发编程 推荐资源 Go语言规范文档 Go语言命令文档 Go语言编辑器和IDE Go语言WIKI Go语言核心技术36讲 Go并发编程实战 Go命令教程 Go语言第一课 有Go语言编程经验的同学 学习Go语言进阶知识 进阶知识 Go语言数据类型使用进阶 Go语言标准库使用进阶 Go语言并发编程进阶 Go语言知识体系巩固 推荐资源 Effective Go Go语言内存模型 Go程序诊断 Go语言核心技术36讲 Go并发编程实战 Go语言实战 进阶方法 打好基础，不断补充知识缺漏 研读Go语言官方文档和源码 学习明星项目中的代码和文档 多读书，读好书（所有相关技术书，不只Go语言） 积极练习、积极讨论、积极加入技术组织和社区 积极发布和开源自己的程序，积极通过代码和软件项目交友 积极公开自己的想法，并拥抱和吸纳不同的想法 尽量多的在公开场合发声，包括公开讨论、演讲、培训和咨询 ","link":"https://xinrong2019.github.io/post/go-yu-yan-cong-ru-men-dao-chu-men/"},{"title":"服务器性能剖析","content":"3.1 性能优化简介 性能 性能的定义：为完成某件任务所需要的时间度量。即响应时间。 优化 测量和优化 无法测量就无法有效地优化。第一步应该测量时间花费在什么地方。 花费大量的时间测量是应该做的事，而不是一上来就做修改。 确定测量范围 确定合适的测量范围，只测量需要优化的活动。 例如，如果确认有慢查询，就应该侧慢查询，而不是测量整个服务器。测量应该是从慢查询的开始到结束的时间，而不是查询之前或查询之后的时间。 测量任务的执行时间和等待时间 完成一项任务所需要的时间可以分成两部分：执行时间和等待时间。 优化任务的执行时间，最好的办法是通过测量定位不同的子任务花费的时间，然后优化去掉一些子任务、降低子任务的执行频率或者提升子任务的效率。 定位和优化子任务时，需要注意，一些运行不频繁或者很短的子任务对整体响应时间的影响很小。如何确认哪些子任务是优化的目标呢？答案就是性能剖析，接下来将介绍通过性能剖析进行优化。 优化任务的等待时间相对复杂，因为等待时间可能是由其他系统间接影响导致，任务之间也可能由于争用磁盘或者CPU资源而相互影响。 如何判断测量是正确的？ 实际上，这个问题的准确提法是：测量到底有多么不准确？要意识到使用的是测量数据，而不是其代表的实际数据。 3.1.1 通过性能剖析进行优化 一旦掌握并实践面向响应时间的优化方法，就会发现需要不断地对系统进行性能剖析（profiling）。 性能剖析一般有两个步骤：测量任务花费的时间；然后对结果进行统计和排序，将重要的任务排到前面。 我们将实际地讨论两种类型的性能剖析：基于执行时间的分析和基于等待的分析。 基于执行时间的分析研究的是什么任务的执行时间最长，而基于等待的分析则是判断任务在什么地方被阻塞的时间最长。 3.1.2 理解性能剖析 3.2 对应用程序进行性能剖析 3.3 剖析MySQL查询 3.3.1 剖析服务器负载 3.3.2 剖析单条查询 3.3.3 使用性能剖析 3.4 诊断间歇性问题 3.4.1 单条查询问题还是服务器问题 3.4.2 捕获诊断数据 3.4.3 一个诊断案例 3.5 其他剖析工具 3.5.1 使用user_statistics表 3.5.2 使用strace 3.6 总结 定义性能最有效的方法是响应时间 如果无法测量就无法优化，所以性能优化工作需要基于高质量、全方位及完整的响应时间测量。 测量的最佳开始点是应用程序，而不是数据库。即使问题出在底层的数据库，借助良好的测量也可以很容易地发现问题。 大多数系统无法完整地测量，测量有时候也会有错误的结果。但也可以想办法绕过一些限制，并得到好的结果。 完整的测量需要借助剖析器。 剖析报告是一种汇总信息，不要完全依赖。 有两种消耗时间的操作：工作或者等待。大多数剖析器只能测量因为工作而消耗的时间，所以等待分析有时候是很有用的补充，尤其是当CPU利用率很低但工作却一直无法完成的时候。 优化和提升是两回事。当继续提升的成本超过收益的时候，应当停止优化。 注意你的直觉，但应该只根据直觉来指导解决问题的思路，而不是用于确定系统的问题。决策应当尽量基于数据而不是感觉。 总体来说，我们认为解决性能问题的方法，首先是要澄清问题，然后选择合适的技术来解答这些问题。 如果想尝试提升服务器的总体性能，那么一个比较好的起点是将所有的查询记录到日志中，然后利用pt-query-digest工具生成系统级别的剖析报告。 可以把精力放在寻找那些消耗时间最多的、导致了糟糕的用户体验的，或者那些高度变化的，抑或有奇怪的响应时间直方图的查询。 如果找不到这些查询性能低下的原因，那么也可能遇到了服务器级别的性能问题。换句话说，我们需要重新站在更高的角度看待整个系统，从头重新思考，看看遗漏了什么。 我们无法完整地测量系统，但说到底它们都是某种状态机，所以只要足够细心，逻辑清晰并坚持下去，通常来说都能得到想要的结果。 要注意的是不要把原因和结果搞混了，而且在确认问题之前也不要随便针对系统做变动。工具虽然不完美，但是真多掌握了以后，已经足以完成大部分的优化诊断工作了。 ","link":"https://xinrong2019.github.io/post/fu-wu-qi-xing-neng-pou-xi/"},{"title":"MySQL基准测试","content":"关键词： 压力测试 可靠性测试 sysbench 学习目的： 通过了解基准测试的策略、方法、工具、案例，结合实践，掌握系统的行为。 2.1 为什么需要基准测试 基准测试是唯一方便有效的、可以学习系统在给定工作负载下会发生什么的方法。 基准测试可以观察系统在不同压力下的行为，评估系统的容量，掌握哪些是重要的变化，或者观察系统如何处理不同的数据。 基准测试可以完成以下工作，或者更多： 验证基于系统的一些假设，确认这些假设是否符合实际情况 重现系统中的某些异常行为，以解决这些异常 测试系统当前的运行情况。如果不清楚系统当前的性能，就无法确认某些优化的效果如何。也可以利用历史的基准测试结果来分析诊断一些无法预测的问题。 模拟比当前系统更高的负载，以找出系统随着压力增加而可能遇到的扩展性瓶颈。 规划未来的业务增长。基准测试可以评估在项目未来的负载下，需要什么样的硬件，需要多大容量的网络，以及其他相关资源。这有助于降低系统升级和重大变更的风险。 测试应用适应可变环境的能力。 测试不同的硬件、软件和操作系统配置。 证明新采购的设备是否配置正确。 我们只能进行大概的测试，来确定系统大致的余量有多少。尽管不能完全模拟真实环境，但是基准测试还是非常有用的（只要搞清楚测试的原理，并且了解如何分析结果所代表的意义）。 2.2 基准测试的策略 集成式 针对整个系统做集成测试，而不是单独测试MySQL的原因主要有以下几点： 测试整个系统，包括Web服务器、应用代码、网络和数据库是非常有用的，因为用户关注的并不仅仅是MySQL本书的性能，而是应用整体的性能。 MySQL并非总是应用的瓶颈，通过整体的测试可以揭示这一点。 只有对应用做整体测试，才能发现各部分之间的缓存带来的影响。 更能揭示应用的真实表现，而单独组件的测试很难做到这一点。 单组件式 在项目初期，可以只测试MySQL 需要比较不同的schema或查询的性能 针对应用中某个具体问题的测试 为了避免漫长的基准测试，可以通过一个短期的基准测试，做快速的“周期循环”，来检测出某些调整后的效果。 如果可能，采用生产环境的数据快照做测试。 2.2.1 测试何种指标 在开始执行甚至是在设计基准测试之前，需要先明确测试的目标。 测试目标决定了选择什么样的测试工具和技术，以获得精确而有意义的测试结果。 可以将测试目标细化为一系列的问题，比如，“这种CPU是否比另一种快？”，“新索引是否比当前索引性能更好？” 有时候需要用不同的方法测试不同的指标。比如，针对延迟和吞吐量就需要采用不同的测试方法。 请考虑以下指标，看看如何满足测试的需求。 吞吐量 吞吐量指的是单位时间内的事务处理数。 主要针对在线事务处理（OLTP）的吞吐量，非常适用于多用户的交互式应用。常用的测试单位是每秒事务数（TPS），有些采用每分钟事务数（TPM）。 响应时间或者延迟 这个指标用于测试任务所需的整体时间。 通常可以使用百分比响应时间来替代最大响应时间。 例如，如果95%的响应时间都是5毫秒，则表示任务在95%的时间段内都可以在5毫秒之内完成。 并发性 Web服务器的并发性，是指在任意时间有多少同时发生的并发请求。 并发性基准测试需要关注的是正在工作中的并发操作，或者是同时工作中的线程数或连接数， 一个Web站点“同时有50000个用户”访问，却可能只有10～15个并发请求到MySQL数据库。 当并发性增加时，需要测量吞吐量是否下降，响应时间是否变长，如果是这样，应用可能就无法处理峰值压力。 并发性测试不是为了测试应用能达到的并发度，而是为了测试应用在不同并发下的性能。 可扩展性 系统的业务压力可能发生变化时，测试可扩展性非常必要。 可扩展性指的是，给系统增加一倍的工作，在理想情况下就能获得两倍的结果（即吞吐量增加一倍）。 可扩展性指标对于容量规范非常有用，基于不断增加用户连接的情况下的响应时间测试可以发现应用的瓶颈。 小结 应该测试那些对用户来说最重要的指标。因此应该尽可能地去收集一些需求，比如，什么样的响应时间是可以接受的，期待多少的并发性，等等。然后基于这些需求来设计基准测试，避免目光短浅地只关注部分指标，而忽略其他指标。 2.3 基准测试方法 在了解基本概念后，现在可以具体讨论一下如何设计和执行基准测试。 先来看一下如何避免一些常见的错误，这些错误可能导致测试结果无用或者不精确： 使用真实数据的子集而不是全集。例如，应用需要处理几百GB的数据，但测试只有1GB数据；或者只使用当前数据进行测试，却希望模拟未来业务大幅度增长后的情况。 使用错误的数据分布。例如使用均匀分布的数据测试，而系统的真实数据有很多热点区域（随机生成的测试数据通常无法模拟真实的数据分布）。 使用不真实的分布参数，例如假定所有用户的个人信息都会被平均地读取。 在多用户场景中，只做单用户的测试。 在单服务器上测试分布式应用。 与真实用户行为不匹配。 反复执行同一个查询。 没有检查错误（日志）。 忽略了系统预热的过程。 使用默认的服务器配置。 测试时间太短。 2.3.1 设计和规划基准测试 标准的基准测试 专用的基准测试 针对查询的测试，可以建立一个单元测试集作为初步的测试，并运行多遍。 更好的办法是选择一个有代表性的时间段，比如高峰期的一个小时，或者一整天，记录生产系统上的所有查询。 如果时间段选得比较小，则可以选择多个时间段。 可以在不同级别记录查询。例如，如果是集成测试，可以记录Web服务器上HTTP请求，也可以打开MySQL的查询日期。倘若要重演这些查询，就要确保创建多线程来并行执行，而不是单线程线性地执行。 详细地写下测试规划。测试规划应该记录测试数据、系统配置的步骤、如何测量和分析结果，以及预热的方案等。 应该建立将参数和结果文档化的规范，每一轮测试都必须进行详细记录。 2.3.2 基准测试应该运行多长时间 直到系统稳定为止，读IO和写IO稳定。 如果没有时间去完成准确完整的基准测试，那么已经花费的所有时间都是一种浪费。 2.3.3 获取系统性能和状态 2.3.4 获得准确的测试结果 2.3.5 运行基准测试并分析结果 2.3.6 绘图的重要性 2.4 基准测试工具 2.4.1 集成测试工具 2.4.2 单组件式测试工具 2.5 基准测试案例 2.6 总结 ","link":"https://xinrong2019.github.io/post/mysql-ji-zhun-ce-shi/"},{"title":"MySQL架构","content":"MySQL为什么灵活？灵活性体现在哪？ 可以通过配置使它在不同的硬件上都运行得很好，也可以支持多种不同的数据类型。但是最重要、最与众不同的特性是它的存储引擎架构，这种架构的设计将查询处理及其他系统任务和数据的存储/提取相分离。 这种处理和存储分离的设计可以在使用时根据性能、特性，以及其他需求来选择数据存储的方式。 学习目标： 掌握MySQL服务器架构 掌握各种存储引擎之间的主要区别，以及这些区别的重要性 了解MySQL的历史背景和基准测试 初步掌握MySQL的原理 1.1 MySQL逻辑架构 头脑中构建出一幅MySQL各组件之间如何协同工作的架构图，有助于深入理解MySQL服务器。 第一层：连接处理、授权认证、安全 第二层：大多数MySQL的核心服务，包括查询解析、分析、优化、缓存以及所有的内置函数（例如，日期、时间、数学和加密函数），所有跨存储引擎的功能都在这一层实现：存储过程、触发器、视图等。 第三层：存储引擎。存储引擎负责MySQL中数据的存取和提取。服务器通过API与存储引擎进行通信。存储引擎API包含几十个底层函数，用于执行诸如“开始一个事务”或者“根据主键提取一行记录”等操作。但存储引擎不回去解析SQL(InnoDB例外，会解析外健定义，因为MySQL服务器本身没有实现该功能)，不同存储引擎之间也不会相互通信，而只是简单地响应上层服务器等请求。 1.1.1 连接管理与安全性 每个客户端连接都会在服务器进程中拥有一个线程，这个连接的查询只会在这个单独的线程中执行，该线程只能轮流在某个CPU核心或者CPU中运行。服务器会负责缓存线程，因此不需要为每一个新建的连接创建或者销毁线程。 线程池是一个更优秀的资源管理策略 当客户端(应用)连接到MySQL服务器时，服务器需要对其进行认证。认证基于用户名、原始主机信息和密码。如果使用了安全套接字(SSL)的方式连接，还可以使用X.509证书认证。一旦客户端连接成功，服务器会继续验证该客户端是否具有执行某个特定查询的权限(例如，是否允许客户端对world数据库的Country表执行Select语句)。 1.1.2 优化与执行 MySQL会解析查询，并创建内部数据结构(解析树)，然后对其进行各种优化，包括重写查询、决定表的读取顺序，以及选择合适的索引等。 用户可以通过特殊的关键字提示(hint)优化器，影响它的决策过程。 也可以请求优化器解释(explain)优化过程的各个因素，使用户可以知道服务器是如何进行优化决策的，并提供一个参考基准，便于用户重构查询和schema、修改相关配置，使应用尽可能高效运行。 第6章将讨论更多优化器细节。 优化器会请求存储引擎提供容量或某个具体操作的开销信息，以及表数据的统计信息等。例如，某些存储引擎的某种索引，可能对一些特定的查询有优化。 关于索引与schema的优化，参见第4章和第5章。 对于SELECT语句，在解析查询之前，服务器会先检查查询缓存，如果能够在其中找到对应的查询，服务器就不必再执行查询解析、优化和执行的整个过程，而是直接返回查询缓存中的结果集。 第7章详细讨论了相关内容。 1.2 并发控制 无论何时，只要有多个查询需要在同一时刻修改数据，都会产生并发控制的问题。 本章的目的是讨论MySQL在两个层面的并发控制：服务器层与存储引擎层。 本章只简要地讨论MySQL如何控制并发读写。 以Unix系统的email box为例，典型的mbox文件格式是非常简单的。一个mbox邮箱中的所有邮件都串行在一起，彼此首尾相连。 这种格式对于读取和分析邮件信息非常友好，同时投递邮件也很容易，只要在文件末尾附加新的邮件内容即可。 但如果两个进程在同一时刻对同一个邮箱投递邮件，邮箱的数据会被破坏，两封邮件的内容会交叉地附加在邮箱文件的末尾。 设计良好的邮箱投递系统会通过锁(lock)来防止数据损坏。如果客户试图投递邮件，而邮箱已经被其他客户锁住，那就必须等待，直到锁释放才能进行投递。 这种锁的方案在实际应用环境中虽然工作良好，但并不支持并发处理。因为任意一个时刻，只有一个进程可以修改邮箱的数据，这在大容量的邮箱系统中是个问题。 1.2.1 读写锁 读读不会出现问题，读写、写读、写写都会有问题。需要做同步处理。 一个经典的方法是，通过实现一个由两种类型的锁组成的锁系统来解决问题。 这两种类型的锁通常被称为共享锁和排他锁，也叫读锁和写锁。 读锁是共享的，或者说是相互不阻塞的。多个客户在同一时刻可以同时读取同一个资源，而互不干扰。 写锁则是排他的，也就是说一个写锁会阻塞其他的写锁和读锁。 在实际的数据库系统中，每时每刻都在发生锁定，当某个用户修改某一部分数据时，MySQL会通过锁定防止其他用户读取同一数据。大多数时候，MySQL锁的内部管理都是透明的。 1.2.2 锁粒度 一种提高共享资源并发性的方式就是让锁定对象更有选择性。尽量只锁定需要修改的部分数据，而不是所有的资源。 更理想的方式是，只对会修改的数据片进行精确的锁定。任何时候，在给定的资源上，锁定的数据量越少，则系统的并发程度越高，只要相互之间不发生冲突即可。 问题是加锁也需要消耗资源。锁的各种操作，包括获得锁、检查锁是否已经解除、释放锁等，都会增加系统等开销。如果系统花费大量的时间来管理锁，而不是存取数据，那么系统的性能可能会因此受到影响。 所谓的锁策略，是在锁的开销和数据的安全性之间寻求平衡，这种平衡当然也会影响到性能。 大多数商业数据库系统没有提供更多的选择，一般都是在表上施加行级锁，并以各种复杂的方式来实现，以便在锁比较多的情况下尽可能地提供更好的性能。 而MySQL则提供了多种选择。每种MySQL存储引擎都可以实现自己的锁策略和锁粒度。 MySQL中，对锁的管理灵活，锁粒度可以修改，多存储引擎架构提供对多场景支持。 两种重要的锁策略 表锁 开销最小 在特定的场景中，表锁也可能有良好的性能。例如，READ_LOCAL表锁支持某些类型的并发写操作。 另外，写锁也比读锁有更高的优先级，因此一个写锁请求可能会被插入到读锁队列的前面。 尽管存储引擎可以管理自己的锁，MySQL本身还是会使用各种有效的表锁来实现不同的目的。例如，服务器会为诸如ALTER TABLE之类的语句使用表锁，而忽略存储引擎的锁机制。 行级锁 行级锁可以最大程度地支持并发处理（同时也带来了最大的锁开销）。在InnoDB和XtraDB，以及一些存储引擎中实现了行级锁。 行级锁只在存储引擎层实现，而MySQL服务器层（如有必要，请回顾前问的逻辑架构图）没有实现。服务器层完全不了解存储引擎中的锁实现。在本章的后续内容以及全书中，所有的存储引擎都以自己的方式显现了锁机制。 1.3 事务 事务就是一组原子性的SQL查询，或者说一个独立的工作单元。 事务内的语句，要么全部执行成功，要么全部执行失败。 事务的ACID 一个运行良好的事务处理系统，必须具备这些标准特征： 原子性（atomicity） 一致性（consistency） 隔离性（isolation） 持久性（durability） 实现ACID需要考虑性能、安全等很多复杂问题。 隔离级别 在SQL标准中定义了四种隔离级别，每一种级别都规定了一个事务中所做的修改，哪些在事务内和事务间是可见的，哪些是不可见的。较低级别的隔离通常可以执行更高的并发，系统的开销也更低。 READ UNCOMMITTED(读未提交) READ COMMITTED(读已提交) REPEATABLE READ(可重复度) SERIALIZABLE(可串行化) ANSI SQL隔离级别 隔离级别 脏读可能性 不可重复读可能性 幻读可能性 加锁读 READ UNCOMMITTED Yes Yes Yes No READ COMMITTED No Yes Yes No REPEATABLE READ No No Yes No SERIALIZABLE No No No Yes 1.3.2 死锁 什么是死锁？ 怎么产生死锁？ 死锁检测和超时机制 1.3.3 事务日志 采用追加的方式，速度快，顺序IO，不用移动磁头。 预写式日志（Write-Ahead Logging），修改数据需要写两次磁盘，实时修改内存拷贝，持久化事务日志，事务日志持久化后，内存中被修改的数据在后台可以慢慢地刷回到磁盘。 1.3.4 MySQL中的事务 事务支持：InnoDB 自动提交 默认自动提交 在事务中混合使用存储引擎 隐式和显式锁定 1.4 多版本并发控制 可以认为MVCC是行级锁的一个变种，但是它在很多情况下避免了加锁操作，因此开销更低。虽然实现机制有所不同，但都实现了非阻塞的读操作，写操作也只锁定必要的行。 MVCC的实现，是通过保存数据在某个时间点的快照来实现的。 MVCC的实现，典型的有乐观并发控制和悲观并发控制。下面我们通过InnoDB的简化版行为来说明MVCC是如何工作的。 InnoDB的MVCC，是通过在每行记录后保存两个隐藏的列来实现的。这两个列，一个保存了行的创建时间，一个保存了行的过期时间（或删除时间）。当然存储的并不是实际的时间值，而是系统版本号（system version number）。没开始一个新的事务，系统版本号都会自动递增。事务开始时刻的系统版本号会作为事务的版本号，用来和查询到的每行记录的版本号进行比较。 下面看一下在REPEATABLE READ隔离级别下，MVCC具体是如何操作的。 SELECT InnoDB会根据以下两个条件检查每行记录： a. InnoDB只查找版本早于当前事务版本的数据行（也就是，行的系统版本号小于或等于事务的系统版本号），这样可以确保事务读取的行，要么是在事务开始前已经存在的，要么是事务自身插入或者修改过的。 b. 行的删除版本要么未定义，要么大于当前事务版本号。这可以确保事务读取到的行，在事务开始之前未被删除。 只有符合上述两个条件的记录，才能返回作为查询结果。 Insert InnoDB为新插入的每一行保存当前系统版本号作为行版本号。 DELETE InnoDB为删除的每一行保存当前系统版本号作为行删除标识。 UPDATE InnoDB为插入一行新纪录，保存当前系统版本号作为行版本号，同时保存当前系统版本号到原来的行作为行删除标识。 保存这两个额外系统版本号，使大多数读操作都可以不用加锁。这样设计使得读数据操作很简单，性能很好，并且也能保证只会读取到符合标准的行。 不足之处是每行记录都需要额外的存储空间，需要做更多的行检查工作，以及一些额外的维护工作。 MVCC只在REPEATABLE READ和READ COMMITTED两个隔离级别下工作。其他两个隔离级别都和MVCC不兼容，因为READ UNCOMMITTED总是读取最新的数据行，而不是符合当前事务版本的数据行。而SERIALIZABLE则会对所有读取的行都加锁。 1.5 MySQL的存储引擎 数据库，或称schema，对应文件系统中数据目录下的一个子目录。 创建表时，MySQL会在数据库子目录下创建一个和表同名的.frm文件保存表的定义。 大小写敏感和平台相关。 可以使用show table status命令（在5.0以后的版本中，也可以查询information_schema中对应的表）显示表的相关信息。 1.5.1 InnoDB存储引擎 MySQL默认的事务引擎。被设计用来处理大量的短期事务，短期事务大部分情况时正常提交的，很少会被回滚。 InnoDB的性能和自动崩溃恢复特性，使得它在非事务型存储的需求中也很流行。 InnoDB的历史 InnoDB概览 InnoDB的数据存储在表空间中。 InnoDB采用MVCC来支持高并发，并且实现了四个标准的隔离级别。 默认级别是REPEATABLE READ（可重复读），并且通过间隙锁（next-key locking）策略防止幻读的出现。间隙锁使得InnoDB不仅仅锁定查询涉及的行，还会对索引中的间隙进行锁定，以防止幻影行的插入。 InnoDB表是基于聚簇索引建立的。 聚簇索引对主键查询有很高的性能。不过它的二级索引（secondary index，非主键索引）中必须包含主键列，所以如果主键列很大的话，其他的索引都会很大。 因此，若表上的索引较多的话，主键应当尽可能的小。 InnoDB的存储格式是平台独立的。数据和索引文件可以在各个平台间复制。 InnoDB内部做了很多优化，包括从磁盘读取数据时采用的可预测性预读，能够自动在内存中创建hash索引以加速读操作的自适应哈希索引（adaptive hash index），以及能够加速插入操作的插入缓冲区（insert buffer）等。后面将详细地讨论这些内容。 如果应用程序基于InnoDB引起，则应该了解一下InnoDB的MVCC架构带来的一些微妙和细节之处时非常有必要的。 存储引擎要为所有用户甚至包括修改数据的用户维持一致性的视图，是非常复杂的工作。要获取一致性视图需要停止对所有表的写入，而在读写混合场景中，停止写入也意味着停止读取。 InnoDB支持热备份。 1.5.2 MyISAM存储引擎 特性： 支持全文索引、压缩、空间函数（GIS）等 缺点： 不支持事务和行级锁 崩溃后无法完全恢复 存储 特性 压缩表 性能 1.5.3 MySQL内建等其他存储引擎 Memory引擎 Merge引擎 1.5.4 第三方存储引擎 OLTP类引擎 TokuDB引擎，分形树（Fractal Trees）索引数据结构。缓存无关，是一种大数据存储引擎，因为其拥有很高的压缩比，可以在大的数据量上创建大量索引。 面向列的存储引擎 社区存储引擎 1.5.5 选择合适的引擎 如果应用需要不同的存储引擎，请先考虑以下几个因素。 事务 备份 崩溃恢复 特有的特性 常见的应用场景。 日志型应用 只读或者大部分情况下只读的表 订单处理 电子公告牌和主题讨论论坛 CD-ROM应用 大数据量 1.5.6 转换表的引擎 ALTER TABLE 导出与导入 创建于查询 先创建一个新的存储引擎的表，然后利用insert... select语法来导数据。 create table innodb_table like muisam_table; alter table innodb_table engine=Innodb; insert into innodb_table select * from myisam_table; 数据量大的情况，可以考虑做分批处理，针对每一段数据执行事务提交操作，避免大事务产生过多的undo。 start transaction; insert into innodb_table select * from myisam_table where id between x and y; commit; 1.6 MySQL时间线（Timeline） 1.7 MySQL的开发模式 新里程碑开发版 GA（Generally Available）版，通常可用版 实验室预览版，发布一些需要评估的特性 插件付费，插件开发模式 1.8 总结 MySQL拥有分层的架构。 上层是服务器层的服务和查询执行引擎，下层则是存储引擎。 如果能理解MySQL在存储引擎和服务层之间处理查询时如何通过API来回交互，就能抓住MySQL的核心基础架构的精髓。 数据字典保存在.frm文件中，对于InnoDB来说，所有的操作都是事务。 选择多并非好事。InnoDB对于95%以上的用户来说都是最佳选择。 ","link":"https://xinrong2019.github.io/post/mysql-jia-gou/"},{"title":"[死磕Spring]--IOC之注册 BeanDefinitions","content":"本文主要基于 Spring 5.0.6.RELEASE 摘要: 原创出处 http://cmsblogs.com/?p=2697 「小明哥」，谢谢！ 获取 XML Document 对象后，会根据该对象和 Resource 资源对象调用 XmlBeanDefinitionReader#registerBeanDefinitions(Document doc, Resource resource) 方法，开始注册 BeanDefinitions 之旅。代码如下： // AbstractBeanDefinitionReader.java private final BeanDefinitionRegistry registry; // XmlBeanDefinitionReader.java public int registerBeanDefinitions(Document doc, Resource resource) throws BeanDefinitionStoreException { // &lt;1&gt; 创建 BeanDefinitionDocumentReader 对象 BeanDefinitionDocumentReader documentReader = createBeanDefinitionDocumentReader(); // &lt;2&gt; 获取已注册的 BeanDefinition 数量 int countBefore = getRegistry().getBeanDefinitionCount(); // &lt;3&gt; 创建 XmlReaderContext 对象 // &lt;4&gt; 注册 BeanDefinition documentReader.registerBeanDefinitions(doc, createReaderContext(resource)); // 计算新注册的 BeanDefinition 数量 return getRegistry().getBeanDefinitionCount() - countBefore; } &lt;1&gt; 处，调用 #createBeanDefinitionDocumentReader() 方法，实例化 BeanDefinitionDocumentReader 对象。 FROM 《Spring 源码深度解析》P16 页 定义读取 Document 并注册 BeanDefinition 功能 &lt;2&gt; 处，调用 BeanDefinitionRegistry#getBeanDefinitionCount() 方法，获取已注册的 BeanDefinition 数量。 &lt;3&gt; 处，调用 #createReaderContext(Resource resource) 方法，创建 XmlReaderContext 对象。 &lt;4&gt; 处，调用 BeanDefinitionDocumentReader#registerBeanDefinitions(Document doc, XmlReaderContext readerContext) 方法，读取 XML 元素，注册 BeanDefinition 们。 &lt;5&gt; 处，计算新注册的 BeanDefinition 数量。 1. createBeanDefinitionDocumentReader #createBeanDefinitionDocumentReader()，实例化 BeanDefinitionDocumentReader 对象。代码如下： /** * documentReader 的类 * * @see #createBeanDefinitionDocumentReader() */ private Class&lt;? extends BeanDefinitionDocumentReader&gt; documentReaderClass = DefaultBeanDefinitionDocumentReader.class; protected BeanDefinitionDocumentReader createBeanDefinitionDocumentReader() { return BeanUtils.instantiateClass(this.documentReaderClass); } documentReaderClass 的默认值为 DefaultBeanDefinitionDocumentReader.class 。关于它，我们在后续的文章，详细解析。 2. registerBeanDefinitions BeanDefinitionDocumentReader#registerBeanDefinitions(Document doc, XmlReaderContext readerContext) 方法，注册 BeanDefinition ，在接口 BeanDefinitionDocumentReader 中定义。代码如下： public interface BeanDefinitionDocumentReader { /** * Read bean definitions from the given DOM document and * register them with the registry in the given reader context. * @param doc the DOM document * @param readerContext the current context of the reader * (includes the target registry and the resource being parsed) * @throws BeanDefinitionStoreException in case of parsing errors */ void registerBeanDefinitions(Document doc, XmlReaderContext readerContext) throws BeanDefinitionStoreException; } 从给定的 Document 对象中解析定义的 BeanDefinition 并将他们注册到注册表中。方法接收两个参数： doc 方法参数：待解析的 Document 对象。 readerContext 方法，解析器的当前上下文，包括目标注册表和被解析的资源。它是根据 Resource 来创建的，见 「3. createReaderContext」 。 2.1 DefaultBeanDefinitionDocumentReader BeanDefinitionDocumentReader 有且只有一个默认实现类 DefaultBeanDefinitionDocumentReader 。它对 #registerBeanDefinitions(...) 方法的实现代码如下： DefaultBeanDefinitionDocumentReader 对该方法提供了实现： @Nullable private XmlReaderContext readerContext; @Nullable private BeanDefinitionParserDelegate delegate; /** * This implementation parses bean definitions according to the &quot;spring-beans&quot; XSD * (or DTD, historically). * &lt;p&gt;Opens a DOM Document; then initializes the default settings * specified at the {@code &lt;beans/&gt;} level; then parses the contained bean definitions. */ @Override public void registerBeanDefinitions(Document doc, XmlReaderContext readerContext) { this.readerContext = readerContext; // 获得 XML Document Root Element // 执行注册 BeanDefinition doRegisterBeanDefinitions(doc.getDocumentElement()); } /** * Register each bean definition within the given root {@code &lt;beans/&gt;} element. */ @SuppressWarnings(&quot;deprecation&quot;) // for Environment.acceptsProfiles(String...) protected void doRegisterBeanDefinitions(Element root) { // Any nested &lt;beans&gt; elements will cause recursion in this method. In // order to propagate and preserve &lt;beans&gt; default-* attributes correctly, // keep track of the current (parent) delegate, which may be null. Create // the new (child) delegate with a reference to the parent for fallback purposes, // then ultimately reset this.delegate back to its original (parent) reference. // this behavior emulates a stack of delegates without actually necessitating one. // 记录老的 BeanDefinitionParserDelegate 对象 BeanDefinitionParserDelegate parent = this.delegate; // &lt;1&gt; 创建 BeanDefinitionParserDelegate 对象，并进行设置到 delegate this.delegate = createDelegate(getReaderContext(), root, parent); // &lt;2&gt; 检查 &lt;beans /&gt; 根标签的命名空间是否为空，或者是 http://www.springframework.org/schema/beans if (this.delegate.isDefaultNamespace(root)) { // &lt;2.1&gt; 处理 profile 属性。可参见《Spring3自定义环境配置 &lt;beans profile=&quot;&quot;&gt;》http://nassir.iteye.com/blog/1535799 String profileSpec = root.getAttribute(PROFILE_ATTRIBUTE); if (StringUtils.hasText(profileSpec)) { // &lt;2.2&gt; 使用分隔符切分，可能有多个 profile 。 String[] specifiedProfiles = StringUtils.tokenizeToStringArray( profileSpec, BeanDefinitionParserDelegate.MULTI_VALUE_ATTRIBUTE_DELIMITERS); // &lt;2.3&gt; 如果所有 profile 都无效，则不进行注册 // We cannot use Profiles.of(...) since profile expressions are not supported // in XML config. See SPR-12458 for details. if (!getReaderContext().getEnvironment().acceptsProfiles(specifiedProfiles)) { if (logger.isDebugEnabled()) { logger.debug(&quot;Skipped XML bean definition file due to specified profiles [&quot; + profileSpec + &quot;] not matching: &quot; + getReaderContext().getResource()); } return; } } } // &lt;3&gt; 解析前处理 preProcessXml(root); // &lt;4&gt; 解析 parseBeanDefinitions(root, this.delegate); // &lt;5&gt; 解析后处理 postProcessXml(root); // 设置 delegate 回老的 BeanDefinitionParserDelegate 对象 this.delegate = parent; } &lt;1&gt; 处，创建 BeanDefinitionParserDelegate 对象，并进行设置到 delegate 。BeanDefinitionParserDelegate 是一个重要的类，它负责解析 BeanDefinition。代码如下： FROM 《Spring 源码深度解析》P16 定义解析 XML Element 的各种方法 protected BeanDefinitionParserDelegate createDelegate( XmlReaderContext readerContext, Element root, @Nullable BeanDefinitionParserDelegate parentDelegate) { // 创建 BeanDefinitionParserDelegate 对象 BeanDefinitionParserDelegate delegate = new BeanDefinitionParserDelegate(readerContext); // 初始化默认 delegate.initDefaults(root, parentDelegate); return delegate; } &lt;2&gt; 处，检查 &lt;beans/&gt; 根标签的命名空间是否为空，或者是 http://www.springframework.org/schema/beans 。 &lt;2.1&gt; 处，判断是否 &lt;beans/&gt; 上配置了 profile 属性。不了解这块的胖友，可以看下 《《Spring3自定义环境配置 》》 。 &lt;2.2&gt; 处，使用分隔符切分，可能有多个 profile 。 &lt;2.3&gt; 处，判断，如果所有 profile 都无效，则 return 不进行注册。 &lt;4&gt; 处，调用 #parseBeanDefinitions(Element root, BeanDefinitionParserDelegate delegate) 方法，进行解析逻辑。详细解析，见 「3.1 parseBeanDefinitions」 。 &lt;3&gt; / &lt;5&gt; 处，解析前后的处理，目前这两个方法都是空实现，交由子类来实现。代码如下： protected void preProcessXml(Element root) {} protected void postProcessXml(Element root) {} 2.1.1 parseBeanDefinitions #parseBeanDefinitions(Element root, BeanDefinitionParserDelegate delegate) 方法，进行解析逻辑。代码如下： /** * Parse the elements at the root level in the document: * &quot;import&quot;, &quot;alias&quot;, &quot;bean&quot;. * @param root the DOM root element of the document */ protected void parseBeanDefinitions(Element root, BeanDefinitionParserDelegate delegate) { // &lt;1&gt; 如果根节点使用默认命名空间，执行默认解析 if (delegate.isDefaultNamespace(root)) { // 遍历子节点 NodeList nl = root.getChildNodes(); for (int i = 0; i &lt; nl.getLength(); i++) { Node node = nl.item(i); if (node instanceof Element) { Element ele = (Element) node; // &lt;1&gt; 如果该节点使用默认命名空间，执行默认解析 if (delegate.isDefaultNamespace(ele)) { parseDefaultElement(ele, delegate); // 如果该节点非默认命名空间，执行自定义解析 } else { delegate.parseCustomElement(ele); } } } // &lt;2&gt; 如果根节点非默认命名空间，执行自定义解析 } else { delegate.parseCustomElement(root); } } Spring 有两种 Bean 声明方式： 配置文件式声明：&lt;bean id=&quot;studentService&quot; class=&quot;org.springframework.core.StudentService&quot; /&gt; 。对应 &lt;1&gt; 处。 自定义注解方式：&lt;tx:annotation-driven&gt; 。对应 &lt;2&gt; 处。 &lt;1&gt; 处，如果根节点或子节点使用默认命名空间，调用 #parseDefaultElement(Element ele, BeanDefinitionParserDelegate delegate) 方法，执行默认解析。代码如下： private void parseDefaultElement(Element ele, BeanDefinitionParserDelegate delegate) { if (delegate.nodeNameEquals(ele, IMPORT_ELEMENT)) { // import importBeanDefinitionResource(ele); } else if (delegate.nodeNameEquals(ele, ALIAS_ELEMENT)) { // alias processAliasRegistration(ele); } else if (delegate.nodeNameEquals(ele, BEAN_ELEMENT)) { // bean processBeanDefinition(ele, delegate); } else if (delegate.nodeNameEquals(ele, NESTED_BEANS_ELEMENT)) { // beans // recurse doRegisterBeanDefinitions(ele); } } 详细的解析，见后续文章。 &lt;2&gt; 处，如果根节点或子节点不使用默认命名空间，调用 BeanDefinitionParserDelegate#parseCustomElement(Element ele) 方法，执行自定义解析。详细的解析，见后续文章。 3. createReaderContext #createReaderContext(Resource resource) 方法，创建 XmlReaderContext 对象。代码如下： private ProblemReporter problemReporter = new FailFastProblemReporter(); private ReaderEventListener eventListener = new EmptyReaderEventListener(); private SourceExtractor sourceExtractor = new NullSourceExtractor(); @Nullable private NamespaceHandlerResolver namespaceHandlerResolver; /** * Create the {@link XmlReaderContext} to pass over to the document reader. */ public XmlReaderContext createReaderContext(Resource resource) { return new XmlReaderContext(resource, this.problemReporter, this.eventListener, this.sourceExtractor, this, getNamespaceHandlerResolver()); } 关于 XmlReaderContext 的详细解析，见后续文章。 4. 小结 至此，XmlBeanDefinitionReader#doLoadBeanDefinitions(InputSource inputSource, Resource resource) 方法中，做的三件事情已经全部分析完毕，下面将对 BeanDefinition 的解析过程做详细分析说明。 另外，XmlBeanDefinitionReader#doLoadBeanDefinitions(InputSource inputSource, Resource resource) 方法，整体时序图如下： 红框部分，就是 BeanDefinition 的解析过程。 ","link":"https://xinrong2019.github.io/post/si-ke-spring-ioc-zhi-zhu-ce-beandefinitions/"},{"title":"面向简历编程","content":"目录 面向简历编程 JD 总结互联网企业的岗位要求 针对以上知识点系统学习计划 JD Zoom高级Java工程师 16-32k 工作内容： 负责Zoom产品线Web前后端平台架构设计和开发 负责第三方系统和Zoom平台的集成 解决开发过程中的技术问题，支持、协助处理其他相关的技术问题 进行程序性能的分析和优化工作 岗位要求： 对互联网的高并发、海量处理、负载均衡、容错处理等有深入的理解和丰富的经验优先 计算机相关专业本科及以上学历，3年以上Java开发经验 熟悉Java语言，基础扎实，包括JVM、类装载机制、多线程并发、IO、网络等技术体系 精通Java Web开发，熟悉HTTP协议和Servlet规范，掌握Spring、Spring MVC、Mybatis等Java开源框架 熟悉MySQL数据库设计，性能调优，以及数据库热备，快速切换等机制; 另外，熟悉Nosql如DynamoDB等优先 学习能力强，热衷技术，喜欢钻研和尝试新的技术 具备良好的编码规范，面向对象设计理解，熟悉面向对象设计原则，掌握设计模式及应用场景 具备良好的沟通和团队协作能力，工作积极主动，思路清晰，责任心强 有SSO相关开发经验（熟悉不同IDP的特性）优先 连连支付高级开发工程师 15-25k 职位诱惑： 年度旅游、氛围欢乐、年终丰厚、下午茶 职位描述： 岗位职责： 参与核心业务系统的设计和开发 负责系统的持续优化和改造，保证系统的稳定和性能 研究并尝试最新技术 任职要求： 本科及以上学历，计算机相关专业，3年以上Java开发经验 ，有支付、互金、风控相关开发经验者优先 熟悉JAVA开发，基础扎实，对JVM原理有一定的了解，对Spring, MyBatis等开源框架熟悉 熟悉分布式系统的设计和应用，熟悉分布式、缓存、消息等机制，能对分布式常用技术进行合理应用，解决问题 熟悉多线程及高性能的设计与编码及性能调优，有高并发应用开发经验 熟悉主流数据库的操作，对SQL优化有丰富的经验 思维敏捷，逻辑严密，学习能力强，适应能力好，有强烈的责任心，有优秀的团队合作能力 连连支付Java信贷 20k-40k 职位诱惑： 免费下午茶自助晚餐 职位描述： 负责跨境金融系统的设计和开发； 优化现有系统，对现有系统流程、系统响应速度、内存使用等方面做优化，提升系统的稳定性和用户体验。 任职要求： 熟练掌握流行的开源框架（Spring/Mybatis/SpringMVC），并且对其核心思想、实现原理有一定认知； JAVA基础扎实，理解并能熟练使用io、多线程，对JVM原理有一定的了解； 熟练使用Oracle、MySql数据库； 熟练掌握Linux操作系统及相关命令； 熟悉分布式系统的设计和应用，熟悉分布式、缓存、消息等机制；能对分布式常用技术进行合理应用者优先； 有互联网金融行业开发经验优先。 热爱技术、学习能力强、关注设计、重视质量、善于沟通与团队协作； 连连支付资深Java开发工程师 15-30k 职位诱惑: 年度旅游、氛围欢乐、年终丰厚、下午茶 职位描述： 岗位职责： 负责支付产品的总体设计、开发，保障开发质量，实现系统的高可用、高并发； 对现有系统优化迭代，提升系统的性能和稳定性，并给商户提供高效的接入方案及指南； 引入新技术、创新方案，提升团队的技术能力，解决问题的能力； 任职要求： 1、熟练掌握流行的开源框架（Spring/Mybatis/SpringMVC），并且对其核心思想、实现原理有一定认知； 2、理解微服务架构的原理，熟练使用某种开源框架，使用并研读过Dubbo核心代码最佳； 3、JAVA基础扎实，理解并能熟练使用IO、多线程，对JVM垃圾回收机制有深入研究，并进行调优； 4、对SQL优化有一定的积累，熟练掌握Redis、MQ的使用； 5、有互联网金融行业开发经验优先； 6、热爱技术、学习能力强、注重代码质量、善于发现系统中的设计及实现风险； 连连支付大数据开发专家 职位诱惑： 年度旅游、氛围欢乐、年终丰厚、下午茶 职位描述： 任职要求： 负责完成大数据基础组件的封装，大数据技术使用规范的定义； 负责对业务开发团队进行大数据技术的培训与开发指导； 负责对公司产品已有的大数据架构，不断改进完善； 负责跟进大数据前沿技术的发展，根据业务需要完成公司大数据架构的演进。 负责解决重大疑难问题，有开源组件的bug fix 经验者优先 职位要求： 熟练掌握JAVA开发语言，有4年以上大数据开发经验； 对数据敏感，有较强的逻辑分析能力，对 (大) 数据处理和分析有多年从事经验，有复杂业务和算法的数据平台建设经验； 有分布式数据存储和流式计算开发经验，熟悉Hadoop生态相关技术及各种大数据计算框架，熟练使用Flink、 Hadoop、Spark、HDFS、Hbase、Kafka、ElasticSearch、Solr，Druid有优化经验者优先； 对实时指标的开发和架构经验者优先； 有较强的技术好奇心和求知欲，有技术总结的习惯（如写技术博客）； 云集资深Java开发工程师 职位诱惑： 五险一金，年终奖丰厚，年度旅游，福利多多 职位描述： 岗位职责： 1.深入理解业务功能，负责相关核心模块设计开发和实现 2.协助对服务器程序进行架构分析和软件设计，并完成相应的文档； 3.解决项目开发实施过程中遇到的技术问题，制定解决方案, 快速分析问题并优化解决问题, 后续复盘总结 4.开发服务端各项周边工具； 岗位要求： 本科以上学历，3年以上java服务器端开发经验，精通java语言，有良好的编程习惯 熟悉Linux 系统.熟悉mysql数据库.能独立设计数据库结构，掌握备份.优化.合并方案 熟悉网络连接相关知识，熟练掌握socket技术，熟悉netty/mina框架中的至少一种，对HTTP协议有一定的理解,熟悉多线程技术 对算法和数据结构以及基本概念有很好的掌握和理解，熟悉常用设计模式 有过完整的游戏项目开发经验优先 总结互联网企业的岗位要求 1. Java JAVA基础扎实，理解并能熟练使用IO、多线程，对JVM垃圾回收机制有深入研究，并进行调优； 类加载机制 2. 框架 Spring 、SpringMVC、Spring Boot、Mybatis核心思想和实现原理 3. 微服务架构 微服务理论、集群、分布式理论、服务拆分(水平垂直) Spring Cloud、Dubbo核心思想和实现原理 4. 数据存储、缓冲、缓存、搜索 SQL、Nosql、MQ、Redis、Elasticsearch 数据库性能调优，高可用、高并发 5. 编程习惯、代码质量、设计模式、算法与数据结构 思维敏捷，逻辑严密，学习能力强，适应能力好，有强烈的责任心，有优秀的团队合作能力。 具备良好的编码规范，面向对象设计理解，熟悉面向对象设计原则，掌握设计模式及应用场景。 具备良好的沟通和团队协作能力，工作积极主动，思路清晰，责任心强 6. Linux操作系统、网络 Netty、网络协议 7. 世界观、价值观 针对以上知识点系统学习计划 看书、看视频、看系列博客、和大佬交流学习经验和过程， 监督机制，熔断机制，缓冲机制 书籍 我的Java入门自学书单 我的Java进阶书单 博客网站 Java技术驿站 有很多系列源码解析，死磕Java系列等等 梁桂钊的博客 框架、工程实践 拉勾网高质量内容 酷壳网 作者的世界观、技术分享、人生经验 阮一峰的网络日志 作者的世界观、技术分享 纯洁的微笑 技术分享、Spring Boot、Spring Cloud 学习平台 极客时间 慕课网 Gitchat B站 掘金小册 中国mooc大学 学堂在线 Coursera LeetCode 牛客 微信读书 多看阅读 记录和总结的工具 Gridea博客(开源博客软件，只用方便，够用) 有道云笔记 Typora(用Typora写Markdown流畅的一逼，配合uPic图床，简直爱上知识积累和分享) Markdown(编辑语法) MindMaster思维导图 PPT(画图) uPic(开源图床工具) ","link":"https://xinrong2019.github.io/post/mian-xiang-jian-li-bian-cheng/"},{"title":"[死磕Spring]--IOC之获取Document 对象","content":"本文主要基于 Spring 5.0.6.RELEASE 摘要: 原创出处 http://cmsblogs.com/?p=2695 「小明哥」，谢谢！ 在 XmlBeanDefinitionReader#doLoadDocument(InputSource inputSource, Resource resource) 方法，中做了两件事情： 调用 #getValidationModeForResource(Resource resource) 方法，获取指定资源（xml）的验证模式。 上篇博客，我们已经详细解析。 调用 DocumentLoader#loadDocument(InputSource inputSource, EntityResolver entityResolver, ErrorHandler errorHandler, int validationMode, boolean namespaceAware) 方法，获取 XML Document 实例。 本篇博客，我们来详细解析。 1. DocumentLoader 获取 Document 的策略，由接口 org.springframework.beans.factory.xml.DocumentLoader 定义。代码如下： FROM 《Spring 源码深度解析》P16 页 定义从资源文件加载到转换为 Document 的功能。 public interface DocumentLoader { Document loadDocument( InputSource inputSource, EntityResolver entityResolver, ErrorHandler errorHandler, int validationMode, boolean namespaceAware) throws Exception; } inputSource 方法参数，加载 Document 的 Resource 资源。 entityResolver 方法参数，解析文件的解析器。 errorHandler 方法参数，处理加载 Document 对象的过程的错误。 validationMode 方法参数，验证模式。 namespaceAware 方法参数，命名空间支持。如果要提供对 XML 名称空间的支持，则需要值为 true 。 1.1 DefaultDocumentLoader 该方法由 DocumentLoader 的默认实现类 org.springframework.beans.factory.xml.DefaultDocumentLoader 实现。代码如下： /** * Load the {@link Document} at the supplied {@link InputSource} using the standard JAXP-configured * XML parser. */ @Override public Document loadDocument(InputSource inputSource, EntityResolver entityResolver, ErrorHandler errorHandler, int validationMode, boolean namespaceAware) throws Exception { // &lt;1&gt; 创建 DocumentBuilderFactory DocumentBuilderFactory factory = createDocumentBuilderFactory(validationMode, namespaceAware); if (logger.isTraceEnabled()) { logger.trace(&quot;Using JAXP provider [&quot; + factory.getClass().getName() + &quot;]&quot;); } // &lt;2&gt; 创建 DocumentBuilder DocumentBuilder builder = createDocumentBuilder(factory, entityResolver, errorHandler); // &lt;3&gt; 解析 XML InputSource 返回 Document 对象 return builder.parse(inputSource); } 首先，调用 #createDocumentBuilderFactory(...) 方法，创建 javax.xml.parsers.DocumentBuilderFactory 对象。代码如下： /** * JAXP attribute used to configure the schema language for validation. */ private static final String SCHEMA_LANGUAGE_ATTRIBUTE = &quot;http://java.sun.com/xml/jaxp/properties/schemaLanguage&quot;; /** * JAXP attribute value indicating the XSD schema language. */ private static final String XSD_SCHEMA_LANGUAGE = &quot;http://www.w3.org/2001/XMLSchema&quot;; protected DocumentBuilderFactory createDocumentBuilderFactory(int validationMode, boolean namespaceAware) throws ParserConfigurationException { // 创建 DocumentBuilderFactory DocumentBuilderFactory factory = DocumentBuilderFactory.newInstance(); factory.setNamespaceAware(namespaceAware); // 设置命名空间支持 if (validationMode != XmlValidationModeDetector.VALIDATION_NONE) { factory.setValidating(true); // 开启校验 // XSD 模式下，设置 factory 的属性 if (validationMode == XmlValidationModeDetector.VALIDATION_XSD) { // Enforce namespace aware for XSD... factory.setNamespaceAware(true); // XSD 模式下，强制设置命名空间支持 // 设置 SCHEMA_LANGUAGE_ATTRIBUTE try { factory.setAttribute(SCHEMA_LANGUAGE_ATTRIBUTE, XSD_SCHEMA_LANGUAGE); } catch (IllegalArgumentException ex) { ParserConfigurationException pcex = new ParserConfigurationException( &quot;Unable to validate using XSD: Your JAXP provider [&quot; + factory + &quot;] does not support XML Schema. Are you running on Java 1.4 with Apache Crimson? &quot; + &quot;Upgrade to Apache Xerces (or Java 1.5) for full XSD support.&quot;); pcex.initCause(ex); throw pcex; } } } return factory; } 然后，调用 #createDocumentBuilder(DocumentBuilderFactory factory, EntityResolver entityResolver,ErrorHandler errorHandler) 方法，创建 javax.xml.parsers.DocumentBuilder 对象。代码如下： protected DocumentBuilder createDocumentBuilder(DocumentBuilderFactory factory, @Nullable EntityResolver entityResolver, @Nullable ErrorHandler errorHandler) throws ParserConfigurationException { // 创建 DocumentBuilder 对象 DocumentBuilder docBuilder = factory.newDocumentBuilder(); // &lt;x&gt; 设置 EntityResolver 属性 if (entityResolver != null) { docBuilder.setEntityResolver(entityResolver); } // 设置 ErrorHandler 属性 if (errorHandler != null) { docBuilder.setErrorHandler(errorHandler); } return docBuilder; } 在 &lt;x&gt;处，设置 DocumentBuilder 的 EntityResolver 属性。关于它，在 「2. EntityResolver」 会详细解析。 最后，调用 DocumentBuilder#parse(InputSource) 方法，解析 InputSource ，返回 Document 对象。 2. EntityResolver 通过 DocumentLoader#loadDocument(...) 方法来获取 Document 对象时，有一个方法参数 entityResolver 。该参数是通过 XmlBeanDefinitionReader#getEntityResolver() 方法来获取的。代码如下： #getEntityResolver() 方法，返回指定的解析器，如果没有指定，则构造一个未指定的默认解析器。 // XmlBeanDefinitionReader.java /** * EntityResolver 解析器 */ @Nullable private EntityResolver entityResolver; protected EntityResolver getEntityResolver() { if (this.entityResolver == null) { // Determine default EntityResolver to use. ResourceLoader resourceLoader = getResourceLoader(); if (resourceLoader != null) { this.entityResolver = new ResourceEntityResolver(resourceLoader); } else { this.entityResolver = new DelegatingEntityResolver(getBeanClassLoader()); } } return this.entityResolver; } 如果 ResourceLoader 不为 null，则根据指定的 ResourceLoader 创建一个 ResourceEntityResolver 对象。 如果 ResourceLoader 为 null ，则创建 一个 DelegatingEntityResolver 对象。该 Resolver 委托给默认的 BeansDtdResolver 和 PluggableSchemaResolver 。 2.1 子类 上面的方法，一共涉及四个 EntityResolver 的子类： org.springframework.beans.factory.xm.BeansDtdResolver ：实现 EntityResolver 接口，Spring Bean dtd 解码器，用来从 classpath 或者 jar 文件中加载 dtd 。部分代码如下： private static final String DTD_EXTENSION = &quot;.dtd&quot;; private static final String DTD_NAME = &quot;spring-beans&quot;; org.springframework.beans.factory.xml.PluggableSchemaResolver ，实现 EntityResolver 接口，读取 classpath 下的所有 &quot;META-INF/spring.schemas&quot; 成一个 namespaceURI 与 Schema 文件地址的 map 。代码如下： /** * The location of the file that defines schema mappings. * Can be present in multiple JAR files. * * 默认 {@link #schemaMappingsLocation} 地址 */ public static final String DEFAULT_SCHEMA_MAPPINGS_LOCATION = &quot;META-INF/spring.schemas&quot;; @Nullable private final ClassLoader classLoader; /** * Schema 文件地址 */ private final String schemaMappingsLocation; /** Stores the mapping of schema URL -&gt; local schema path. */ @Nullable private volatile Map&lt;String, String&gt; schemaMappings; // namespaceURI 与 Schema 文件地址的映射集合 org.springframework.beans.factory.xml.DelegatingEntityResolver ：实现 EntityResolver 接口，分别代理 dtd 的 BeansDtdResolver 和 xml schemas 的 PluggableSchemaResolver 。代码如下： /** Suffix for DTD files. */ public static final String DTD_SUFFIX = &quot;.dtd&quot;; /** Suffix for schema definition files. */ public static final String XSD_SUFFIX = &quot;.xsd&quot;; private final EntityResolver dtdResolver; private final EntityResolver schemaResolver; // 默认 public DelegatingEntityResolver(@Nullable ClassLoader classLoader) { this.dtdResolver = new BeansDtdResolver(); this.schemaResolver = new PluggableSchemaResolver(classLoader); } // 自定义 public DelegatingEntityResolver(EntityResolver dtdResolver, EntityResolver schemaResolver) { Assert.notNull(dtdResolver, &quot;'dtdResolver' is required&quot;); Assert.notNull(schemaResolver, &quot;'schemaResolver' is required&quot;); this.dtdResolver = dtdResolver; this.schemaResolver = schemaResolver; } org.springframework.beans.factory.xml.ResourceEntityResolver ：继承自 DelegatingEntityResolver 类，通过 ResourceLoader 来解析实体的引用。代码如下： private final ResourceLoader resourceLoader; public ResourceEntityResolver(ResourceLoader resourceLoader) { super(resourceLoader.getClassLoader()); this.resourceLoader = resourceLoader; } 2.2 作用 EntityResolver 的作用就是，通过实现它，应用可以自定义如何寻找【验证文件】的逻辑。 FROM 《Spring 源码深度解析》 在 loadDocument 方法中涉及一个参数 EntityResolver ，何为EntityResolver？官网这样解释：如果 SAX 应用程序需要实现自定义处理外部实体，则必须实现此接口并使用 setEntityResolver 方法向SAX 驱动器注册一个实例。也就是说，对于解析一个XML，SAX 首先读取该 XML 文档上的声明，根据声明去寻找相应的 DTD 定义，以便对文档进行一个验证。默认的寻找规则，即通过网络（实现上就是声明的DTD的URI地址）来下载相应的DTD声明，并进行认证。下载的过程是一个漫长的过程，而且当网络中断或不可用时，这里会报错，就是因为相应的DTD声明没有被找到的原因。 EntityResolver 的作用是项目本身就可以提供一个如何寻找 DTD 声明的方法，即由程序来实现寻找 DTD 声明的过程，比如我们将 DTD 文件放到项目中某处，在实现时直接将此文档读取并返回给 SAX 即可。这样就避免了通过网络来寻找相应的声明。 org.xml.sax.EntityResolver 接口，代码如下： public interface EntityResolver { public abstract InputSource resolveEntity (String publicId, String systemId) throws SAXException, IOException; } 接口方法接收两个参数 publicId 和 systemId ，并返回 InputSource 对象。两个参数声明如下： publicId ：被引用的外部实体的公共标识符，如果没有提供，则返回 null 。 systemId ：被引用的外部实体的系统标识符。 这两个参数的实际内容和具体的验证模式的关系如下： XSD 验证模式 publicId：null systemId：http://www.springframework.org/schema/beans/spring-beans.xsd DTD 验证模式 publicId：-//SPRING//DTD BEAN 2.0//EN systemId：http://www.springframework.org/dtd/spring-beans.dtd 2.3 DelegatingEntityResolver 我们知道在 Spring 中使用 DelegatingEntityResolver 为 EntityResolver 的实现类。#resolveEntity(String publicId, String systemId) 方法，实现如下： @Override @Nullable public InputSource resolveEntity(String publicId, @Nullable String systemId) throws SAXException, IOException { if (systemId != null) { // DTD 模式 if (systemId.endsWith(DTD_SUFFIX)) { return this.dtdResolver.resolveEntity(publicId, systemId); // XSD 模式 } else if (systemId.endsWith(XSD_SUFFIX)) { return this.schemaResolver.resolveEntity(publicId, systemId); } } return null; } 如果是 DTD 验证模式，则使用 BeansDtdResolver 来进行解析 如果是 XSD 验证模式，则使用 PluggableSchemaResolver 来进行解析。 2.4 BeansDtdResolver BeansDtdResolver 的解析过程，代码如下： /** * DTD 文件的后缀 */ private static final String DTD_EXTENSION = &quot;.dtd&quot;; /** * Spring Bean DTD 的文件名 */ private static final String DTD_NAME = &quot;spring-beans&quot;; @Override @Nullable public InputSource resolveEntity(String publicId, @Nullable String systemId) throws IOException { if (logger.isTraceEnabled()) { logger.trace(&quot;Trying to resolve XML entity with public ID [&quot; + publicId + &quot;] and system ID [&quot; + systemId + &quot;]&quot;); } // 必须以 .dtd 结尾 if (systemId != null &amp;&amp; systemId.endsWith(DTD_EXTENSION)) { // 获取最后一个 / 的位置 int lastPathSeparator = systemId.lastIndexOf('/'); // 获取 spring-beans 的位置 int dtdNameStart = systemId.indexOf(DTD_NAME, lastPathSeparator); if (dtdNameStart != -1) { // 找到 String dtdFile = DTD_NAME + DTD_EXTENSION; if (logger.isTraceEnabled()) { logger.trace(&quot;Trying to locate [&quot; + dtdFile + &quot;] in Spring jar on classpath&quot;); } try { // 创建 ClassPathResource 对象 Resource resource = new ClassPathResource(dtdFile, getClass()); // 创建 InputSource 对象，并设置 publicId、systemId 属性 InputSource source = new InputSource(resource.getInputStream()); source.setPublicId(publicId); source.setSystemId(systemId); if (logger.isTraceEnabled()) { logger.trace(&quot;Found beans DTD [&quot; + systemId + &quot;] in classpath: &quot; + dtdFile); } return source; } catch (IOException ex) { if (logger.isDebugEnabled()) { logger.debug(&quot;Could not resolve beans DTD [&quot; + systemId + &quot;]: not found in classpath&quot;, ex); } } } } // 使用默认行为，从网络上下载 // Use the default behavior -&gt; download from website or wherever. return null; } 从上面的代码中，我们可以看到，加载 DTD 类型的 BeansDtdResolver#resolveEntity(...) 过程，只是对 systemId 进行了简单的校验（从最后一个 / 开始，内容中是否包含 spring-beans），然后构造一个 InputSource 对象，并设置 publicId、systemId 属性，然后返回。 2.5 PluggableSchemaResolver PluggableSchemaResolver 的解析过程，代码如下: @Nullable private final ClassLoader classLoader; /** * Schema 文件地址 */ private final String schemaMappingsLocation; /** Stores the mapping of schema URL -&gt; local schema path. */ @Nullable private volatile Map&lt;String, String&gt; schemaMappings; // namespaceURI 与 Schema 文件地址的映射集合 @Override @Nullable public InputSource resolveEntity(String publicId, @Nullable String systemId) throws IOException { if (logger.isTraceEnabled()) { logger.trace(&quot;Trying to resolve XML entity with public id [&quot; + publicId + &quot;] and system id [&quot; + systemId + &quot;]&quot;); } if (systemId != null) { // 获得 Resource 所在位置 String resourceLocation = getSchemaMappings().get(systemId); if (resourceLocation != null) { // 创建 ClassPathResource Resource resource = new ClassPathResource(resourceLocation, this.classLoader); try { // 创建 InputSource 对象，并设置 publicId、systemId 属性 InputSource source = new InputSource(resource.getInputStream()); source.setPublicId(publicId); source.setSystemId(systemId); if (logger.isTraceEnabled()) { logger.trace(&quot;Found XML schema [&quot; + systemId + &quot;] in classpath: &quot; + resourceLocation); } return source; } catch (FileNotFoundException ex) { if (logger.isDebugEnabled()) { logger.debug(&quot;Could not find XML schema [&quot; + systemId + &quot;]: &quot; + resource, ex); } } } } return null; } 首先调用 #getSchemaMappings() 方法，获取一个映射表(systemId 与其在本地的对照关系)。代码如下： private Map&lt;String, String&gt; getSchemaMappings() { Map&lt;String, String&gt; schemaMappings = this.schemaMappings; // 双重检查锁，实现 schemaMappings 单例 if (schemaMappings == null) { synchronized (this) { schemaMappings = this.schemaMappings; if (schemaMappings == null) { if (logger.isTraceEnabled()) { logger.trace(&quot;Loading schema mappings from [&quot; + this.schemaMappingsLocation + &quot;]&quot;); } try { // 以 Properties 的方式，读取 schemaMappingsLocation Properties mappings = PropertiesLoaderUtils.loadAllProperties(this.schemaMappingsLocation, this.classLoader); if (logger.isTraceEnabled()) { logger.trace(&quot;Loaded schema mappings: &quot; + mappings); } // 将 mappings 初始化到 schemaMappings 中 schemaMappings = new ConcurrentHashMap&lt;&gt;(mappings.size()); CollectionUtils.mergePropertiesIntoMap(mappings, schemaMappings); this.schemaMappings = schemaMappings; } catch (IOException ex) { throw new IllegalStateException( &quot;Unable to load schema mappings from location [&quot; + this.schemaMappingsLocation + &quot;]&quot;, ex); } } } } return schemaMappings; } 映射表如下（部分）: 然后，根据传入的 systemId 获取该 systemId 在本地的路径 resourceLocation 。 最后，根据 resourceLocation ，构造 InputSource 对象。 2.6 ResourceEntityResolver ResourceEntityResolver 的解析过程，代码如下: private final ResourceLoader resourceLoader; @Override @Nullable public InputSource resolveEntity(String publicId, @Nullable String systemId) throws SAXException, IOException { // 调用父类的方法，进行解析 InputSource source = super.resolveEntity(publicId, systemId); // 解析失败，resourceLoader 进行解析 if (source == null &amp;&amp; systemId != null) { // 获得 resourcePath ，即 Resource 资源地址 String resourcePath = null; try { String decodedSystemId = URLDecoder.decode(systemId, &quot;UTF-8&quot;); // 使用 UTF-8 ，解码 systemId String givenUrl = new URL(decodedSystemId).toString(); // 转换成 URL 字符串 // 解析文件资源的相对路径（相对于系统根路径） String systemRootUrl = new File(&quot;&quot;).toURI().toURL().toString(); // Try relative to resource base if currently in system root. if (givenUrl.startsWith(systemRootUrl)) { resourcePath = givenUrl.substring(systemRootUrl.length()); } } catch (Exception ex) { // Typically a MalformedURLException or AccessControlException. if (logger.isDebugEnabled()) { logger.debug(&quot;Could not resolve XML entity [&quot; + systemId + &quot;] against system root URL&quot;, ex); } // No URL (or no resolvable URL) -&gt; try relative to resource base. resourcePath = systemId; } if (resourcePath != null) { if (logger.isTraceEnabled()) { logger.trace(&quot;Trying to locate XML entity [&quot; + systemId + &quot;] as resource [&quot; + resourcePath + &quot;]&quot;); } // 获得 Resource 资源 Resource resource = this.resourceLoader.getResource(resourcePath); // 创建 InputSource 对象 source = new InputSource(resource.getInputStream()); // 设置 publicId 和 systemId 属性 source.setPublicId(publicId); source.setSystemId(systemId); if (logger.isDebugEnabled()) { logger.debug(&quot;Found XML entity [&quot; + systemId + &quot;]: &quot; + resource); } } } return source; } 首先，调用父类的方法，进行解析。 如果失败，使用 resourceLoader ，尝试读取 systemId 对应的 Resource 资源。 2.7 自定义 EntityResolver #getEntityResolver() 方法返回 EntityResolver 对象。那么怎么进行自定义 EntityResolver 呢? If a SAX application needs to implement customized handling for external entities, it must implement this interface and register an instance with the SAX driver using the setEntityResolver method. 就是说：如果 SAX 应用程序需要实现自定义处理外部实体，则必须实现此接口，并使用 #setEntityResolver(EntityResolver entityResolver) 方法，向 SAX 驱动器注册一个 EntityResolver 实例。 示例如下： public class MyResolver implements EntityResolver { @Override public InputSource resolveEntity(String publicId, String systemId) { if (systemId.equals(&quot;http://www.myhost.com/today&quot;)) { MyReader reader = new MyReader(); return new InputSource(reader); } else { // use the default behaviour return null; } } } 我们首先将 &quot;spring-student.xml&quot; 文件中的 XSD 声明的地址改掉，如下： 如果我们再次运行，则会报如下错误： 从上面的错误可以看到，是在进行文档验证时，无法根据声明找到 XSD 验证文件而导致无法进行 XML 文件验证。在 《【死磕 Spring】—— IoC 之获取验证模型》 中讲到，如果要解析一个 XML 文件，SAX 首先会读取该 XML 文档上的声明，然后根据声明去寻找相应的 DTD 定义，以便对文档进行验证。默认的加载规则是通过网络方式下载验证文件，而在实际生产环境中我们会遇到网络中断或者不可用状态，那么就应用就会因为无法下载验证文件而报错。 3. 小结 是不是看到此处，有点懵逼，不是说好了分享获取 Document 对象，结果内容主要是 EntityResolver 呢？因为，从 XML 中获取 Document 对象，已经有 javax.xml 库进行解析。而 EntityResolver 的重点，是在于如何获取【验证文件】，从而验证用户写的 XML 是否通过验证。 ","link":"https://xinrong2019.github.io/post/si-ke-spring-ioc-zhi-huo-qu-document-dui-xiang/"},{"title":"[死磕Spring]--IOC之获取验证模型","content":"本文主要基于 Spring 5.0.6.RELEASE 摘要: 原创出处 http://cmsblogs.com/?p=2688 「小明哥」，谢谢！ 在上篇博客【死磕 Spring】—— IoC 之加载 Definitions 中提到，在核心逻辑方法 #doLoadBeanDefinitions(InputSource inputSource, Resource resource) 方法中，中主要是做三件事情： 调用 #getValidationModeForResource(Resource resource) 方法，获取指定资源（xml）的验证模式。 调用 DocumentLoader#loadDocument(InputSource inputSource, EntityResolver entityResolver,ErrorHandler errorHandler, int validationMode, boolean namespaceAware) 方法，获取 XML Document 实例。 调用 #registerBeanDefinitions(Document doc, Resource resource) 方法，根据获取的 Document 实例，注册 Bean 信息。 这篇博客主要第 1 步，分析获取 xml 文件的验证模式。为什么需要获取验证模式呢？原因如下： XML 文件的验证模式保证了 XML 文件的正确性。 1. DTD 与 XSD 的区别 1.1 DTD DTD(Document Type Definition)，即文档类型定义，为 XML 文件的验证机制，属于 XML 文件中组成的一部分。DTD 是一种保证 XML 文档格式正确的有效验证方式，它定义了相关 XML 文档的元素、属性、排列方式、元素的内容类型以及元素的层次结构。其实 DTD 就相当于 XML 中的 “词汇”和“语法”，我们可以通过比较 XML 文件和 DTD 文件 来看文档是否符合规范，元素和标签使用是否正确。 要在 Spring 中使用 DTD，需要在 Spring XML 文件头部声明： &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;!DOCTYPE beans PUBLIC &quot;-//SPRING//DTD BEAN//EN&quot; &quot;http://www.springframework.org/dtd/spring-beans.dtd&quot;&gt; 它没有使用 XML 格式，而是自己定义了一套格式，相对解析器的重用性较差；而且 DTD 的构建和访问没有标准的编程接口，因而解析器很难简单的解析 DTD 文档。 DTD 对元素的类型限制较少；同时其他的约束力也叫弱。 DTD 扩展能力较差。 基于正则表达式的 DTD 文档的描述能力有限。 1.2 XSD 针对 DTD 的缺陷，W3C 在 2001 年推出 XSD。XSD（XML Schemas Definition）即 XML Schema 语言。XML Schema 本身就是一个 XML文档，使用的是 XML 语法，因此可以很方便的解析 XSD 文档。相对于 DTD，XSD 具有如下优势： XML Schema 基于 XML ，没有专门的语法。 XML Schema 可以象其他 XML 文件一样解析和处理。 XML Schema 比 DTD 提供了更丰富的数据类型。 XML Schema 提供可扩充的数据模型。 XML Schema 支持综合命名空间。 XML Schema 支持属性组。 2. getValidationModeForResource // XmlBeanDefinitionReader.java // 禁用验证模式 public static final int VALIDATION_NONE = XmlValidationModeDetector.VALIDATION_NONE; // 自动获取验证模式 public static final int VALIDATION_AUTO = XmlValidationModeDetector.VALIDATION_AUTO; // DTD 验证模式 public static final int VALIDATION_DTD = XmlValidationModeDetector.VALIDATION_DTD; // XSD 验证模式 public static final int VALIDATION_XSD = XmlValidationModeDetector.VALIDATION_XSD; /** * 验证模式。默认为自动模式。 */ private int validationMode = VALIDATION_AUTO; protected int getValidationModeForResource(Resource resource) { // &lt;1&gt; 获取指定的验证模式 int validationModeToUse = getValidationMode(); // 首先，如果手动指定，则直接返回 if (validationModeToUse != VALIDATION_AUTO) { return validationModeToUse; } // 其次，自动获取验证模式 int detectedMode = detectValidationMode(resource); if (detectedMode != VALIDATION_AUTO) { return detectedMode; } // 最后，使用 VALIDATION_XSD 做为默认 // Hmm, we didn't get a clear indication... Let's assume XSD, // since apparently no DTD declaration has been found up until // detection stopped (before finding the document's root tag). return VALIDATION_XSD; } &lt;1&gt; 处，调用 #getValidationMode() 方法，获取指定的验证模式( validationMode )。如果有手动指定，则直接返回。另外，对对于 validationMode 属性的设置和获得的代码，代码如下： public void setValidationMode(int validationMode) { this.validationMode = validationMode; } public int getValidationMode() { return this.validationMode; } &lt;2&gt; 处，调用 #detectValidationMode(Resource resource) 方法，自动获取验证模式。代码如下： /** * XML 验证模式探测器 */ private final XmlValidationModeDetector validationModeDetector = new XmlValidationModeDetector(); protected int detectValidationMode(Resource resource) { // 不可读，抛出 BeanDefinitionStoreException 异常 if (resource.isOpen()) { throw new BeanDefinitionStoreException( &quot;Passed-in Resource [&quot; + resource + &quot;] contains an open stream: &quot; + &quot;cannot determine validation mode automatically. Either pass in a Resource &quot; + &quot;that is able to create fresh streams, or explicitly specify the validationMode &quot; + &quot;on your XmlBeanDefinitionReader instance.&quot;); } // 打开 InputStream 流 InputStream inputStream; try { inputStream = resource.getInputStream(); } catch (IOException ex) { throw new BeanDefinitionStoreException( &quot;Unable to determine validation mode for [&quot; + resource + &quot;]: cannot open InputStream. &quot; + &quot;Did you attempt to load directly from a SAX InputSource without specifying the &quot; + &quot;validationMode on your XmlBeanDefinitionReader instance?&quot;, ex); } // &lt;x&gt; 获取相应的验证模式 try { return this.validationModeDetector.detectValidationMode(inputStream); } catch (IOException ex) { throw new BeanDefinitionStoreException(&quot;Unable to determine validation mode for [&quot; + resource + &quot;]: an error occurred whilst reading from the InputStream.&quot;, ex); } } 核心在于 &lt;x&gt;处，调用 XmlValidationModeDetector#detectValidationMode(InputStream inputStream) 方法，获取相应的验证模式。详细解析，见 「3. XmlValidationModeDetector」 中。 &lt;3&gt; 处，使用 VALIDATION_XSD 做为默认。 3. XmlValidationModeDetector org.springframework.util.xml.XmlValidationModeDetector ，XML 验证模式探测器。 public int detectValidationMode(InputStream inputStream) throws IOException { // Peek into the file to look for DOCTYPE. BufferedReader reader = new BufferedReader(new InputStreamReader(inputStream)); try { // 是否为 DTD 校验模式。默认为，非 DTD 模式，即 XSD 模式 boolean isDtdValidated = false; String content; // &lt;0&gt; 循环，逐行读取 XML 文件的内容 while ((content = reader.readLine()) != null) { content = consumeCommentTokens(content); // 跳过，如果是注释，或者 if (this.inComment || !StringUtils.hasText(content)) { continue; } // &lt;1&gt; 包含 DOCTYPE 为 DTD 模式 if (hasDoctype(content)) { isDtdValidated = true; break; } // &lt;2&gt; hasOpeningTag 方法会校验，如果这一行有 &lt; ，并且 &lt; 后面跟着的是字母，则返回 true 。 if (hasOpeningTag(content)) { // End of meaningful data... break; } } // 返回 VALIDATION_DTD or VALIDATION_XSD 模式 return (isDtdValidated ? VALIDATION_DTD : VALIDATION_XSD); } catch (CharConversionException ex) { // &lt;3&gt; 返回 VALIDATION_AUTO 模式 // Choked on some character encoding... // Leave the decision up to the caller. return VALIDATION_AUTO; } finally { reader.close(); } } &lt;0&gt; 处，从代码中看，主要是通过读取 XML 文件的内容，来进行自动判断。 &lt;1&gt; 处，调用 #hasDoctype(String content) 方法，判断内容中如果包含有 &quot;DOCTYPE“ ，则为 DTD 验证模式。代码如下： /** * The token in a XML document that declares the DTD to use for validation * and thus that DTD validation is being used. */ private static final String DOCTYPE = &quot;DOCTYPE&quot;; private boolean hasDoctype(String content) { return content.contains(DOCTYPE); } &lt;2&gt; 处，调用 #hasOpeningTag(String content) 方法，判断如果这一行包含 &lt; ，并且 &lt; 紧跟着的是字母，则为 XSD 验证模式。代码如下： /** * Does the supplied content contain an XML opening tag. If the parse state is currently * in an XML comment then this method always returns false. It is expected that all comment * tokens will have consumed for the supplied content before passing the remainder to this method. */ private boolean hasOpeningTag(String content) { if (this.inComment) { return false; } int openTagIndex = content.indexOf('&lt;'); return (openTagIndex &gt; -1 // &lt; 存在 &amp;&amp; (content.length() &gt; openTagIndex + 1) // &lt; 后面还有内容 &amp;&amp; Character.isLetter(content.charAt(openTagIndex + 1))); // &lt; 后面的内容是字母 } &lt;3&gt; 处，如果发生 CharConversionException 异常，则为 VALIDATION_AUTO 模式。 关于 #consumeCommentTokens(String content) 方法，代码比较复杂。感兴趣的胖友可以看看。代码如下： /** * The token that indicates the start of an XML comment. */ private static final String START_COMMENT = &quot;&lt;!--&quot;; /** * The token that indicates the end of an XML comment. */ private static final String END_COMMENT = &quot;--&gt;&quot;; /** * Consumes all the leading comment data in the given String and returns the remaining content, which * may be empty since the supplied content might be all comment data. For our purposes it is only important * to strip leading comment content on a line since the first piece of non comment content will be either * the DOCTYPE declaration or the root element of the document. */ @Nullable private String consumeCommentTokens(String line) { // 非注释 if (!line.contains(START_COMMENT) &amp;&amp; !line.contains(END_COMMENT)) { return line; } String currLine = line; while ((currLine = consume(currLine)) != null) { if (!this.inComment &amp;&amp; !currLine.trim().startsWith(START_COMMENT)) { return currLine; } } return null; } /** * Consume the next comment token, update the &quot;inComment&quot; flag * and return the remaining content. */ @Nullable private String consume(String line) { int index = (this.inComment ? endComment(line) : startComment(line)); return (index == -1 ? null : line.substring(index)); } /** * Try to consume the {@link #START_COMMENT} token. * @see #commentToken(String, String, boolean) */ private int startComment(String line) { return commentToken(line, START_COMMENT, true); } private int endComment(String line) { return commentToken(line, END_COMMENT, false); } /** * Try to consume the supplied token against the supplied content and update the * in comment parse state to the supplied value. Returns the index into the content * which is after the token or -1 if the token is not found. */ private int commentToken(String line, String token, boolean inCommentIfPresent) { int index = line.indexOf(token); if (index &gt; - 1) { this.inComment = inCommentIfPresent; } return (index == -1 ? index : index + token.length()); } 😈 反正老艿艿没细看。哈哈哈哈。如果真看，如下两篇文章，有一定的辅助： 《spring源码（六）–XmlValidationModeDetector（获取xml文档校验模式）》 《XmlValidationModeDetector》 4. 小结 好了，XML 文件的验证模式分析完毕。下篇，我们来分析 #doLoadBeanDefinitions(InputSource inputSource, Resource resource) 方法的第 2 个步骤：获取 Document 实例。 ","link":"https://xinrong2019.github.io/post/si-ke-spring-ioc-zhi-huo-qu-yan-zheng-mo-xing/"},{"title":"[死磕Spring]--IoC之加载 BeanDefinition","content":"本文主要基于 Spring 5.0.6.RELEASE 摘要: 原创出处 http://cmsblogs.com/?p=2658 「小明哥」 先看一段熟悉的代码： ClassPathResource resource = new ClassPathResource(&quot;bean.xml&quot;); // &lt;1&gt; DefaultListableBeanFactory factory = new DefaultListableBeanFactory(); // &lt;2&gt; XmlBeanDefinitionReader reader = new XmlBeanDefinitionReader(factory); // &lt;3&gt; reader.loadBeanDefinitions(resource); // &lt;4&gt; 这段代码是 Spring 中编程式使用 IoC 容器，通过这四段简单的代码，我们可以初步判断 IoC 容器的使用过程。 获取资源 获取 BeanFactory 根据新建的 BeanFactory 创建一个 BeanDefinitionReader 对象，该 Reader 对象为资源的解析器 装载资源 整个过程就分为三个步骤：资源定位、装载、注册，如下： 资源定位。我们一般用外部资源来描述 Bean 对象，所以在初始化 IoC 容器的第一步就是需要定位这个外部资源。在上一篇博客（《【死磕 Spring】—— IoC 之 Spring 统一资源加载策略》）已经详细说明了资源加载的过程。 装载。装载就是 BeanDefinition 的载入。BeanDefinitionReader 读取、解析 Resource 资源，也就是将用户定义的 Bean 表示成 IoC 容器的内部数据结构：BeanDefinition 。 在 IoC 容器内部维护着一个 BeanDefinition Map 的数据结构 在配置文件中每一个&lt;bea&gt; 都对应着一个 BeanDefinition 对象。 😈 本文，我们分享的就是装载这个步骤。 FROM 《Spring 源码深度解析》P16 页 BeanDefinitionReader ，主要定义资源文件读取并转换为 BeanDefinition 的各个功能。 注册。向 IoC 容器注册在第二步解析好的 BeanDefinition，这个过程是通过 BeanDefinitionRegistry 接口来实现的。在 IoC 容器内部其实是将第二个过程解析得到的 BeanDefinition 注入到一个 HashMap 容器中，IoC 容器就是通过这个 HashMap 来维护这些 BeanDefinition 的。 在这里需要注意的一点是这个过程并没有完成依赖注入（Bean 创建），Bean 创建是发生在应用第一次调用 #getBean(...) 方法，向容器索要 Bean 时。 当然我们可以通过设置预处理，即对某个 Bean 设置 lazyinit = false 属性，那么这个 Bean 的依赖注入就会在容器初始化的时候完成。 FROM 老艿艿 简单的说，上面步骤的结果是，XML Resource =&gt; XML Document =&gt; Bean Definition 。 1. loadBeanDefinitions 资源定位在前面已经分析了，下面我们直接分析加载，上面看到的 reader.loadBeanDefinitions(resource) 代码，才是加载资源的真正实现，所以我们直接从该方法入手。代码如下： // XmlBeanDefinitionReader.java @Override public int loadBeanDefinitions(Resource resource) throws BeanDefinitionStoreException { return loadBeanDefinitions(new EncodedResource(resource)); } 从指定的 xml 文件加载 Bean Definition ，这里会先对 Resource 资源封装成 org.springframework.core.io.support.EncodedResource 对象。这里为什么需要将 Resource 封装成 EncodedResource 呢？主要是为了对 Resource 进行编码，保证内容读取的正确性。 然后，再调用 #loadBeanDefinitions(EncodedResource encodedResource) 方法，执行真正的逻辑实现。 /** * 当前线程，正在加载的 EncodedResource 集合。 */ private final ThreadLocal&lt;Set&lt;EncodedResource&gt;&gt; resourcesCurrentlyBeingLoaded = new NamedThreadLocal&lt;&gt;(&quot;XML bean definition resources currently being loaded&quot;); public int loadBeanDefinitions(EncodedResource encodedResource) throws BeanDefinitionStoreException { Assert.notNull(encodedResource, &quot;EncodedResource must not be null&quot;); if (logger.isTraceEnabled()) { logger.trace(&quot;Loading XML bean definitions from &quot; + encodedResource); } // &lt;1&gt; 获取已经加载过的资源 Set&lt;EncodedResource&gt; currentResources = this.resourcesCurrentlyBeingLoaded.get(); if (currentResources == null) { currentResources = new HashSet&lt;&gt;(4); this.resourcesCurrentlyBeingLoaded.set(currentResources); } if (!currentResources.add(encodedResource)) { // 将当前资源加入记录中。如果已存在，抛出异常 throw new BeanDefinitionStoreException(&quot;Detected cyclic loading of &quot; + encodedResource + &quot; - check your import definitions!&quot;); } try { // &lt;2&gt; 从 EncodedResource 获取封装的 Resource ，并从 Resource 中获取其中的 InputStream InputStream inputStream = encodedResource.getResource().getInputStream(); try { InputSource inputSource = new InputSource(inputStream); if (encodedResource.getEncoding() != null) { // 设置编码 inputSource.setEncoding(encodedResource.getEncoding()); } // 核心逻辑部分，执行加载 BeanDefinition return doLoadBeanDefinitions(inputSource, encodedResource.getResource()); } finally { inputStream.close(); } } catch (IOException ex) { throw new BeanDefinitionStoreException(&quot;IOException parsing XML document from &quot; + encodedResource.getResource(), ex); } finally { // 从缓存中剔除该资源 &lt;3&gt; currentResources.remove(encodedResource); if (currentResources.isEmpty()) { this.resourcesCurrentlyBeingLoaded.remove(); } } } &lt;1&gt; 处，通过 resourcesCurrentlyBeingLoaded.get() 代码，来获取已经加载过的资源，然后将encodedResource 加入其中，如果 resourcesCurrentlyBeingLoaded 中已经存在该资源，则抛出 BeanDefinitionStoreException异常。 为什么需要这么做呢？答案在 &quot;Detected cyclic loading&quot; ，避免一个 EncodedResource 在加载时，还没加载完成，又加载自身，从而导致死循环。 也因此，在 &lt;3&gt; 处，当一个 EncodedResource 加载完成后，需要从缓存中剔除。 &lt;2&gt; 处理，从 encodedResource 获取封装的 Resource 资源，并从 Resource 中获取相应的 InputStream ，然后将 InputStream 封装为 InputSource ，最后调用 #doLoadBeanDefinitions(InputSource inputSource, Resource resource) 方法，执行加载 Bean Definition 的真正逻辑。 2. doLoadBeanDefinitions /** * Actually load bean definitions from the specified XML file. * @param inputSource the SAX InputSource to read from * @param resource the resource descriptor for the XML file * @return the number of bean definitions found * @throws BeanDefinitionStoreException in case of loading or parsing errors * @see #doLoadDocument * @see #registerBeanDefinitions */ protected int doLoadBeanDefinitions(InputSource inputSource, Resource resource) throws BeanDefinitionStoreException { try { // &lt;1&gt; 获取 XML Document 实例 Document doc = doLoadDocument(inputSource, resource); // &lt;2&gt; 根据 Document 实例，注册 Bean 信息 int count = registerBeanDefinitions(doc, resource); if (logger.isDebugEnabled()) { logger.debug(&quot;Loaded &quot; + count + &quot; bean definitions from &quot; + resource); } return count; } catch (BeanDefinitionStoreException ex) { throw ex; } catch (SAXParseException ex) { throw new XmlBeanDefinitionStoreException(resource.getDescription(), &quot;Line &quot; + ex.getLineNumber() + &quot; in XML document from &quot; + resource + &quot; is invalid&quot;, ex); } catch (SAXException ex) { throw new XmlBeanDefinitionStoreException(resource.getDescription(), &quot;XML document from &quot; + resource + &quot; is invalid&quot;, ex); } catch (ParserConfigurationException ex) { throw new BeanDefinitionStoreException(resource.getDescription(), &quot;Parser configuration exception parsing XML from &quot; + resource, ex); } catch (IOException ex) { throw new BeanDefinitionStoreException(resource.getDescription(), &quot;IOException parsing XML document from &quot; + resource, ex); } catch (Throwable ex) { throw new BeanDefinitionStoreException(resource.getDescription(), &quot;Unexpected exception parsing XML document from &quot; + resource, ex); } } 在 &lt;1&gt; 处，调用 #doLoadDocument(InputSource inputSource, Resource resource) 方法，根据 xml 文件，获取 Document 实例。 在 &lt;2&gt; 处，调用 #registerBeanDefinitions(Document doc, Resource resource) 方法，根据获取的 Document 实例，注册 Bean 信息。 2.1 doLoadDocument /** * 获取 XML Document 实例 * * Actually load the specified document using the configured DocumentLoader. * @param inputSource the SAX InputSource to read from * @param resource the resource descriptor for the XML file * @return the DOM Document * @throws Exception when thrown from the DocumentLoader * @see #setDocumentLoader * @see DocumentLoader#loadDocument */ protected Document doLoadDocument(InputSource inputSource, Resource resource) throws Exception { return this.documentLoader.loadDocument(inputSource, getEntityResolver(), this.errorHandler, getValidationModeForResource(resource), isNamespaceAware()); } 调用 #getValidationModeForResource(Resource resource) 方法，获取指定资源（xml）的验证模式。详细解析，见 《【死磕 Spring】—— IoC 之获取验证模型》 。 调用 DocumentLoader#loadDocument(InputSource inputSource, EntityResolver entityResolver, ErrorHandler errorHandler, int validationMode, boolean namespaceAware) 方法，获取 XML Document 实例。详细解析，见 《【死磕 Spring】—— IoC 之获取 Document 对象》 。 2.2 registerBeanDefinitions 该方法的详细解析，见 《【死磕 Spring】—— IoC 之注册 BeanDefinition》 。 ","link":"https://xinrong2019.github.io/post/si-ke-spring-ioc-zhi-jia-zai-beandefinition/"},{"title":"个人管理","content":"个人知识积累和知识管理计划 算法1题（30分钟） 框架源码一篇（30分钟） Spring Core MyBatis Spring Boot 中间件一篇（30分钟） MySQL Dubbo Redis Spring Cloud RocketMQ Java（30分钟） 集合 并发、多线程、线程池 IO Netty JVM Hutools、Guava 设计模式 性能调优 家庭关系管理、心理健康管理 陪家人聊天，陪孩子玩（30分钟） 阅读相关书籍（30分钟） 吃饭 洗澡 身体健康管理 俯卧撑20个 仰卧起坐30个 深蹲30个 10年 10年前，18岁，读大一，应该是前20多年的一个巅峰期了。10年的时间，如果专心做一件事，应该早就成为专家了。然而，现实是，每件事都没有有始有终，没有闭环，事情往往只是开了个头，一开始就结束了。这样下去，生命后面的时间，活着的意义是什么？ 生命是长跑，贵在坚持 生命是长跑，长跑只有坚持和专注才能胜利，当我老了，不想为自己年轻时没有坚持做成事而后悔。 责任 是个有家室的人了，也有了孩子，最起码给孩子一个做一面可以照的镜子。 最好的状态 我对聪明这个词有一定见解，因为在高中时，我在别人眼里是聪明的，每次考试，各科目都是前三名，高考年级第一。 那个时候的我确实可以称得上是聪明的。那个时候的状态非常好。什么样的状态呢？ 回想下，其实做一个成绩好的孩子并不难，我的学习过程大体是这样的 课前预习，自己看一遍并理解 上课认真听讲，因为预习过了，老师说的内容基本上可以很好的和老师互动 课后认真做题 考前复习 分析一下当时自己的学习动机： 一开始并没有学习动机，就是闲着无聊，把书随便翻了一遍，发现自己可以不依赖老师讲课，也能够把书看懂看完。 这一块分析一下，可以归纳为自己比较主动的去学习。没有等待课堂上老师讲，然后自己被动的接收知识。 尝到了几次甜头（考上第一名，那种自信感，还有同学老师投来的目光和对待你的态度会有变化的，你会发现大家见到你都很开心）后，当然是继续保持成绩，坚持同样的学习过程了。而且也并不难，因为当时没有手机、没有电脑游戏的干扰。除了学习看书、看电视，就是找邻居的小伙伴下棋打牌之类的，电视也有时间安排，每天也只能看某个自己喜欢的动画片或者电视剧看那么一两集，因为它只放一两集，还不能回看。。对比我两岁不到的女儿现在想看佩奇，电视手机都可以随时点播某一集，方便是方便，但是没有计划性。 归纳起来，就是外界干扰少，生活简单，娱乐设施简单。而如今互联网让人们接受信息更便捷，信息也会被商家更主动的传播(比如广告)，打乱人们的计划。以前可以很专心的列学习计划。现在除了列学习计划，还要列出不做什么，抵制什么，否则会被被动的影响。比如手机和电视，根本不会一天放一集这种，需要你自己控制播放频度，或者学习的时候，采取极端的方式，不要带手机。 ","link":"https://xinrong2019.github.io/post/ge-ren-guan-li/"},{"title":"使用IDEA导入Gradle项目构建时遇到的问题","content":"问题1 127.0.0.1:8888问题 Could not resolve all artifacts for configuration ':classpath' 解决步骤 删除.m2,.gradle目录下的所有文件。 删除原来的项目，重新克隆 使用idea导入项目 在项目的build.gradle文件中，添加阿里源 repositories { maven { url 'http://maven.aliyun.com/nexus/content/groups/public/' } maven{ url 'http://maven.aliyun.com/nexus/content/repositories/jcenter'} } reimport 打开Project Settings -&gt; Modules 检查main和test模块下content root的位置有无报红，有删掉，没有跳过。 问题2 IDEA导入gradle项目后处处报红 IDEA版本：2019.2.1 解决步骤 重新导入项目，打开Project Structure 设置srouces 设置后的 ","link":"https://xinrong2019.github.io/post/shi-yong-idea-dao-ru-gradle-xiang-mu-gou-jian-shi-yu-dao-de-wen-ti/"},{"title":"[死磕Spring]--IoC之Spring 统一资源加载策略","content":"在学 Java SE 的时候，我们学习了一个标准类 java.net.URL，该类在 Java SE 中的定位为统一资源定位器（Uniform Resource Locator），但是我们知道它的实现基本只限于网络形式发布的资源的查找和定位。然而，实际上资源的定义比较广泛，除了网络形式的资源，还有以二进制形式存在的、以文件形式存在的、以字节流形式存在的等等。而且它可以存在于任何场所，比如网络、文件系统、应用程序中。所以 java.net.URL 的局限性迫使 Spring 必须实现自己的资源加载策略，该资源加载策略需要满足如下要求： 职能划分清楚。资源的定义和资源的加载应该要有一个清晰的界限； 统一的抽象。统一的资源定义和资源加载策略。资源加载后要返回统一的抽象给客户端，客户端要对资源进行怎样的处理，应该由抽象资源接口来界定。 1. 统一资源：Resource org.springframework.core.io.Resource 为 Spring 框架所有资源的抽象和访问接口，它继承 org.springframework.core.io.InputStreamSource接口。作为所有资源的统一抽象，Resource 定义了一些通用的方法，由子类 AbstractResource 提供统一的默认实现。定义如下： public interface Resource extends InputStreamSource { /** * 资源是否存在 */ boolean exists(); /** * 资源是否可读 */ default boolean isReadable() { return true; } /** * 资源所代表的句柄是否被一个 stream 打开了 */ default boolean isOpen() { return false; } /** * 是否为 File */ default boolean isFile() { return false; } /** * 返回资源的 URL 的句柄 */ URL getURL() throws IOException; /** * 返回资源的 URI 的句柄 */ URI getURI() throws IOException; /** * 返回资源的 File 的句柄 */ File getFile() throws IOException; /** * 返回 ReadableByteChannel */ default ReadableByteChannel readableChannel() throws IOException { return java.nio.channels.Channels.newChannel(getInputStream()); } /** * 资源内容的长度 */ long contentLength() throws IOException; /** * 资源最后的修改时间 */ long lastModified() throws IOException; /** * 根据资源的相对路径创建新资源 */ Resource createRelative(String relativePath) throws IOException; /** * 资源的文件名 */ @Nullable String getFilename(); /** * 资源的描述 */ String getDescription(); } 1.1 子类结构 类结构图如下： 从上图可以看到，Resource 根据资源的不同类型提供不同的具体实现，如下： FileSystemResource ：对 java.io.File 类型资源的封装，只要是跟 File 打交道的，基本上与FileSystemResource 也可以打交道。支持文件和 URL 的形式，实现 WritableResource 接口，且从 Spring Framework 5.0 开始，FileSystemResource 使用 NIO2 API进行读/写交互。 ByteArrayResource ：对字节数组提供的数据的封装。如果通过 InputStream 形式访问该类型的资源，该实现会根据字节数组的数据构造一个相应的 ByteArrayInputStream。 UrlResource ：对 java.net.URL类型资源的封装。内部委派 URL 进行具体的资源操作。 ClassPathResource ：class path 类型资源的实现。使用给定的 ClassLoader 或者给定的 Class 来加载资源。 InputStreamResource ：将给定的 InputStream 作为一种资源的 Resource 的实现类。 1.2 AbstractResource org.springframework.core.io.AbstractResource ，为 Resource 接口的默认抽象实现。它实现了 Resource 接口的大部分的公共实现，作为 Resource 接口中的重中之重，其定义如下： public abstract class AbstractResource implements Resource { /** * 判断文件是否存在，若判断过程产生异常（因为会调用SecurityManager来判断），就关闭对应的流 */ @Override public boolean exists() { try { // 基于 File 进行判断 return getFile().exists(); } catch (IOException ex) { // Fall back to stream existence: can we open the stream? // 基于 InputStream 进行判断 try { InputStream is = getInputStream(); is.close(); return true; } catch (Throwable isEx) { return false; } } } /** * 直接返回true，表示可读 */ @Override public boolean isReadable() { return true; } /** * 直接返回 false，表示未被打开 */ @Override public boolean isOpen() { return false; } /** * 直接返回false，表示不为 File */ @Override public boolean isFile() { return false; } /** * 抛出 FileNotFoundException 异常，交给子类实现 */ @Override public URL getURL() throws IOException { throw new FileNotFoundException(getDescription() + &quot; cannot be resolved to URL&quot;); } /** * 基于 getURL() 返回的 URL 构建 URI */ @Override public URI getURI() throws IOException { URL url = getURL(); try { return ResourceUtils.toURI(url); } catch (URISyntaxException ex) { throw new NestedIOException(&quot;Invalid URI [&quot; + url + &quot;]&quot;, ex); } } /** * 抛出 FileNotFoundException 异常，交给子类实现 */ @Override public File getFile() throws IOException { throw new FileNotFoundException(getDescription() + &quot; cannot be resolved to absolute file path&quot;); } /** * 根据 getInputStream() 的返回结果构建 ReadableByteChannel */ @Override public ReadableByteChannel readableChannel() throws IOException { return Channels.newChannel(getInputStream()); } /** * 获取资源的长度 * * 这个资源内容长度实际就是资源的字节长度，通过全部读取一遍来判断 */ @Override public long contentLength() throws IOException { InputStream is = getInputStream(); try { long size = 0; byte[] buf = new byte[255]; // 每次最多读取 255 字节 int read; while ((read = is.read(buf)) != -1) { size += read; } return size; } finally { try { is.close(); } catch (IOException ex) { } } } /** * 返回资源最后的修改时间 */ @Override public long lastModified() throws IOException { long lastModified = getFileForLastModifiedCheck().lastModified(); if (lastModified == 0L) { throw new FileNotFoundException(getDescription() + &quot; cannot be resolved in the file system for resolving its last-modified timestamp&quot;); } return lastModified; } protected File getFileForLastModifiedCheck() throws IOException { return getFile(); } /** * 抛出 FileNotFoundException 异常，交给子类实现 */ @Override public Resource createRelative(String relativePath) throws IOException { throw new FileNotFoundException(&quot;Cannot create a relative resource for &quot; + getDescription()); } /** * 获取资源名称，默认返回 null ，交给子类实现 */ @Override @Nullable public String getFilename() { return null; } /** * 返回资源的描述 */ @Override public String toString() { return getDescription(); } @Override public boolean equals(Object obj) { return (obj == this || (obj instanceof Resource &amp;&amp; ((Resource) obj).getDescription().equals(getDescription()))); } @Override public int hashCode() { return getDescription().hashCode(); } } 如果我们想要实现自定义的 Resource ，记住不要实现 Resource 接口，而应该继承 AbstractResource 抽象类，然后根据当前的具体资源特性覆盖相应的方法即可。 2. 统一资源定位：ResourceLoader 一开始就说了 Spring 将资源的定义和资源的加载区分开了，Resource 定义了统一的资源，那资源的加载则由 ResourceLoader 来统一定义。 org.springframework.core.io.ResourceLoader为 Spring 资源加载的统一抽象，具体的资源加载则由相应的实现类来完成，所以我们可以将 ResourceLoader 称作为统一资源定位器。其定义如下： FROM 《Spring 源码深度解析》P16 页 ResourceLoader，定义资源加载器，主要应用于根据给定的资源文件地址，返回对应的 Resource 。 public interface ResourceLoader { String CLASSPATH_URL_PREFIX = ResourceUtils.CLASSPATH_URL_PREFIX; // CLASSPATH URL 前缀。默认为：&quot;classpath:&quot; Resource getResource(String location); ClassLoader getClassLoader(); } #getResource(String location) 方法，根据所提供资源的路径 location 返回 Resource 实例，但是它不确保该 Resource 一定存在，需要调用 Resource#exist()方法来判断。 该方法支持以下模式的资源加载： URL位置资源，如 &quot;file:C:/test.dat&quot;。 ClassPath位置资源，如&quot;classpath:test.dat 。 相对路径资源，如&quot;WEB-INF/test.dat&quot; ，此时返回的Resource 实例，根据实现不同而不同。 该方法的主要实现是在其子类 DefaultResourceLoader中实现，具体过程我们在分析 DefaultResourceLoader 时做详细说明。 #getClassLoader()方法，返回 ClassLoader 实例，对于想要获取 ResourceLoader 使用的 ClassLoader 用户来说，可以直接调用该方法来获取。在分析 Resource 时，提到了一个类 ClassPathResource ，这个类是可以根据指定的 ClassLoader 来加载资源的。 2.1 子类结构 作为 Spring 统一的资源加载器，它提供了统一的抽象，具体的实现则由相应的子类来负责实现，其类的类结构图如下： 2.2 DefaultResourceLoader 与 AbstractResource 相似，org.springframework.core.io.DefaultResourceLoader是 ResourceLoader 的默认实现。 2.2.1 构造函数 它接收 ClassLoader 作为构造函数的参数，或者使用不带参数的构造函数。 在使用不带参数的构造函数时，使用的 ClassLoader 为默认的 ClassLoader（一般 Thread.currentThread()#getContextClassLoader() ）。 在使用带参数的构造函数时，可以通过 ClassUtils#getDefaultClassLoader()获取。 代码如下： @Nullable private ClassLoader classLoader; public DefaultResourceLoader() { // 无参构造函数 this.classLoader = ClassUtils.getDefaultClassLoader(); } public DefaultResourceLoader(@Nullable ClassLoader classLoader) { // 带 ClassLoader 参数的构造函数 this.classLoader = classLoader; } public void setClassLoader(@Nullable ClassLoader classLoader) { this.classLoader = classLoader; } @Override @Nullable public ClassLoader getClassLoader() { return (this.classLoader != null ? this.classLoader : ClassUtils.getDefaultClassLoader()); } 另外，也可以调用 #setClassLoader() 方法进行后续设置。 2.2.2 getResource 方法 ResourceLoader 中最核心的方法为 #getResource(String location)，它根据提供的 location 返回相应的 Resource 。而 DefaultResourceLoader 对该方法提供了核心实现（因为，它的两个子类都没有提供覆盖该方法，所以可以断定 ResourceLoader 的资源加载策略就封装在 DefaultResourceLoader 中)，代码如下： // DefaultResourceLoader.java @Override public Resource getResource(String location) { Assert.notNull(location, &quot;Location must not be null&quot;); // 首先，通过 ProtocolResolver 来加载资源 for (ProtocolResolver protocolResolver : this.protocolResolvers) { Resource resource = protocolResolver.resolve(location, this); if (resource != null) { return resource; } } // 其次，以 / 开头，返回 ClassPathContextResource 类型的资源 if (location.startsWith(&quot;/&quot;)) { return getResourceByPath(location); // 再次，以 classpath: 开头，返回 ClassPathResource 类型的资源 } else if (location.startsWith(CLASSPATH_URL_PREFIX)) { return new ClassPathResource(location.substring(CLASSPATH_URL_PREFIX.length()), getClassLoader()); // 然后，根据是否为文件 URL ，是则返回 FileUrlResource 类型的资源，否则返回 UrlResource 类型的资源 } else { try { // Try to parse the location as a URL... URL url = new URL(location); return (ResourceUtils.isFileURL(url) ? new FileUrlResource(url) : new UrlResource(url)); } catch (MalformedURLException ex) { // 最后，返回 ClassPathContextResource 类型的资源 // No URL -&gt; resolve as resource path. return getResourceByPath(location); } } } 首先，通过 ProtocolResolver 来加载资源，成功返回 Resource 。 其次，若location 以 &quot;/&quot; 开头，则调用 #getResourceByPath()方法，构造 ClassPathContextResource 类型资源并返回。代码如下： protected Resource getResourceByPath(String path) { return new ClassPathContextResource(path, getClassLoader()); } 再次，若location 以 &quot;classpath:&quot; 开头，则构造 ClassPathResource 类型资源并返回。在构造该资源时，通过 #getClassLoader() 获取当前的 ClassLoader。 然后，构造 URL ，尝试通过它进行资源定位，若没有抛出 MalformedURLException 异常，则判断是否为 FileURL , 如果是则构造 FileUrlResource 类型的资源，否则构造 UrlResource 类型的资源。 最后，若在加载过程中抛出 MalformedURLException 异常，则委派 #getResourceByPath() 方法，实现资源定位加载。😈 实际上，和【其次】相同。 2.2.3 ProtocolResolver org.springframework.core.io.ProtocolResolver，用户自定义协议资源解决策略，作为 DefaultResourceLoader 的 SPI：它允许用户自定义资源加载协议，而不需要继承 ResourceLoader 的子类。 在介绍 Resource 时，提到如果要实现自定义 Resource，我们只需要继承 AbstractResource 即可，但是有了 ProtocolResolver 后，我们不需要直接继承 DefaultResourceLoader，改为实现 ProtocolResolver 接口也可以实现自定义的 ResourceLoader。 ProtocolResolver 接口，仅有一个方法Resource resolve(String location, ResourceLoader resourceLoader)。代码如下： /** * 使用指定的 ResourceLoader ，解析指定的 location 。 * 若成功，则返回对应的 Resource 。 * * Resolve the given location against the given resource loader * if this implementation's protocol matches. * @param location the user-specified resource location 资源路径 * @param resourceLoader the associated resource loader 指定的加载器 ResourceLoader * @return a corresponding {@code Resource} handle if the given location * matches this resolver's protocol, or {@code null} otherwise 返回为相应的 Resource */ @Nullable Resource resolve(String location, ResourceLoader resourceLoader); 在 Spring 中你会发现该接口并没有实现类，它需要用户自定义，自定义的 Resolver 如何加入 Spring 体系呢？调用 DefaultResourceLoader#addProtocolResolver(ProtocolResolver)方法即可。代码如下： /** * ProtocolResolver 集合 */ private final Set&lt;ProtocolResolver&gt; protocolResolvers = new LinkedHashSet&lt;&gt;(4); public void addProtocolResolver(ProtocolResolver resolver) { Assert.notNull(resolver, &quot;ProtocolResolver must not be null&quot;); this.protocolResolvers.add(resolver); } 2.2.4 示例 下面示例是演示 DefaultResourceLoader 加载资源的具体策略，代码如下（该示例参考《Spring 揭秘》 P89）： ResourceLoader resourceLoader = new DefaultResourceLoader(); Resource fileResource1 = resourceLoader.getResource(&quot;D:/Users/chenming673/Documents/spark.txt&quot;); System.out.println(&quot;fileResource1 is FileSystemResource:&quot; + (fileResource1 instanceof FileSystemResource)); Resource fileResource2 = resourceLoader.getResource(&quot;/Users/chenming673/Documents/spark.txt&quot;); System.out.println(&quot;fileResource2 is ClassPathResource:&quot; + (fileResource2 instanceof ClassPathResource)); Resource urlResource1 = resourceLoader.getResource(&quot;file:/Users/chenming673/Documents/spark.txt&quot;); System.out.println(&quot;urlResource1 is UrlResource:&quot; + (urlResource1 instanceof UrlResource)); Resource urlResource2 = resourceLoader.getResource(&quot;http://www.baidu.com&quot;); System.out.println(&quot;urlResource1 is urlResource:&quot; + (urlResource2 instanceof UrlResource)); 运行结果： fileResource1 is FileSystemResource:false fileResource2 is ClassPathResource:true urlResource1 is UrlResource:true urlResource1 is urlResource:true 其实对于fileResource1，我们更加希望是 FileSystemResource 资源类型。但是，事与愿违，它是 ClassPathResource 类型。为什么呢？在 DefaultResourceLoader#getResource()方法的资源加载策略中，我们知道 &quot;D:/Users/chenming673/Documents/spark.txt&quot; 地址，其实在该方法中没有相应的资源类型，那么它就会在抛出 MalformedURLException 异常时，通过 DefaultResourceLoader#getResourceByPath(...) 方法，构造一个 ClassPathResource 类型的资源。 而 urlResource1 和urlResource2，指定有协议前缀的资源路径，则通过 URL 就可以定义，所以返回的都是 UrlResource 类型。 2.3 FileSystemResourceLoader 从上面的示例，我们看到，其实 DefaultResourceLoader 对#getResourceByPath(String)方法处理其实不是很恰当，这个时候我们可以使用 org.springframework.core.io.FileSystemResourceLoader 。它继承 DefaultResourceLoader ，且覆写了 #getResourceByPath(String)方法，使之从文件系统加载资源并以 FileSystemResource 类型返回，这样我们就可以得到想要的资源类型。代码如下： @Override protected Resource getResourceByPath(String path) { // 截取首 / if (path.startsWith(&quot;/&quot;)) { path = path.substring(1); } // 创建 FileSystemContextResource 类型的资源 return new FileSystemContextResource(path); } 2.3.1 FileSystemContextResource FileSystemContextResource ，为 FileSystemResourceLoader 的内部类，它继承 FileSystemResource 类，实现 ContextResource 接口。代码如下： /** * FileSystemResource that explicitly expresses a context-relative path * through implementing the ContextResource interface. */ private static class FileSystemContextResource extends FileSystemResource implements ContextResource { public FileSystemContextResource(String path) { super(path); } @Override public String getPathWithinContext() { return getPath(); } } 在构造器中，也是调用 FileSystemResource 的构造函数来构造 FileSystemResource 的。 为什么要有 FileSystemContextResource 类的原因是，实现 ContextResource 接口，并实现对应的 #getPathWithinContext()接口方法。 2.3.2 示例 在回过头看 「2.2.4 示例」 ，如果将 DefaultResourceLoader 改为 FileSystemResourceLoader ，则 fileResource1 则为 FileSystemResource 类型的资源。 2.4 ClassRelativeResourceLoader org.springframework.core.io.ClassRelativeResourceLoader ，是 DefaultResourceLoader 的另一个子类的实现。和 FileSystemResourceLoader 类似，在实现代码的结构上类似，也是覆写#getResourceByPath(String path)方法，并返回其对应的 ClassRelativeContextResource 的资源类型。 感兴趣的胖友，可以看看 《Spring5：就这一次，搞定资源加载器之ClassRelativeResourceLoader》 文章。 ClassRelativeResourceLoader 扩展的功能是，可以根据给定的class 所在包或者所在包的子包下加载资源。 2.5 ResourcePatternResolver ResourceLoader 的 Resource getResource(String location)方法，每次只能根据 location 返回一个 Resource 。当需要加载多个资源时，我们除了多次调用 #getResource(String location) 方法外，别无他法。org.springframework.core.io.support.ResourcePatternResolver 是 ResourceLoader 的扩展，它支持根据指定的资源路径匹配模式每次返回多个 Resource 实例，其定义如下： public interface ResourcePatternResolver extends ResourceLoader { String CLASSPATH_ALL_URL_PREFIX = &quot;classpath*:&quot;; Resource[] getResources(String locationPattern) throws IOException; } ResourcePatternResolver 在 ResourceLoader 的基础上增加了 #getResources(String locationPattern)方法，以支持根据路径匹配模式返回多个 Resource 实例。 同时，也新增了一种新的协议前缀 &quot;classpath*:&quot;，该协议前缀由其子类负责实现。 2.6 PathMatchingResourcePatternResolver org.springframework.core.io.support.PathMatchingResourcePatternResolver，为 ResourcePatternResolver 最常用的子类，它除了支持 ResourceLoader 和 ResourcePatternResolver 新增的&quot;classpath*:&quot; 前缀外，还支持 Ant 风格的路径匹配模式（类似于&quot;**/*.xml&quot;）。 2.6.1 构造函数 PathMatchingResourcePatternResolver 提供了三个构造函数，如下： /** * 内置的 ResourceLoader 资源定位器 */ private final ResourceLoader resourceLoader; /** * Ant 路径匹配器 */ private PathMatcher pathMatcher = new AntPathMatcher(); public PathMatchingResourcePatternResolver() { this.resourceLoader = new DefaultResourceLoader(); } public PathMatchingResourcePatternResolver(ResourceLoader resourceLoader) { Assert.notNull(resourceLoader, &quot;ResourceLoader must not be null&quot;); this.resourceLoader = resourceLoader; } public PathMatchingResourcePatternResolver(@Nullable ClassLoader classLoader) { this.resourceLoader = new DefaultResourceLoader(classLoader); } PathMatchingResourcePatternResolver 在实例化的时候，可以指定一个 ResourceLoader，如果不指定的话，它会在内部构造一个 DefaultResourceLoader 。 pathMatcher 属性，默认为 AntPathMatcher 对象，用于支持 Ant 类型的路径匹配。 2.6.2 getResource @Override public Resource getResource(String location) { return getResourceLoader().getResource(location); } public ResourceLoader getResourceLoader() { return this.resourceLoader; } 该方法，直接委托给相应的 ResourceLoader 来实现。所以，如果我们在实例化的 PathMatchingResourcePatternResolver 的时候，如果未指定 ResourceLoader 参数的情况下，那么在加载资源时，其实就是 DefaultResourceLoader 的过程。 其实在下面介绍的Resource[] getResources(String locationPattern) 方法也相同，只不过返回的资源是多个而已。 2.6.3 getResources @Override public Resource[] getResources(String locationPattern) throws IOException { Assert.notNull(locationPattern, &quot;Location pattern must not be null&quot;); // 以 &quot;classpath*:&quot; 开头 if (locationPattern.startsWith(CLASSPATH_ALL_URL_PREFIX)) { // 路径包含通配符 // a class path resource (multiple resources for same name possible) if (getPathMatcher().isPattern(locationPattern.substring(CLASSPATH_ALL_URL_PREFIX.length()))) { // a class path resource pattern return findPathMatchingResources(locationPattern); // 路径不包含通配符 } else { // all class path resources with the given name return findAllClassPathResources(locationPattern.substring(CLASSPATH_ALL_URL_PREFIX.length())); } // 不以 &quot;classpath*:&quot; 开头 } else { // Generally only look for a pattern after a prefix here, // 通常只在这里的前缀后面查找模式 // and on Tomcat only after the &quot;*/&quot; separator for its &quot;war:&quot; protocol. 而在 Tomcat 上只有在 “*/ ”分隔符之后才为其 “war:” 协议 int prefixEnd = (locationPattern.startsWith(&quot;war:&quot;) ? locationPattern.indexOf(&quot;*/&quot;) + 1 : locationPattern.indexOf(':') + 1); // 路径包含通配符 if (getPathMatcher().isPattern(locationPattern.substring(prefixEnd))) { // a file pattern return findPathMatchingResources(locationPattern); // 路径不包含通配符 } else { // a single resource with the given name return new Resource[] {getResourceLoader().getResource(locationPattern)}; } } } 逻辑处理如下图： 非 &quot;classpath*:&quot;开头，且路径不包含通配符，直接委托给相应的 ResourceLoader 来实现。 其他情况，调用#findAllClassPathResources(...)、或 #findPathMatchingResources(...) 方法，返回多个 Resource 。下面，我们来详细分析。 2.6.4 findAllClassPathResources 当locationPattern 以&quot;classpath*:&quot; 开头但是不包含通配符，则调用 #findAllClassPathResources(...) 方法加载资源。该方法返回 classes 路径下和所有 jar 包中的所有相匹配的资源。 protected Resource[] findAllClassPathResources(String location) throws IOException { String path = location; // 去除首个 / if (path.startsWith(&quot;/&quot;)) { path = path.substring(1); } // 真正执行加载所有 classpath 资源 Set&lt;Resource&gt; result = doFindAllClassPathResources(path); if (logger.isTraceEnabled()) { logger.trace(&quot;Resolved classpath location [&quot; + location + &quot;] to resources &quot; + result); } // 转换成 Resource 数组返回 return result.toArray(new Resource[0]); } 真正执行加载的是在#doFindAllClassPathResources(...) 方法，代码如下： protected Set&lt;Resource&gt; doFindAllClassPathResources(String path) throws IOException { Set&lt;Resource&gt; result = new LinkedHashSet&lt;&gt;(16); ClassLoader cl = getClassLoader(); // &lt;1&gt; 根据 ClassLoader 加载路径下的所有资源 Enumeration&lt;URL&gt; resourceUrls = (cl != null ? cl.getResources(path) : ClassLoader.getSystemResources(path)); // &lt;2&gt; while (resourceUrls.hasMoreElements()) { URL url = resourceUrls.nextElement(); // 将 URL 转换成 UrlResource result.add(convertClassLoaderURL(url)); } // &lt;3&gt; 加载路径下得所有 jar 包 if (&quot;&quot;.equals(path)) { // The above result is likely to be incomplete, i.e. only containing file system references. // We need to have pointers to each of the jar files on the classpath as well... addAllClassLoaderJarRoots(cl, result); } return result; } &lt;1&gt;处，根据 ClassLoader 加载路径下的所有资源。在加载资源过程时，如果在构造 PathMatchingResourcePatternResolver 实例的时候如果传入了 ClassLoader，则调用该 ClassLoader 的 #getResources()方法，否则调用 ClassLoader#getSystemResources(path) 方法。另外，ClassLoader#getResources()方法，代码如下: // java.lang.ClassLoader.java public Enumeration&lt;URL&gt; getResources(String name) throws IOException { @SuppressWarnings(&quot;unchecked&quot;) Enumeration&lt;URL&gt;[] tmp = (Enumeration&lt;URL&gt;[]) new Enumeration&lt;?&gt;[2]; if (parent != null) { tmp[0] = parent.getResources(name); } else { tmp[0] = getBootstrapResources(name); } tmp[1] = findResources(name); return new CompoundEnumeration&lt;&gt;(tmp); } 看到这里是不是就已经一目了然了？如果当前父类加载器不为 null ，则通过父类向上迭代获取资源，否则调用 #getBootstrapResources() 。这里是不是特别熟悉，(▽)。 &lt;2&gt; 处，遍历 URL 集合，调用#convertClassLoaderURL(URL url)方法，将 URL 转换成 UrlResource 对象。代码如下： protected Resource convertClassLoaderURL(URL url) { return new UrlResource(url); } &lt;3&gt; 处，若 path 为空（&quot;&quot;）时，则调用 #addAllClassLoaderJarRoots(...)方法。该方法主要是加载路径下得所有 jar 包，方法较长也没有什么实际意义就不贴出来了。感兴趣的胖友，自己可以去看看。😈 当然，可能代码也比较长哈。 通过上面的分析，我们知道#findAllClassPathResources(...) 方法，其实就是利用 ClassLoader 来加载指定路径下的资源，不论它是在 class 路径下还是在 jar 包中。如果我们传入的路径为空或者/，则会调用 #addAllClassLoaderJarRoots(...) 方法，加载所有的 jar 包。 2.6.5 findPathMatchingResources 当locationPattern 中包含了通配符，则调用该方法进行资源加载。代码如下： protected Resource[] findPathMatchingResources(String locationPattern) throws IOException { // 确定根路径、子路径 String rootDirPath = determineRootDir(locationPattern); String subPattern = locationPattern.substring(rootDirPath.length()); // 获取根据路径下的资源 Resource[] rootDirResources = getResources(rootDirPath); // 遍历，迭代 Set&lt;Resource&gt; result = new LinkedHashSet&lt;&gt;(16); for (Resource rootDirResource : rootDirResources) { rootDirResource = resolveRootDirResource(rootDirResource); URL rootDirUrl = rootDirResource.getURL(); // bundle 资源类型 if (equinoxResolveMethod != null &amp;&amp; rootDirUrl.getProtocol().startsWith(&quot;bundle&quot;)) { URL resolvedUrl = (URL) ReflectionUtils.invokeMethod(equinoxResolveMethod, null, rootDirUrl); if (resolvedUrl != null) { rootDirUrl = resolvedUrl; } rootDirResource = new UrlResource(rootDirUrl); } // vfs 资源类型 if (rootDirUrl.getProtocol().startsWith(ResourceUtils.URL_PROTOCOL_VFS)) { result.addAll(VfsResourceMatchingDelegate.findMatchingResources(rootDirUrl, subPattern, getPathMatcher())); // jar 资源类型 } else if (ResourceUtils.isJarURL(rootDirUrl) || isJarResource(rootDirResource)) { result.addAll(doFindPathMatchingJarResources(rootDirResource, rootDirUrl, subPattern)); // 其它资源类型 } else { result.addAll(doFindPathMatchingFileResources(rootDirResource, subPattern)); } } if (logger.isTraceEnabled()) { logger.trace(&quot;Resolved location pattern [&quot; + locationPattern + &quot;] to resources &quot; + result); } // 转换成 Resource 数组返回 return result.toArray(new Resource[0]); } 方法有点儿长，但是思路还是很清晰的，主要分两步： 确定目录，获取该目录下得所有资源。 在所获得的所有资源后，进行迭代匹配获取我们想要的资源。 在这个方法里面，我们要关注两个方法，一个是#determineRootDir(String location) 方法，一个是 #doFindPathMatchingXXXResources(...) 等方法。 2.6.5.1 determineRootDir determineRootDir(String location) 方法，主要是用于确定根路径。代码如下： /** * Determine the root directory for the given location. * &lt;p&gt;Used for determining the starting point for file matching, * resolving the root directory location to a {@code java.io.File} * and passing it into {@code retrieveMatchingFiles}, with the * remainder of the location as pattern. * &lt;p&gt;Will return &quot;/WEB-INF/&quot; for the pattern &quot;/WEB-INF/*.xml&quot;, * for example. * @param location the location to check * @return the part of the location that denotes the root directory * @see #retrieveMatchingFiles */ protected String determineRootDir(String location) { // 找到冒号的后一位 int prefixEnd = location.indexOf(':') + 1; // 根目录结束位置 int rootDirEnd = location.length(); // 在从冒号开始到最后的字符串中，循环判断是否包含通配符，如果包含，则截断最后一个由”/”分割的部分。 // 例如：在我们路径中，就是最后的ap?-context.xml这一段。再循环判断剩下的部分，直到剩下的路径中都不包含通配符。 while (rootDirEnd &gt; prefixEnd &amp;&amp; getPathMatcher().isPattern(location.substring(prefixEnd, rootDirEnd))) { rootDirEnd = location.lastIndexOf('/', rootDirEnd - 2) + 1; } // 如果查找完成后，rootDirEnd = 0 了，则将之前赋值的 prefixEnd 的值赋给 rootDirEnd ，也就是冒号的后一位 if (rootDirEnd == 0) { rootDirEnd = prefixEnd; } // 截取根目录 return location.substring(0, rootDirEnd); } 方法比较绕，效果如下示例： 原路径 确定根路径 classpath*:test/cc*/spring-*.xml classpath*:test/ classpath*:test/aa/spring-*.xml classpath*:test/aa/ 2.6.5.2 doFindPathMatchingXXXResources #doFindPathMatchingXXXResources(...) 方法，是个泛指，一共对应三个方法： #doFindPathMatchingJarResources(rootDirResource, rootDirUrl, subPatter) 方法 #doFindPathMatchingFileResources(rootDirResource, subPattern)方法 VfsResourceMatchingDelegate#findMatchingResources(rootDirUrl, subPattern, pathMatcher) 方法 因为本文重在分析 Spring 统一资源加载策略的整体流程。相对来说，上面几个方法的代码量会比较多。所以本文不再追溯，感兴趣的胖友，推荐阅读如下文章： 《Spring源码情操陶冶-PathMatchingResourcePatternResolver路径资源匹配溶解器》 ，主要针对 #doFindPathMatchingJarResources(rootDirResource, rootDirUrl, subPatter)方法 《深入 Spring IoC 源码之 ResourceLoader》 ，主要针对 #doFindPathMatchingFileResources(rootDirResource, subPattern) 方法。 《Spring 源码学习 —— 含有通配符路径解析（上）》 3. 小结 至此 Spring 整个资源记载过程已经分析完毕。下面简要总结下： Spring 提供了 Resource 和 ResourceLoader 来统一抽象整个资源及其定位。使得资源与资源的定位有了一个更加清晰的界限，并且提供了合适的 Default 类，使得自定义实现更加方便和清晰。 AbstractResource 为 Resource 的默认抽象实现，它对 Resource 接口做了一个统一的实现，子类继承该类后只需要覆盖相应的方法即可，同时对于自定义的 Resource 我们也是继承该类。 DefaultResourceLoader 同样也是 ResourceLoader 的默认实现，在自定 ResourceLoader 的时候我们除了可以继承该类外还可以实现 ProtocolResolver 接口来实现自定资源加载协议。 DefaultResourceLoader 每次只能返回单一的资源，所以 Spring 针对这个提供了另外一个接口 ResourcePatternResolver ，该接口提供了根据指定的 locationPattern 返回多个资源的策略。其子类 PathMatchingResourcePatternResolver 是一个集大成者的 ResourceLoader ，因为它即实现了 Resource getResource(String location) 方法，也实现了 Resource[] getResources(String locationPattern) 方法。 另外，如果胖友认真的看了本文的包结构，我们可以发现，Resource 和 ResourceLoader 核心是在，spring-core 项目中。 如果想要调试本小节的相关内容，可以直接使用 Resource 和 ResourceLoader 相关的 API ，进行操作调试。 ","link":"https://xinrong2019.github.io/post/si-ke-spring-ioc-zhi-spring-tong-yi-zi-yuan-jia-zai-ce-lue/"},{"title":"Oracle创建表空间、创建用户的完整过程","content":"正文 /* 步骤： 1、创建表空间 2、创建用户 3、用户授权 */ /*创建表空间*/ create tablespace QCJ_TABLESPACE /*表空间物理文件名称*/ datafile 'QCJ_TABLESPACE.dbf' -- 这种方式指定表空间物理文件位置 -- datafile 'F:\\APP\\QIUCHANGJIN\\ORADATA\\ORCL\\QCJ_TABLESPACE.dbf' -- 大小 500M，每次 5M 自动增大，最大不限制 size 500M autoextend on next 5M maxsize unlimited; /* 创建用户*/ create user qiuchangjin IDENTIFIED BY root --用户密码 default tablespace QCJ_TABLESPACE-- 表空间是上面创建的 temporary tablespace TEMP -- 临时表空间默认 TEMP profile DEFAULT; --password expire; /*密码过期需要重设密码,意思是当你用这个新建立的密码过期用户首次登录后，系统会提示你重新输入新密码，不然会拒绝你登陆，重设新密码后就可以登录，该用户的密码就是你新设的密码，相当于首次登录修改密码这样的选项。*/ /* 用户授权_1*/ grant connect,resource,dba to qiuchangjin; /* 用户授权_2*/ grant connect to qiuchangjin with admin option; grant dba to qiuchangjin with admin option; grant resource to qiuchangjin with admin option; /*查询所有表空间物理位置*/ select name from v$datafile; /*查询当前用户的表空间*/ select username,default_tablespace from user_users; /*修改用户的默认表空间*/ alter user 用户名 default tablespace 新表空间; /*查询所有的表空间*/ select * from user_tablespaces; /* 删除表空间*/ alter tablespace QCJ_TABLESPACE offline; drop tablespace QCJ_TABLESPACE including contents and datafiles; 其他 1、查看当前用户拥有的角色权限信息： select * from role_sys_privs; 2、查看当前用户的详细信息： select * from user_users; 3、查看当前用户的角色信息： select * from user_role_privs; 4、修改用户密码： alter user 用户名 identified by 新密码； 5、设置Oracle用户密码为无期限 ALTER PROFILE DEFAULT LIMIT PASSWORD_LIFE_TIME UNLIMITED; 参考资料： Oracle创建表空间、创建用户的完整过程 ","link":"https://xinrong2019.github.io/post/oracle-chuang-jian-biao-kong-jian-chuang-jian-yong-hu-de-wan-zheng-guo-cheng/"},{"title":"[死磕Spring]--IoC之深入理解Spring IoC","content":"1 IoC理论 IoC 全称为 Inversion of Control，翻译为 “控制反转”，它还有一个别名为 DI（Dependency Injection）,即依赖注入。 如何理解“控制反转”好呢？理解好它的关键在于我们需要回答如下四个问题： 谁控制谁 控制什么 为何是反转 哪些方面反转了 在回答这四个问题之前，我们先看 IoC 的定义： 所谓 IoC ，就是由 Spring IoC 容器来负责对象的生命周期和对象之间的关系 谁控制谁：在传统的开发模式下，我们都是采用直接 new 一个对象的方式来创建对象，也就是说你依赖的对象直接由你自己控制，但是有了 IoC 容器后，则直接由 IoC 容器来控制。所以“谁控制谁”，当然是 IoC 容器控制对象 控制什么：控制对象。 为何是反转：没有 IoC 的时候我们都是在自己对象中主动去创建被依赖的对象，这是正转。但是有了 IoC 后，所依赖的对象直接由 IoC 容器创建后注入到被注入的对象中，依赖的对象由原来的主动获取变成被动接受，所以是反转。 哪些方面反转了：所依赖对象的获取被反转了。 1.1 注入形式 IoC Service Provider 为被注入对象提供被依赖对象有如下几种方式：构造方法注入、stter方法注入、接口注入。 ① 构造器注入 构造器注入，顾名思义就是被注入的对象通过在其构造方法中声明依赖对象的参数列表，让外部知道它需要哪些依赖对象。 YoungMan(BeautifulGirl beautifulGirl) { this.beautifulGirl = beautifulGirl; } 构造器注入方式比较直观，对象构造完毕后就可以直接使用，这就好比你出生你家里就给你指定了你媳妇。 ② setter 方法注入 对于 JavaBean 对象而言，我们一般都是通过 getter 和 setter 方法来访问和设置对象的属性。所以，当前对象只需要为其所依赖的对象提供相对应的 setter 方法，就可以通过该方法将相应的依赖对象设置到被注入对象中。如下： public class YoungMan { private BeautifulGirl beautifulGirl; public void setBeautifulGirl(BeautifulGirl beautifulGirl) { this.beautifulGirl = beautifulGirl; } } ③ 接口方式注入 接口方式注入显得比较霸道，因为它需要被依赖的对象实现不必要的接口，带有侵入性。一般都不推荐这种方式。 《依赖注入的三种实现形式 —— 接口注入（Interface Injection）》 1.2 推荐文章 关于 IoC 理论部分，笔者不在阐述，这里推荐几篇博客阅读： 《谈谈对 Spring IoC 的理解》 《Spring 的 IoC 原理[通俗解释一下]》 《Spring IoC 原理（看完后大家可以自己写一个spring）》 2. 各个组件 先看下图（摘自:http://singleant.iteye.com/blog/1177358） 该图为 ClassPathXmlApplicationContext 的类继承体系结构，虽然只有一部分，但是它基本上包含了 IoC 体系中大部分的核心类和接口。 下面我们就针对这个图进行简单的拆分和补充说明。 2.1 Resource 体系 org.springframework.core.io.Resource，对资源的抽象。它的每一个实现类都代表了一种资源的访问策略，如 ClassPathResource、RLResource、FileSystemResource 等。 2.1.2 ResourceLoader 体系 有了资源，就应该有资源加载，Spring 利用 org.springframework.core.io.ResourceLoader来进行统一资源加载，类图如下： 关于 Resource 和 ResourceLoader 的源码解析，见 《【死磕 Spring】—— IoC 之 Spring 统一资源加载策略》 。 2.2 BeanFactory 体系 org.springframework.beans.factory.BeanFactory，是一个非常纯粹的 bean 容器，它是 IoC 必备的数据结构，其中 BeanDefinition 是它的基本结构。BeanFactory 内部维护着一个BeanDefinition map ，并可根据 BeanDefinition 的描述进行 bean 的创建和管理。 BeanFactory 有三个直接子类 ListableBeanFactory、HierarchicalBeanFactory 和 AutowireCapableBeanFactory 。 DefaultListableBeanFactory 为最终默认实现，它实现了所有接口。 2.3 BeanDefinition 体系 org.springframework.beans.factory.config.BeanDefinition ，用来描述 Spring 中的 Bean 对象。 2.4 BeanDefinitionReader 体系 org.springframework.beans.factory.support.BeanDefinitionReader的作用是读取 Spring 的配置文件的内容，并将其转换成 Ioc 容器内部的数据结构 ：BeanDefinition 。 关于 BeanDefinitionReader 的源码解析，见如下文章： 《【死磕 Spring】—— IoC 之加载 Definitions》 《【死磕 Spring】—— IoC 之获取验证模型》 《【死磕 Spring】—— IoC 之获取 Document 对象》 《【死磕 Spring】—— IoC 之注册 BeanDefinitions》 2.5 ApplicationContext 体系 org.springframework.context.ApplicationContext，这个就是大名鼎鼎的 Spring 容器，它叫做应用上下文，与我们应用息息相关。它继承 BeanFactory ，所以它是 BeanFactory 的扩展升级版，如果BeanFactory 是屌丝的话，那么 ApplicationContext 则是名副其实的高富帅。由于 ApplicationContext 的结构就决定了它与 BeanFactory 的不同，其主要区别有： 继承 org.springframework.context.MessageSource 接口，提供国际化的标准访问策略。 继承 org.springframework.context.ApplicationEventPublisher 接口，提供强大的事件机制。 扩展 ResourceLoader ，可以用来加载多种 Resource ，可以灵活访问不同的资源。 对 Web 应用的支持。 下图来源：https://blog.csdn.net/yujin753/article/details/47043143 2.6 小结 上面五个体系可以说是 Spring IoC 中最核心的部分，后面博文也是针对这五个部分进行源码分析。其实 IoC 咋一看还是挺简单的，无非就是将配置文件（暂且认为是 xml 文件）进行解析（分析 xml 谁不会啊），然后放到一个 Map 里面就差不多了，初看有道理，其实要面临的问题还是有很多的，下面就劳烦各位看客跟着 LZ 博客来一步一步揭开 Spring IoC 的神秘面纱。 此系列博文为 LZ 学习、研究 Spring 机制和源码的学习笔记，会涉及参考别人的博文和书籍内容，如有雷同，纯属借鉴，当然 LZ 会标明参考来源。同时由于知识面和能力的问题，文章中难免会出现错误之处，如有，望各位大佬指出，不胜感激。 另外，通过上面五个体系，我们可以看出，IoC 主要由 spring-beans 和 spring-context 项目，进行实现。 参考文章： 【死磕 Spring】—— IoC 之深入理解 Spring IoC ","link":"https://xinrong2019.github.io/post/si-ke-spring-ioc-zhi-shen-ru-li-jie-spring-ioc/"},{"title":"SSH公钥配置多账户映射及配置本地仓库提交到多个远程仓库","content":"1、什么是SSH？ Secure Shell是一种加密的网络传输协议，简称SSH。有开源实现OpenSSH和商业实现。 想要了解SSH工作原理,可以看看这篇文章。 2、为什么会出现Key is already in use这个错？ 因为公钥只能添加到一个远程仓库 3、我为什么要配置多个ssh密钥对? 因为我想把我的本地仓库推送到不同到远程仓库，比如我有两个Github账号，想把本地同一份代码推到两个不同到账号到对应仓库里。 这个时候，同一个公钥在绑定一个账号后，再绑定另一个账号，就会报出错误Key is already in use。 4、如何配置多个ssh密钥对? 4.1、为每个远程仓库生成一份ssh密钥对 生成本地ssh密钥对 ssh-keygen -t rsa -C 'your_email@example.com' -f ~/.ssh/id_rsa_github 需要把your_email@example.com修改成自己到邮箱; id_rsa_github是保存到文件名，可以任意取，但是最好有含义. 第一步执行后，会生成id_rsa_github和id_rsa_github.pub两个文件 编辑config文件，映射不同到远程仓库账户 在~/.ssh/目录下，编辑config文件，如果不存在新建 内容如下： # 个人的GitHub公钥 Host github.com # host名是自己取,任意，但是最好有意义 HostName github.com # 域名必须是远程仓库的域名，不能随便写，其他如gitee.com PreferredAuthentications publickey IdentityFile ~/.ssh/id_rsa_github_xinrong2019 # key的路径 #指定特定的ssh私钥文件 # 公司的's gitee.com Host gitee.com HostName gitee.com PreferredAuthentications publickey IdentityFile ~/.ssh/id_rsa # 指定特定的ssh私钥文件 # 另一个github账号 Host github_2.com HostName github.com PreferredAuthentications publickey IdentityFile ~/.ssh/jameingh 上面的配置为三个远程仓库账号配置了映射。 将不同账户的公钥配置到对应的Git服务提供商的配置中保存。 比如点击这里在GitHub上添加SSH密钥 测试是否添加成功 测试Host为github.com的密钥对是否添加成功 ssh -T git@github.com Hi xinrong2019! You've successfully authenticated, but GitHub does not provide shell access. 测试Host为github_2.com的密钥对是否添加成功 ssh -T git@github_2.com Hi jameingh! You've successfully authenticated, but GitHub does not provide shell access. 4.2、将本地仓库绑定到多个远程仓库，这样就可以每次选择提交到不同的仓库 先删除已关联的名为origin的远程库： git remote rm origin 分别关联GitHub和Gitee仓库 git remote add github git@github.com:SixGodFlowerDewWater1029/mindmap.git git remote add gitee git@gitee.com:JavaLoveGo/mindmap.git 配置本地仓库绑定多个远程仓库(可选) 进入.git目录，修改config文件，执行了上面关联仓库的命令后，一般来说会自动加入到config文件中。没有的话，自己手动添加。 文件内容格式 [core] repositoryformatversion = 0 filemode = true bare = false logallrefupdates = true ignorecase = true precomposeunicode = true [remote &quot;github&quot;] url = git@github_2.com:SixGodFlowerDewWater1029/mindmap.git fetch = +refs/heads/*:refs/remotes/github/* [remote &quot;gitee&quot;] url = git@gitee.com:JavaLoveGo/mindmap.git fetch = +refs/heads/*:refs/remotes/gitee/* 查看本地映射的仓库 回到项目根目录，执行git remote -v，查看映射的远程仓库 gitee git@gitee.com:JavaLoveGo/mindmap.git (fetch) gitee git@gitee.com:JavaLoveGo/mindmap.git (push) github git@github_2.com:SixGodFlowerDewWater1029/mindmap.git (fetch) github git@github_2.com:SixGodFlowerDewWater1029/mindmap.git (push) 分别在两个远程仓库上拉代码 git pull github master git pull gitee master 推送代码 git push github master git push gitee master 可能的错误1：推送代码失败 Push failed ERROR: Permission to SixGodFlowerDewWater1029/mindmap.git denied to xinrong2019. Could not read from remote repository. Please make sure you have the correct access rights and the repository exists. 这是因为远程仓库关联的不对。 执行git remote -v，看到的是如下的映射 github git@github.com:SixGodFlowerDewWater1029/mindmap.git (fetch) github git@github.com:SixGodFlowerDewWater1029/mindmap.git (push) 这里的github.com是.ssh目录下config文件中配置的Host，确定github.com和账号xinrong2019是不是关联正确。 就是说，你是不是把公钥配置在了xinrong2019账号下。 我这里，github.com是配置在了jameingh账号下，所以上面报错说xinrong2019没有权限，拒绝访问。 jameingh对应的Host是github_2.com，修改项目根目录下.git/config文件中的配置 可能的错误2: git pull失败 Can't Update No tracked branch configured for branch master or the branch doesn't exist. To make your branch track a remote branch call, for example, git branch --set-upstream-to=origin/master master (show balloon) 设置本地仓库对应的远程仓库映射，从哪个远程仓库等对应分支拉代码。 git branch --set-upstream-to=gitee/master master 5、参考 1、配置多个ssh公钥，解决Key is already in use 2、多个sshkey对应多个不同的github账号 3、git同步代码至github和gitee(码云) ","link":"https://xinrong2019.github.io/post/pei-zhi-duo-ge-ssh-gong-yao-jie-jue-key-is-already-in-use/"},{"title":"计划清单","content":"要求： 写下自己掌握和理解的。 由于时间宝贵，要有重要紧急和优先主次。 要有完成时间 技术层面： 计算机基础： 算法 操作系统 网络 计算机组成原理 Java Java基础 Java并发 disruptor Java集合 IO Netty 框架 Spring Core Spring Boot Spring MVC Mybatis Spring Data JPA 中间件 Dubbo Redis Memcache MQ ElasticSearch 自动化运维 Jenkins Docker 职业素养： 简历 面试 转正申请 试用期所从事的工作事项或参与的项目，量化的形式简述相应内容 简述试用部门技术、产品、管理、工作流程等的了解、掌握及改善提议 简述目前工作中存在的不足或痛点，请结合实际，说明改进或提高的具体方法、措施及对应时间表 阐述希望从部门主管或公司领导处获得何种帮助，以期更顺利地开展工作 平时工作考核 高效地开展工作并能使用得当的工作方法及时、保质保量完成工作任务。 具有较强的计划性和条理性，善于总结经验教训。 工作积极主动，不断改进工作方法，提高工作效率、优化工作结果 善于与人协调、沟通、合作，具有团队协作精神 锐意进取，积极创造或引进新观念、新方法等，有意识的利用新知识来改进工作，提升工作绩效。 积极主动学习，不断提高自身的业务水平和技能，并能主动分享所学。 自觉遵守公司各项规章制度，依照即定计划执行工作任务，关注细节，有意识地在工作中寻求规律技巧，提升效率。 书单 程序员修炼之道 程序员的自我修养 ","link":"https://xinrong2019.github.io/post/ji-hua-qing-dan/"}]}